

@book{hox_multilevel_2017,
	address = {Third edition. {\textbar} New York, NY : Routledge, 2017. {\textbar}},
	edition = {3},
	title = {Multilevel {Analysis}: {Techniques} and {Applications}},
	isbn = {978-1-315-65098-2},
	shorttitle = {Multilevel {Analysis}},
	url = {https://www.taylorfrancis.com/books/9781317308683},
	language = {en},
	urldate = {2023-03-27},
	publisher = {Routledge},
	author = {Hox, Joop J. and Moerbeek, Mirjam and van de Schoot, Rens},
	month = sep,
	year = {2017},
	doi = {10.4324/9781315650982},
}

@book{lazega_multilevel_2016,
	address = {Cham},
	series = {Methodos series},
	title = {Multilevel network analysis for the social sciences: theory, methods and applications},
	isbn = {978-1-84920-201-5 978-3-319-24518-8},
	shorttitle = {Multilevel network analysis for the social sciences},
	language = {eng},
	number = {12},
	publisher = {Springer},
	editor = {Lazega, Emmanuel and Snijders, Tom A. B.},
	year = {2016},
	annote = {Literaturangaben},
}

@article{franzese_empirical_2005,
	title = {Empirical {Strategies} for {Various} {Manifestations} of {Multilevel} {Data}},
	volume = {13},
	issn = {1047-1987},
	url = {https://www.jstor.org/stable/25791826},
	abstract = {Equivalent separate-subsample (two-step) and pooled-sample (one-step) strategies exist for any multilevel-modeling task, but their relative practicality and efficacy depend on dataset dimensions and properties and researchers' goals. Separate-subsample strategies have difficulties incorporating cross-subsample information, often crucial in time-series cross-section or panel contexts (subsamples small and/or cross-subsample information great) but less relevant in pools of independently random surveys (subsamples large; cross-sample information small). Separate-subsample estimation also complicates retrieval of macro-level-effect estimates, although they remain obtainable and may not be substantively central. Pooled-sample estimation, conversely, struggles with stochastic specifications that differ across levels (e.g., stochastic linear interactions in binary dependent-variable models). Moreover, pooled-sample estimation that models coefficient variation in a theoretically reduced manner rather than allowing each subsample coefficient vector to differ arbitrarily can suffer misspecification ills insofar as this reduced specification is lacking. Often, though, these ills are limited to inefficiencies and standard-error inaccuracies that familiar efficient (e.g., feasible generalized least squares) or consistent-standard-error estimation strategies can satisfactorily redress.},
	number = {4},
	urldate = {2023-03-27},
	journal = {Political Analysis},
	author = {Franzese, Robert J.},
	year = {2005},
	note = {Publisher: [Oxford University Press, Society for Political Methodology]},
	pages = {430--446},
	file = {Franzese - 2005 - Empirical Strategies for Various Manifestations of.pdf:/Users/isabelleborucki/Zotero/storage/J8N2BGL9/Franzese - 2005 - Empirical Strategies for Various Manifestations of.pdf:application/pdf},
}

@article{heisig_why_2019,
	title = {Why {You} {Should} {Always} {Include} a {Random} {Slope} for the {Lower}-{Level} {Variable} {Involved} in a {Cross}-{Level} {Interaction}},
	volume = {35},
	issn = {0266-7215},
	url = {https://doi.org/10.1093/esr/jcy053},
	doi = {10.1093/esr/jcy053},
	abstract = {Mixed-effects multilevel models are often used to investigate cross-level interactions, a specific type of context effect that may be understood as an upper-level variable moderating the association between a lower-level predictor and the outcome. We argue that multilevel models involving cross-level interactions should always include random slopes on the lower-level components of those interactions. Failure to do so will usually result in severely anti-conservative statistical inference. We illustrate the problem with extensive Monte Carlo simulations and examine its practical relevance by studying 30 prototypical cross-level interactions with European Social Survey data for 28 countries. In these empirical applications, introducing a random slope term reduces the absolute t-ratio of the cross-level interaction term by 31 per cent or more in three quarters of cases, with an average reduction of 42 per cent. Many practitioners seem to be unaware of these issues. Roughly half of the cross-level interaction estimates published in the European Sociological Review between 2011 and 2016 are based on models that omit the crucial random slope term. Detailed analysis of the associated test statistics suggests that many of the estimates would not reach conventional thresholds for statistical significance in correctly specified models that include the random slope. This raises the question how much robust evidence of cross-level interactions sociology has actually produced over the past decades.},
	number = {2},
	urldate = {2023-03-27},
	journal = {European Sociological Review},
	author = {Heisig, Jan Paul and Schaeffer, Merlin},
	month = apr,
	year = {2019},
	pages = {258--279},
	file = {Heisig and Schaeffer - 2019 - Why You Should Always Include a Random Slope for t.pdf:/Users/isabelleborucki/Zotero/storage/CZPQZ3M2/Heisig and Schaeffer - 2019 - Why You Should Always Include a Random Slope for t.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/BP8SMM5B/5306121.html:text/html},
}

@article{bryan_multilevel_2016,
	title = {Multilevel {Modelling} of {Country} {Effects}: {A} {Cautionary} {Tale}},
	volume = {32},
	issn = {0266-7215},
	shorttitle = {Multilevel {Modelling} of {Country} {Effects}},
	url = {https://doi.org/10.1093/esr/jcv059},
	doi = {10.1093/esr/jcv059},
	abstract = {Country effects on outcomes for individuals are often analysed using multilevel (hierarchical) models applied to harmonized multi-country data sets such as ESS, EU-SILC, EVS, ISSP, and SHARE. We point out problems with the assessment of country effects that appear not to be widely appreciated, and develop our arguments using Monte Carlo simulation analysis of multilevel linear and logit models. With large sample sizes of individuals within each country but only a small number of countries, analysts can reliably estimate individual-level effects but estimates of parameters summarizing country effects are likely to be unreliable. Multilevel modelling methods are no panacea.},
	number = {1},
	urldate = {2023-03-27},
	journal = {European Sociological Review},
	author = {Bryan, Mark L. and Jenkins, Stephen P.},
	month = feb,
	year = {2016},
	pages = {3--22},
	file = {Bryan and Jenkins - 2016 - Multilevel Modelling of Country Effects A Caution.pdf:/Users/isabelleborucki/Zotero/storage/JLNDWL2V/Bryan and Jenkins - 2016 - Multilevel Modelling of Country Effects A Caution.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/WJNA8LVY/2404247.html:text/html},
}

@article{heisig_costs_2017,
	title = {The {Costs} of {Simplicity}: {Why} {Multilevel} {Models} {May} {Benefit} from {Accounting} for {Cross}-{Cluster} {Differences} in the {Effects} of {Controls}},
	volume = {82},
	issn = {0003-1224},
	shorttitle = {The {Costs} of {Simplicity}},
	url = {https://doi.org/10.1177/0003122417717901},
	doi = {10.1177/0003122417717901},
	abstract = {Context effects, where a characteristic of an upper-level unit or cluster (e.g., a country) affects outcomes and relationships at a lower level (e.g., that of the individual), are a primary object of sociological inquiry. In recent years, sociologists have increasingly analyzed such effects using quantitative multilevel modeling. Our review of multilevel studies in leading sociology journals shows that most assume the effects of lower-level control variables to be invariant across clusters, an assumption that is often implausible. Comparing mixed-effects (random-intercept and slope) models, cluster-robust pooled OLS, and two-step approaches, we find that erroneously assuming invariant coefficients reduces the precision of estimated context effects. Semi-formal reasoning and Monte Carlo simulations indicate that loss of precision is largest when there is pronounced cross-cluster heterogeneity in the magnitude of coefficients, when there are marked compositional differences among clusters, and when the number of clusters is small. Although these findings suggest that practitioners should fit more flexible models, illustrative analyses of European Social Survey data indicate that maximally flexible mixed-effects models do not perform well in real-life settings. We discuss the need to balance parsimony and flexibility, and we demonstrate the encouraging performance of one prominent approach for reducing model complexity.},
	language = {en},
	number = {4},
	urldate = {2023-03-27},
	journal = {American Sociological Review},
	author = {Heisig, Jan Paul and Schaeffer, Merlin and Giesecke, Johannes},
	month = aug,
	year = {2017},
	note = {Publisher: SAGE Publications Inc},
	pages = {796--827},
	file = {Heisig et al. - 2017 - The Costs of Simplicity Why Multilevel Models May.pdf:/Users/isabelleborucki/Zotero/storage/D9L95MSW/Heisig et al. - 2017 - The Costs of Simplicity Why Multilevel Models May.pdf:application/pdf},
}

@article{schmidt-catran_random_2016,
	title = {The {Random} {Effects} in {Multilevel} {Models}: {Getting} {Them} {Wrong} and {Getting} {Them} {Right}},
	volume = {32},
	issn = {0266-7215},
	shorttitle = {The {Random} {Effects} in {Multilevel} {Models}},
	url = {https://doi.org/10.1093/esr/jcv090},
	doi = {10.1093/esr/jcv090},
	abstract = {Many surveys of respondents from multiple countries or subnational regions have now been fielded on multiple occasions. Social scientists are regularly using multilevel models to analyse the data generated by such surveys, investigating variation across both space and time. We show, however, that such models are usually specified erroneously. They typically omit one or more relevant random effects, thereby ignoring important clustering in the data, which leads to downward biases in the standard errors. These biases occur even if the fixed effects are specified correctly; if the fixed effects are incorrect, erroneous specification of the random effects worsens biases in the coefficients. We illustrate these problems using Monte Carlo simulations and two empirical examples. Our recommendation to researchers fitting multilevel models to comparative longitudinal survey data is to include random effects at all potentially relevant levels, thereby avoiding any mismatch between the random and fixed parts of their models.},
	number = {1},
	urldate = {2023-03-27},
	journal = {European Sociological Review},
	author = {Schmidt-Catran, Alexander W. and Fairbrother, Malcolm},
	month = feb,
	year = {2016},
	pages = {23--38},
	file = {Schmidt-Catran and Fairbrother - 2016 - The Random Effects in Multilevel Models Getting T.pdf:/Users/isabelleborucki/Zotero/storage/SDSLGTSH/Schmidt-Catran and Fairbrother - 2016 - The Random Effects in Multilevel Models Getting T.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/UQ8I8CHB/2404356.html:text/html},
}

@article{gebel_does_2016,
	title = {Does {Deregulation} {Help}? {The} {Impact} of {Employment} {Protection} {Reforms} on {Youths}’ {Unemployment} and {Temporary} {Employment} {Risks} in {Europe}},
	volume = {32},
	issn = {0266-7215},
	shorttitle = {Does {Deregulation} {Help}?},
	url = {https://doi.org/10.1093/esr/jcw022},
	doi = {10.1093/esr/jcw022},
	abstract = {Rigid employment protection legislation (EPL) has been blamed as the root of youths’ labour market integration problems in Europe. Many European countries have reacted by deregulating employment protection laws, often targeting youths as a group. However, doubts about the effectiveness of EPL reforms have arisen. Against this background, this article investigates whether EPL reforms succeeded in integrating youths into labour markets or whether they were ineffective and just promoted temporary employment as a crucial new social inequality in Europe. Based on two-step, three-level analyses using micro-data from the European Labour Force Survey for 19 European countries for the period from 1992 to 2012, our results show that deregulating the use of temporary contracts increased temporary employment risks of youths but did not reduce (for low-educated young men, even increased) unemployment risks. In contrast, we find some evidence that decreasing the protection of permanent jobs was successful in decreasing risks of inequality/insecurity (in terms of temporary jobs) without affecting the risks of labour market exclusion.},
	number = {4},
	urldate = {2023-03-27},
	journal = {European Sociological Review},
	author = {Gebel, Michael and Giesecke, Johannes},
	month = aug,
	year = {2016},
	pages = {486--500},
	file = {Gebel and Giesecke - 2016 - Does Deregulation Help The Impact of Employment P.pdf:/Users/isabelleborucki/Zotero/storage/XHGHRLQK/Gebel and Giesecke - 2016 - Does Deregulation Help The Impact of Employment P.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/3NXGEJEN/2450426.html:text/html},
}

@article{jusko_applying_2005,
	title = {Applying a {Two}-{Step} {Strategy} to the {Analysis} of {Cross}-{National} {Public} {Opinion} {Data}},
	volume = {13},
	issn = {1047-1987},
	url = {https://www.jstor.org/stable/25791821},
	abstract = {In recent years, large sets of national surveys with shared content have increasingly been used for cross-national opinion research. But scholars have not yet settled on the most flexible and efficient models for utilizing such data. We present a two-step strategy for such analysis that takes advantage of the fact that in such datasets each "cluster" (i.e., country sample) is large enough to sustain separate analysis of its internal variances and covariances. We illustrate the method by examining a puzzle of comparative electoral behavior—why does turnout decline rather than increase with the number of parties competing in an election (Blais and Dobryzynska 1998, for example)? This discussion demonstrates the ease with which a two-step strategy incorporates confounding variables operating at different levels of analysis. Technical appendices demonstrate that the two-step strategy does not lose efficiency of estimation as compared with a pooling strategy.},
	number = {4},
	urldate = {2023-03-27},
	journal = {Political Analysis},
	author = {Jusko, Karen Long and Shively, W. Phillips},
	year = {2005},
	note = {Publisher: [Oxford University Press, Society for Political Methodology]},
	pages = {327--344},
	file = {Jusko and Shively - 2005 - Applying a Two-Step Strategy to the Analysis of Cr.pdf:/Users/isabelleborucki/Zotero/storage/VTG7V5UG/Jusko and Shively - 2005 - Applying a Two-Step Strategy to the Analysis of Cr.pdf:application/pdf},
}

@article{oldac_multilevel_2020,
	title = {Multilevel analysis of the relationship between school-level variables and student achievement},
	volume = {48},
	issn = {1741-1432},
	url = {https://doi.org/10.1177/1741143219827303},
	doi = {10.1177/1741143219827303},
	abstract = {The purpose of this study was to investigate the relationship between student achievement and a set of school-level variables, including distributed leadership, academic optimism, teacher collaboration and enabling school structure. The study was designed as correlational research. A Hierarchical Linear Modeling (HLM) analysis was conducted with a data set collected from 23,053 students and 426 teachers from 40 randomly selected public schools in Turkey. The data were collected using previously developed scales and student achievement data from the Ministry of National Education. HLM results revealed that two dimensions of academic optimism ? namely collective efficacy and trust in clients ? and hindering bureaucracy significantly predicted between-school differences in student achievement. The tested HLM model explained 60\% of the variation in student achievement across schools. The results revealed that student achievement is shaped by school-level variables that are tied to the structural and functional characteristics of schools in Turkey. However, these school characteristics are rooted in the societal structures and cultural characteristics of the country. Hence, it is concluded that a reinterpretation of common school-level variables used to predict student achievement in the contexts of different countries is necessary.},
	language = {en},
	number = {4},
	urldate = {2023-03-27},
	journal = {Educational Management Administration \& Leadership},
	author = {Oldac, Yusuf Ikbal and Kondakci, Yasar},
	month = jul,
	year = {2020},
	note = {Publisher: SAGE Publications Ltd},
	pages = {762--780},
	file = {Oldac and Kondakci - 2020 - Multilevel analysis of the relationship between sc.pdf:/Users/isabelleborucki/Zotero/storage/KBDRGJCJ/Oldac and Kondakci - 2020 - Multilevel analysis of the relationship between sc.pdf:application/pdf},
}

@article{scheuring_effect_2020,
	title = {The {Effect} of {Fixed}-{Term} {Employment} on {Well}-{Being}: {Disentangling} the {Micro}-{Mechanisms} and the {Moderating} {Role} of {Social} {Cohesion}},
	volume = {152},
	issn = {1573-0921},
	shorttitle = {The {Effect} of {Fixed}-{Term} {Employment} on {Well}-{Being}},
	url = {https://doi.org/10.1007/s11205-020-02421-9},
	doi = {10.1007/s11205-020-02421-9},
	abstract = {This paper examines the impact of fixed-term employment on well-being from a cross-national comparative perspective by testing (1) the effect heterogeneity across European countries, (2) to which extent Jahoda’s Latent Deprivation Model provides a sufficient micro-level explanation for the underlying mechanisms and (3) whether the macro-level factor of social cohesion weakens the micro-level impacts. We investigate the effects in both an upwards (permanent employment) and a downwards (unemployment) comparative control group design. Due to the mediating role of social contacts on the micro-level, we assume social cohesion on the country-level to moderate the main effects: A high degree of societal affiliation should substitute the function of social contacts in the work environment of individuals. Using microdata from the European Social Survey (ESS) 2012 for 23 countries and applying multilevel estimation procedures, we find that there is a remarkable variation in the effects across countries. Even though in each country fixed-term employees have a lower subjective well-being compared to permanent ones, the point estimates vary from .17 to 1.19 units. When comparing fixed-term employees to unemployed individuals, the coefficients even range from − .27 to 1.25 units. More specifically, a negative effect indicates that having a fixed-term contract is worse than unemployment in some countries. Moreover, pooled linear regression models reveal that Jahoda’s Latent Deprivation Model explains about three-quarters of the micro-level effect sizes for both directions. Eventually, social cohesion on the country-level diminishes the individual-level well-being differences between fixed-term employees and permanent individuals but not between fixed-term employees and the unemployed.},
	language = {en},
	number = {1},
	urldate = {2023-03-27},
	journal = {Social Indicators Research},
	author = {Scheuring, Sonja},
	month = nov,
	year = {2020},
	keywords = {Well-being, Fixed-term employment, Mediation analysis, Multilevel estimation, Social cohesion},
	pages = {91--115},
	file = {Scheuring - 2020 - The Effect of Fixed-Term Employment on Well-Being.pdf:/Users/isabelleborucki/Zotero/storage/MGC25MYD/Scheuring - 2020 - The Effect of Fixed-Term Employment on Well-Being.pdf:application/pdf},
}

@misc{noauthor_r_nodate,
	title = {R {Bootcamp}: {Introduction} to {Multilevel} {Model} and {Interactions} {\textbar} {QuantDev} {Methodology}},
	url = {https://quantdev.ssri.psu.edu/tutorials/r-bootcamp-introduction-multilevel-model-and-interactions},
	urldate = {2023-03-27},
	file = {R Bootcamp\: Introduction to Multilevel Model and Interactions | QuantDev Methodology:/Users/isabelleborucki/Zotero/storage/422T9TII/r-bootcamp-introduction-multilevel-model-and-interactions.html:text/html},
}


@misc{noauthor_datenpolitik_nodate,
	title = {Datenpolitik, {Open} {Science} und {Dateninfrastrukturen}: {Aktuelle} {Entwicklungen} im europäischen {Raum} – {Juli} 2022},
	shorttitle = {Datenpolitik, {Open} {Science} und {Dateninfrastrukturen}},
	url = {https://rfii.de/download/datenpolitik-open-science-und-dateninfrastrukturen-aktuelle-entwicklungen-im-europaeischen-raum-juli-2022/},
	abstract = {RfII-Fachbericht zu aktuellen Entwicklungen im europäischen Raum – Juli 2022   Der RfII hat aktuelle Initiativen zum Aufbau von Informations- […]},
	language = {en-GB},
	urldate = {2022-10-22},
	journal = {RfII},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/H7XATAYB/datenpolitik-open-science-und-dateninfrastrukturen-aktuelle-entwicklungen-im-europaeischen-raum.html:text/html},
}

@book{debruine_overview_nodate,
	title = {Overview {\textbar} {Data} visualisation using {R}, for researchers who don’t use {R}},
	url = {https://psyteachr.github.io/introdataviz},
	abstract = {In this tutorial, we provide a practical introduction to data visualisation using R, specifically aimed at researchers who have little to no prior experience of using R.},
	language = {en},
	urldate = {2022-04-29},
	author = {DeBruine, Phil McAleer, Wilhelmiina Toivo, Helena Paterson, Lisa, Emily Nordmann},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/AIKJGNUK/index.html:text/html},
}

@misc{noauthor_moving_nodate,
	title = {Moving from {Beamer} to {R} {Markdown}},
	url = {https://rmarkdown.rstudio.com/articles_beamer.html},
	urldate = {2022-04-08},
	file = {Moving from Beamer to R Markdown:/Users/isabelleborucki/Zotero/storage/9Z8GB32B/articles_beamer.html:text/html},
}

@misc{atteveldt_learning_2021,
	title = {Learning {R}},
	url = {https://github.com/vanatteveldt/learningr},
	abstract = {Helpful resources for learning R},
	urldate = {2022-04-06},
	author = {Atteveldt, Wouter van},
	month = may,
	year = {2021},
	note = {original-date: 2014-06-05T21:05:03Z},
}

@misc{villafane_learning_2021,
	title = {Learning {R} - {Resources}},
	url = {https://github.com/data-datum/learning_R},
	abstract = {List of resources for learning R},
	urldate = {2022-04-06},
	author = {Villafañe, Roxana Noelia},
	month = jul,
	year = {2021},
	note = {original-date: 2018-09-24T23:52:45Z},
	keywords = {books, data-manipulation, data-visualization, datatable, dplyr, functions, ggplot2, purrr, r, r-programming, r-spatial, reproducible-research, rmarkdown, rstudio, shiny, shiny-apps, strings, strings-manipulation, tidyr, webinars},
}

@article{vaida_conditional_2005,
	title = {Conditional {Akaike} information for mixed-effects models},
	volume = {92},
	issn = {1464-3510, 0006-3444},
	url = {http://academic.oup.com/biomet/article/92/2/351/233128/Conditional-Akaike-information-for-mixedeffects},
	doi = {10.1093/biomet/92.2.351},
	language = {en},
	number = {2},
	urldate = {2021-05-25},
	journal = {Biometrika},
	author = {Vaida, Florin and Blanchard, Suzette},
	month = jun,
	year = {2005},
	pages = {351--370},
}

@article{richards_testing_2005,
	title = {{TESTING} {ECOLOGICAL} {THEORY} {USING} {THE} {INFORMATION}-{THEORETIC} {APPROACH}: {EXAMPLES} {AND} {CAUTIONARY} {RESULTS}},
	volume = {86},
	issn = {0012-9658},
	shorttitle = {{TESTING} {ECOLOGICAL} {THEORY} {USING} {THE} {INFORMATION}-{THEORETIC} {APPROACH}},
	url = {http://doi.wiley.com/10.1890/05-0074},
	doi = {10.1890/05-0074},
	language = {en},
	number = {10},
	urldate = {2021-05-25},
	journal = {Ecology},
	author = {Richards, Shane A.},
	month = oct,
	year = {2005},
	pages = {2805--2814},
}

@misc{noauthor_stargazer_nodate,
	title = {Stargazer},
	url = {https://www.jakeruss.com/cheatsheets/stargazer/#change-the-column-names},
	urldate = {2021-05-15},
	file = {Stargazer:/Users/isabelleborucki/Zotero/storage/3BV5956L/stargazer.html:text/html},
}

@article{ludecke_performance_2021,
	title = {performance: {An} {R} {Package} for {Assessment}, {Comparison} and {Testing} of {Statistical} {Models}},
	volume = {6},
	issn = {2475-9066},
	shorttitle = {performance},
	url = {https://joss.theoj.org/papers/10.21105/joss.03139},
	doi = {10.21105/joss.03139},
	abstract = {Lüdecke et al., (2021). performance: An R Package for Assessment, Comparison and Testing of Statistical Models. Journal of Open Source Software, 6(60), 3139, https://doi.org/10.21105/joss.03139},
	language = {en},
	number = {60},
	urldate = {2021-05-15},
	journal = {Journal of Open Source Software},
	author = {Lüdecke, Daniel and Ben-Shachar, Mattan S. and Patil, Indrajeet and Waggoner, Philip and Makowski, Dominique},
	month = apr,
	year = {2021},
	pages = {3139},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/4ZQ9SG3J/Lüdecke et al. - 2021 - performance An R Package for Assessment, Comparis.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/4TEAXWNG/joss.html:text/html},
}

@misc{casallas_casallasrsquaredglmer_2020,
	title = {casallas/rsquared.glmer},
	url = {https://github.com/casallas/rsquared.glmer},
	abstract = {R2 for generalized linear mixed effects models. Contribute to casallas/rsquared.glmer development by creating an account on GitHub.},
	urldate = {2021-05-15},
	author = {Casallas, Juan Sebastián},
	month = mar,
	year = {2020},
	note = {original-date: 2014-01-22T13:24:34Z},
}

@misc{noauthor_matplotlib_nodate,
	title = {matplotlib – mehr als eine {2D} {Diagramm} {Bibliothek} in {Python}},
	url = {https://www.python-lernen.de/bibliothek-matplotlib.htm},
	abstract = {Die Python-Bibliothek matplotlib kann jede Form von Diagrammen erzeugen. Diese können angezeigt oder als Grafik gespeichert werden.},
	language = {de},
	urldate = {2021-03-04},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/G9ZFESJH/bibliothek-matplotlib.html:text/html},
}

@misc{jan_15_vincent_nodate,
	title = {Vincent {Arel}-{Bundock}: {Marginal} {Structural} {Models}: {A} {Simulation} {With} `{R}` and `data.table`},
	shorttitle = {Vincent {Arel}-{Bundock}},
	url = {http://arelbundock.com/posts/marginal_structural_models/},
	urldate = {2021-02-10},
	journal = {Vincent Arel-Bundock},
	author = {Jan. 15, Author Affiliation Vincent Arel-Bundock Published and Doi, 2021},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/CGNINLDQ/marginal_structural_models.html:text/html},
}

@misc{noauthor_mixed_nodate,
	title = {Mixed {Models}: {Testing} {Significance} of {Effects}},
	url = {https://www.ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html#testing-mixed-models-parameters},
	urldate = {2020-12-24},
	file = {Mixed Models\: Testing Significance of Effects:/Users/isabelleborucki/Zotero/storage/HSTXBZZH/MM_TestEffects.html:text/html},
}

@article{xu_measuring_2003,
	title = {Measuring explained variation in linear mixed effects models},
	volume = {22},
	issn = {0277-6715, 1097-0258},
	url = {http://doi.wiley.com/10.1002/sim.1572},
	doi = {10.1002/sim.1572},
	language = {en},
	number = {22},
	urldate = {2020-12-24},
	journal = {Statistics in Medicine},
	author = {Xu, Ronghui},
	month = nov,
	year = {2003},
	pages = {3527--3541},
}

@article{wolfinger_generalized_1993,
	title = {Generalized linear mixed models a pseudo-likelihood approach},
	volume = {48},
	issn = {0094-9655, 1563-5163},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00949659308811554},
	doi = {10.1080/00949659308811554},
	language = {en},
	number = {3-4},
	urldate = {2020-12-24},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Wolfinger, Russ and O'connell, Michael},
	month = dec,
	year = {1993},
	pages = {233--243},
}

@article{warton_many_2005,
	title = {Many zeros does not mean zero inflation: comparing the goodness-of-fit of parametric models to multivariate abundance data},
	volume = {16},
	issn = {1180-4009, 1099-095X},
	shorttitle = {Many zeros does not mean zero inflation},
	url = {http://doi.wiley.com/10.1002/env.702},
	doi = {10.1002/env.702},
	language = {en},
	number = {3},
	urldate = {2020-12-24},
	journal = {Environmetrics},
	author = {Warton, David I.},
	month = may,
	year = {2005},
	pages = {275--289},
}

@article{stroup_rethinking_2015,
	title = {Rethinking the {Analysis} of {Non}-{Normal} {Data} in {Plant} and {Soil} {Science}},
	volume = {107},
	issn = {00021962},
	url = {http://doi.wiley.com/10.2134/agronj2013.0342},
	doi = {10.2134/agronj2013.0342},
	language = {en},
	number = {2},
	urldate = {2020-12-24},
	journal = {Agronomy Journal},
	author = {Stroup, Walter W.},
	month = mar,
	year = {2015},
	pages = {811--827},
}

@article{snijders_standard_1993,
	title = {Standard {Errors} and {Sample} {Sizes} for {Two}-{Level} {Research}},
	volume = {18},
	issn = {03629791},
	url = {https://www.jstor.org/stable/1165134?origin=crossref},
	doi = {10.2307/1165134},
	number = {3},
	urldate = {2020-12-24},
	journal = {Journal of Educational Statistics},
	author = {Snijders, Tom A. B. and Bosker, Roel J.},
	year = {1993},
	pages = {237},
	file = {Submitted Version:/Users/isabelleborucki/Zotero/storage/929PP82J/Snijders and Bosker - 1993 - Standard Errors and Sample Sizes for Two-Level Res.pdf:application/pdf},
}

@article{self_asymptotic_1987,
	title = {Asymptotic {Properties} of {Maximum} {Likelihood} {Estimators} and {Likelihood} {Ratio} {Tests} under {Nonstandard} {Conditions}},
	volume = {82},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1987.10478472},
	doi = {10.1080/01621459.1987.10478472},
	language = {en},
	number = {398},
	urldate = {2020-12-24},
	journal = {Journal of the American Statistical Association},
	author = {Self, Steven G. and Liang, Kung-Yee},
	month = jun,
	year = {1987},
	pages = {605--610},
}

@article{schielzeth_simple_2010,
	title = {Simple means to improve the interpretability of regression coefficients: \textit{{Interpretation} of regression coefficients}},
	volume = {1},
	issn = {2041210X},
	shorttitle = {Simple means to improve the interpretability of regression coefficients},
	url = {http://doi.wiley.com/10.1111/j.2041-210X.2010.00012.x},
	doi = {10.1111/j.2041-210X.2010.00012.x},
	language = {en},
	number = {2},
	urldate = {2020-12-24},
	journal = {Methods in Ecology and Evolution},
	author = {Schielzeth, Holger},
	month = jun,
	year = {2010},
	pages = {103--113},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/SHMRAVAR/Schielzeth - 2010 - Simple means to improve the interpretability of re.pdf:application/pdf},
}

@article{pasch_interspecific_2013,
	title = {Interspecific {Dominance} {Via} {Vocal} {Interactions} {Mediates} {Altitudinal} {Zonation} in {Neotropical} {Singing} {Mice}},
	volume = {182},
	issn = {0003-0147, 1537-5323},
	url = {https://www.journals.uchicago.edu/doi/10.1086/673263},
	doi = {10.1086/673263},
	language = {en},
	number = {5},
	urldate = {2020-12-24},
	journal = {The American Naturalist},
	author = {Pasch, Bret and Bolker, Benjamin M. and Phelps, Steven M.},
	month = nov,
	year = {2013},
	pages = {E161--E173},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/AKYZP7DW/Pasch et al. - 2013 - Interspecific Dominance Via Vocal Interactions Med.pdf:application/pdf},
}

@article{nakagawa_repeatability_2010,
	title = {Repeatability for {Gaussian} and non-{Gaussian} data: a practical guide for biologists},
	issn = {14647931, 1469185X},
	shorttitle = {Repeatability for {Gaussian} and non-{Gaussian} data},
	url = {http://doi.wiley.com/10.1111/j.1469-185X.2010.00141.x},
	doi = {10.1111/j.1469-185X.2010.00141.x},
	language = {en},
	urldate = {2020-12-24},
	journal = {Biological Reviews},
	author = {Nakagawa, Shinichi and Schielzeth, Holger},
	month = jun,
	year = {2010},
	pages = {no--no},
}

@article{mcculloch_misspecifying_2011,
	title = {Misspecifying the {Shape} of a {Random} {Effects} {Distribution}: {Why} {Getting} {It} {Wrong} {May} {Not} {Matter}},
	volume = {26},
	issn = {0883-4237},
	shorttitle = {Misspecifying the {Shape} of a {Random} {Effects} {Distribution}},
	url = {http://projecteuclid.org/euclid.ss/1320066927},
	doi = {10.1214/11-STS361},
	language = {en},
	number = {3},
	urldate = {2020-12-24},
	journal = {Statistical Science},
	author = {McCulloch, Charles E. and Neuhaus, John M.},
	month = aug,
	year = {2011},
	pages = {388--402},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/I4RU5EPH/McCulloch and Neuhaus - 2011 - Misspecifying the Shape of a Random Effects Distri.pdf:application/pdf},
}

@article{matuschek_balancing_2017,
	title = {Balancing {Type} {I} error and power in linear mixed models},
	volume = {94},
	issn = {0749596X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X17300013},
	doi = {10.1016/j.jml.2017.01.001},
	language = {en},
	urldate = {2020-12-24},
	journal = {Journal of Memory and Language},
	author = {Matuschek, Hannes and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald and Bates, Douglas},
	month = jun,
	year = {2017},
	pages = {305--315},
	file = {Submitted Version:/Users/isabelleborucki/Zotero/storage/PQCJUBDE/Matuschek et al. - 2017 - Balancing Type I error and power in linear mixed m.pdf:application/pdf},
}

@article{martin_zero_2005,
	title = {Zero tolerance ecology: improving ecological inference by modelling the source of zero observations: {Modelling} excess zeros in ecology},
	volume = {8},
	issn = {1461023X},
	shorttitle = {Zero tolerance ecology},
	url = {http://doi.wiley.com/10.1111/j.1461-0248.2005.00826.x},
	doi = {10.1111/j.1461-0248.2005.00826.x},
	language = {en},
	number = {11},
	urldate = {2020-12-24},
	journal = {Ecology Letters},
	author = {Martin, Tara G. and Wintle, Brendan A. and Rhodes, Jonathan R. and Kuhnert, Petra M. and Field, Scott A. and Low-Choy, Samantha J. and Tyre, Andrew J. and Possingham, Hugh P.},
	month = nov,
	year = {2005},
	pages = {1235--1246},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/BV4DZWTV/Martin et al. - 2005 - Zero tolerance ecology improving ecological infer.pdf:application/pdf},
}

@article{lo_transform_2015,
	title = {To transform or not to transform: using generalized linear mixed models to analyse reaction time data},
	volume = {6},
	issn = {1664-1078},
	shorttitle = {To transform or not to transform},
	url = {http://journal.frontiersin.org/Article/10.3389/fpsyg.2015.01171/abstract},
	doi = {10.3389/fpsyg.2015.01171},
	urldate = {2020-12-24},
	journal = {Frontiers in Psychology},
	author = {Lo, Steson and Andrews, Sally},
	month = aug,
	year = {2015},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/NVTCZTAH/Lo and Andrews - 2015 - To transform or not to transform using generalize.pdf:application/pdf},
}

@article{kain_practical_2015,
	title = {A practical guide and power analysis for {GLMMs}: detecting among treatment variation in random effects},
	volume = {3},
	issn = {2167-8359},
	shorttitle = {A practical guide and power analysis for {GLMMs}},
	url = {https://peerj.com/articles/1226},
	doi = {10.7717/peerj.1226},
	abstract = {In ecology and evolution generalized linear mixed models (GLMMs) are becoming increasingly used to test for differences in variation by treatment at multiple hierarchical levels. Yet, the specific sampling schemes that optimize the power of an experiment to detect differences in random effects by treatment/group remain unknown. In this paper we develop a blueprint for conducting power analyses for GLMMs focusing on detecting differences in variance by treatment. We present parameterization and power analyses for random-intercepts and random-slopes GLMMs because of their generality as focal parameters for most applications and because of their immediate applicability to emerging questions in the field of behavioral ecology. We focus on the extreme case of hierarchically structured binomial data, though the framework presented here generalizes easily to any error distribution model. First, we determine the optimal ratio of individuals to repeated measures within individuals that maximizes power to detect differences by treatment in among-individual variation in intercept, among-individual variation in slope, and within-individual variation in intercept. Second, we explore how power to detect differences in target variance parameters is affected by total variation. Our results indicate heterogeneity in power across ratios of individuals to repeated measures with an optimal ratio determined by both the target variance parameter and total sample size. Additionally, power to detect each variance parameter was low overall (in most cases {\textgreater}1,000 total observations per treatment needed to achieve 80\% power) and decreased with increasing variance in non-target random effects. With growing interest in variance as the parameter of inquiry, these power analyses provide a crucial component for designing experiments focused on detecting differences in variance. We hope to inspire novel experimental designs in ecology and evolution investigating the causes and implications of individual-level phenotypic variance, such as the adaptive significance of within-individual variation.},
	language = {en},
	urldate = {2020-12-24},
	journal = {PeerJ},
	author = {Kain, Morgan P. and Bolker, Ben M. and McCoy, Michael W.},
	month = sep,
	year = {2015},
	pages = {e1226},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/3Z4ADKCA/Kain et al. - 2015 - A practical guide and power analysis for GLMMs de.pdf:application/pdf},
}

@article{johnson_extension_2014,
	title = {Extension of {Nakagawa} \& {Schielzeth}'s \textit{{R}} $^{\textrm{2}}$ $_{\textrm{{GLMM}}}$ to random slopes models},
	volume = {5},
	issn = {2041210X},
	url = {http://doi.wiley.com/10.1111/2041-210X.12225},
	doi = {10.1111/2041-210X.12225},
	language = {en},
	number = {9},
	urldate = {2020-12-24},
	journal = {Methods in Ecology and Evolution},
	author = {Johnson, Paul C.D.},
	editor = {O'Hara, Robert B.},
	month = sep,
	year = {2014},
	pages = {944--946},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/AN4AZ8FD/Johnson - 2014 - Extension of Nakagawa & Schielzeth's R sup.pdf:application/pdf},
}

@article{harrison_comparison_2015,
	title = {A comparison of observation-level random effect and {Beta}-{Binomial} models for modelling overdispersion in {Binomial} data in ecology \& evolution},
	volume = {3},
	issn = {2167-8359},
	url = {https://peerj.com/articles/1114},
	doi = {10.7717/peerj.1114},
	language = {en},
	urldate = {2020-12-24},
	journal = {PeerJ},
	author = {Harrison, Xavier A.},
	month = jul,
	year = {2015},
	pages = {e1114},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/IS2SHNLP/Harrison - 2015 - A comparison of observation-level random effect an.pdf:application/pdf},
}

@article{gelman_bayesian_2006,
	title = {Bayesian {Measures} of {Explained} {Variance} and {Pooling} in {Multilevel} ({Hierarchical}) {Models}},
	volume = {48},
	issn = {0040-1706, 1537-2723},
	url = {http://www.tandfonline.com/doi/abs/10.1198/004017005000000517},
	doi = {10.1198/004017005000000517},
	language = {en},
	number = {2},
	urldate = {2020-12-24},
	journal = {Technometrics},
	author = {Gelman, Andrew and Pardoe, Iain},
	month = may,
	year = {2006},
	pages = {241--251},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/9QXLAVLD/Gelman and Pardoe - 2006 - Bayesian Measures of Explained Variance and Poolin.pdf:application/pdf},
}

@article{gelman_scaling_2008,
	title = {Scaling regression inputs by dividing by two standard deviations},
	volume = {27},
	issn = {02776715, 10970258},
	url = {http://doi.wiley.com/10.1002/sim.3107},
	doi = {10.1002/sim.3107},
	language = {en},
	number = {15},
	urldate = {2020-12-24},
	journal = {Statistics in Medicine},
	author = {Gelman, Andrew},
	month = jul,
	year = {2008},
	pages = {2865--2873},
}

@article{gelman_analysis_2005,
	title = {Analysis of variance—why it is more important than ever},
	volume = {33},
	issn = {0090-5364},
	url = {https://projecteuclid.org/euclid.aos/1112967698},
	doi = {10.1214/009053604000001048},
	language = {en},
	number = {1},
	urldate = {2020-12-24},
	journal = {The Annals of Statistics},
	author = {Gelman, Andrew},
	month = feb,
	year = {2005},
	pages = {1--53},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/ZHV5U5XB/Gelman - 2005 - Analysis of variance—why it is more important than.pdf:application/pdf},
}

@article{chung_nondegenerate_2013,
	title = {A {Nondegenerate} {Penalized} {Likelihood} {Estimator} for {Variance} {Parameters} in {Multilevel} {Models}},
	volume = {78},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/s11336-013-9328-2},
	doi = {10.1007/s11336-013-9328-2},
	language = {en},
	number = {4},
	urldate = {2020-12-24},
	journal = {Psychometrika},
	author = {Chung, Yeojin and Rabe-Hesketh, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
	month = oct,
	year = {2013},
	pages = {685--709},
}

@article{browne_variance_2005,
	title = {Variance partitioning in multilevel logistic models that exhibit overdispersion},
	volume = {168},
	issn = {0964-1998, 1467-985X},
	url = {http://doi.wiley.com/10.1111/j.1467-985X.2004.00365.x},
	doi = {10.1111/j.1467-985X.2004.00365.x},
	language = {en},
	number = {3},
	urldate = {2020-12-24},
	journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Browne, W. J. and Subramanian, S. V. and Jones, K. and Goldstein, H.},
	month = jul,
	year = {2005},
	pages = {599--613},
}

@article{bell_small_2011,
	title = {Small sample estimation properties of longitudinal count models},
	volume = {81},
	issn = {0094-9655, 1563-5163},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00949651003674144},
	doi = {10.1080/00949651003674144},
	language = {en},
	number = {9},
	urldate = {2020-12-24},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Bell, Melanie L. and Grunwald, Gary K.},
	month = sep,
	year = {2011},
	pages = {1067--1079},
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} \textbf{lme4}},
	volume = {67},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v67/i01/},
	doi = {10.18637/jss.v067.i01},
	language = {en},
	number = {1},
	urldate = {2020-12-24},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	year = {2015},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/M3VRLU5E/Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using lme4.pdf:application/pdf},
}

@article{barr_random_2013,
	title = {Random effects structure for confirmatory hypothesis testing: {Keep} it maximal},
	volume = {68},
	issn = {0749596X},
	shorttitle = {Random effects structure for confirmatory hypothesis testing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X12001180},
	doi = {10.1016/j.jml.2012.11.001},
	language = {en},
	number = {3},
	urldate = {2020-12-24},
	journal = {Journal of Memory and Language},
	author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
	month = apr,
	year = {2013},
	pages = {255--278},
	file = {Accepted Version:/Users/isabelleborucki/Zotero/storage/IWSZPG6M/Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf:application/pdf},
}

@inproceedings{giglietto_coordinated_2020,
	address = {Toronto ON Canada},
	title = {Coordinated {Link} {Sharing} {Behavior} as a {Signal} to {Surface} {Sources} of {Problematic} {Information} on {Facebook}},
	isbn = {978-1-4503-7688-4},
	url = {https://dl.acm.org/doi/10.1145/3400806.3400817},
	doi = {10.1145/3400806.3400817},
	language = {en},
	urldate = {2020-12-21},
	booktitle = {International {Conference} on {Social} {Media} and {Society}},
	publisher = {ACM},
	author = {Giglietto, Fabio and Righetti, Nicola and Rossi, Luca and Marino, Giada},
	month = jul,
	year = {2020},
	pages = {85--91},
}

@techreport{giglietto_understanding_2019,
	type = {preprint},
	title = {Understanding {Coordinated} and {Inauthentic} {Link} {Sharing} {Behavior} on {Facebook} in the {Run}-up to 2018 {General} {Election} and 2019 {European} {Election} in {Italy}},
	url = {https://osf.io/3jteh},
	abstract = {The year 2016 marked a turning point in the history of relations between the Internet, social media, public opinion, and politics. Online practices of grassroots participation, which used to be considered the prerogative of democratizing forces fighting established powers, turned out to be an effective platform for far-right extremists. In the attempt to make sense of what happened and develop workable solutions, stakeholders rapidly moved through the different stages of grief, ranging from denial to anger and acceptance.As a case in point, we trace the path through these stages which moved from an initial denial of the problem to concern over “fake news” and hoaxes, to finally focusing on the behavior of certain actors on the platform. Starting from the current phase, we analyze “coordinated inauthentic behavior”, a concept only briefly defined in Facebook public statements which, nevertheless, is useful to frame future studies insofar as both the idea of coordination and authenticity have been studied in the literature. Leveraging these works, we suggest a definition that is at once framed in this literature and easy to operationalize.Using this definition and an unprecedented combination of CrowdTangle API (a tool for accessing Facebook and other social media data) and two datasets of Italian political news stories published in the run-up to the 2018 Italian general election and 2019 European election, we developed a method that led to the identification of several networks of pages/groups/verified public profiles (“entities”) that shared the same political news stories on Facebook within a very short period of time (10 in 2018, composed of 28 entities, and 50 in 2019, composed of 143 entities). We call this behavior “coordinated link sharing”. By analyzing the social media profiles of such coordinated entities, we observed that while some of them were clearly political, others presented themselves as entertainment venues, despite sharing political content too. Since the political news stories shared by these non-political entities can reach a broad audience which is largely unguarded against attempts to influence, we describe their behavior as “inauthentic”.Further analyses showed that the news shared by the coordinated networks received a Facebook engagement higher than other news included in our dataset, that much news boosted anti-immigration and far-right propaganda and that several of the news outlets shared by these networks were already blacklisted by fact-checkers.},
	urldate = {2020-12-21},
	institution = {SocArXiv},
	author = {Giglietto, Fabio and Righetti, Nicola and Marino, Giada},
	month = sep,
	year = {2019},
	doi = {10.31235/osf.io/3jteh},
}

@article{giglietto_it_2020,
	title = {It takes a village to manipulate the media: coordinated link sharing behavior during 2018 and 2019 {Italian} elections},
	volume = {23},
	issn = {1369-118X, 1468-4462},
	shorttitle = {It takes a village to manipulate the media},
	url = {https://www.tandfonline.com/doi/full/10.1080/1369118X.2020.1739732},
	doi = {10.1080/1369118X.2020.1739732},
	language = {en},
	number = {6},
	urldate = {2020-12-21},
	journal = {Information, Communication \& Society},
	author = {Giglietto, Fabio and Righetti, Nicola and Rossi, Luca and Marino, Giada},
	month = may,
	year = {2020},
	pages = {867--891},
}

@misc{noauthor_what_nodate,
	title = {What is pushshift.io},
	url = {https://pushshift.io/what-is-pushshift-io/},
	abstract = {This site is maintained by Jason Baumgartner and contains various articles relating to big data, social media ingest and analysis and general technology trends.},
	language = {en-US},
	urldate = {2020-12-21},
	journal = {pushshift.io},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/KW9HI9B2/what-is-pushshift-io.html:text/html},
}

@misc{noauthor_recal_nodate,
	title = {{ReCal}: reliability calculation for the masses – {Deen} {Freelon}, {Ph}.{D}.},
	url = {http://dfreelon.org/utils/recalfront},
	urldate = {2020-12-21},
	file = {ReCal\: reliability calculation for the masses – Deen Freelon, Ph.D.:/Users/isabelleborucki/Zotero/storage/LIQYWVVW/recalfront.html:text/html},
}

@article{von_eye_alternative_2006,
	title = {An {Alternative} to {Cohen}'s κ},
	volume = {11},
	issn = {1016-9040, 1878-531X},
	url = {https://econtent.hogrefe.com/doi/10.1027/1016-9040.11.1.12},
	doi = {10.1027/1016-9040.11.1.12},
	abstract = {At the level of manifest categorical variables, a large number of coefficients and models for the examination of rater agreement has been proposed and used. The most popular of these is Cohen's κ. In this article, a new coefficient, κ
              s
              , is proposed as an alternative measure of rater agreement. Both κ and κ
              s
              allow researchers to determine whether agreement in groups of two or more raters is significantly beyond chance. Stouffer's z is used to test the null hypothesis that κ
              s
              = 0. The coefficient κ
              s
              allows one, in addition to evaluating rater agreement in a fashion parallel to κ, to (1) examine subsets of cells in agreement tables, (2) examine cells that indicate disagreement, (3) consider alternative chance models, (4) take covariates into account, and (5) compare independent samples. Results from a simulation study are reported, which suggest that (a) the four measures of rater agreement, Cohen's κ, Brennan and Prediger's κ
              n
              , raw agreement, and κ
              s
              are sensitive to the same data characteristics when evaluating rater agreement and (b) both the z-statistic for Cohen's κ and Stouffer's z for κ
              s
              are unimodally and symmetrically distributed, but slightly heavy-tailed. Examples use data from verbal processing and applicant selection.},
	language = {en},
	number = {1},
	urldate = {2020-12-21},
	journal = {European Psychologist},
	author = {von Eye, Alexander},
	month = jan,
	year = {2006},
	pages = {12--24},
}

@article{brennan_coefficient_1981,
	title = {Coefficient {Kappa}: {Some} {Uses}, {Misuses}, and {Alternatives}},
	volume = {41},
	issn = {0013-1644, 1552-3888},
	shorttitle = {Coefficient {Kappa}},
	url = {http://journals.sagepub.com/doi/10.1177/001316448104100307},
	doi = {10.1177/001316448104100307},
	language = {en},
	number = {3},
	urldate = {2020-12-21},
	journal = {Educational and Psychological Measurement},
	author = {Brennan, Robert L. and Prediger, Dale J.},
	month = oct,
	year = {1981},
	pages = {687--699},
}

@article{fleiss_measuring_1971,
	title = {Measuring nominal scale agreement among many raters.},
	volume = {76},
	issn = {0033-2909},
	url = {http://content.apa.org/journals/bul/76/5/378},
	doi = {10.1037/h0031619},
	language = {en},
	number = {5},
	urldate = {2020-12-21},
	journal = {Psychological Bulletin},
	author = {Fleiss, Joseph L.},
	year = {1971},
	pages = {378--382},
}

@misc{statistics_of_doom_r_2019,
	title = {R - {Binary} {Logistic} {Multilevel} {Models}},
	url = {https://www.youtube.com/watch?v=6MexZiX-2W8},
	abstract = {Lecturer: Dr. Erin M. Buchanan
Harrisburg University of Science and Technology
Fall 2019

This video covers binary logistic regression + multilevel models in R using glmer and the lme4 package. I cover an example of a project that our research lab has under review. We talk about assumptions, visualize the data, and then run through a logistic regression: null model no predictors, null model with random intercepts, fixed effects and random intercepts, and a full model of random intercepts/slopes and fixed effects.

There are links to other materials provided in the video, but go here https://osf.io/2zq9d/​ to find the markdown so you can have those links fully.},
	urldate = {2021-02-01},
	author = {{Statistics of DOOM}},
	month = apr,
	year = {2019},
}

@article{stoetzer_how_2020,
	title = {How {Parties} {React} to {Voter} {Transitions}},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HULLNG},
	doi = {10.7910/DVN/HULLNG},
	abstract = {Replication Material for How Parties React to Voter Transitions. Please read README},
	language = {en},
	urldate = {2021-01-28},
	author = {Stoetzer, Lukas F. and Abou-Chadi, Tarik},
	month = may,
	year = {2020},
	note = {Publisher: Harvard Dataverse
type: dataset},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/X23BQBRI/dataset.html:text/html},
}

@article{nieuwenhuis_influenceme_2012,
	title = {influence.{ME}: {Tools} for {Detecting} {Influential} {Data} in {Mixed} {Effects} {Models}},
	volume = {4},
	language = {en},
	author = {Nieuwenhuis, Rense},
	year = {2012},
	pages = {10},
	file = {Nieuwenhuis - 2012 - influence.ME Tools for Detecting Influential Data.pdf:/Users/isabelleborucki/Zotero/storage/X2SLRXSJ/Nieuwenhuis - 2012 - influence.ME Tools for Detecting Influential Data.pdf:application/pdf},
}

@misc{noauthor_twitter_nodate,
	title = {twitter - {How} to extract tweets between a certain time period in {R}?},
	url = {https://stackoverflow.com/questions/37364908/how-to-extract-tweets-between-a-certain-time-period-in-r},
	urldate = {2021-01-26},
	journal = {Stack Overflow},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/K2MTX47S/how-to-extract-tweets-between-a-certain-time-period-in-r.html:text/html},
}

@misc{walther_spearman-korrelationskoeffizient_2020,
	title = {Spearman-{Korrelationskoeffizient} in {R} berechnen},
	url = {https://www.bjoernwalther.com/spearman-korrelationskoeffizient-in-r-berechnen/},
	abstract = {Dieser Beitrag zeigt Voraussetzungen, Berechnung und Interpretation der Ergebnisse der Spearman-Korrelation in R.},
	language = {de-DE},
	urldate = {2020-11-26},
	journal = {Björn Walther},
	author = {Walther, Björn},
	month = aug,
	year = {2020},
}

@misc{noauthor_hierarchische_nodate,
	title = {Hierarchische {Lineare} {Modelle} mit {R}},
	url = {https://rstudio-pubs-static.s3.amazonaws.com/84998_fc20913e519042f0a1d22781bc34d2ea.html},
	urldate = {2020-11-26},
}

@misc{noauthor_plot_nodate,
	title = {Plot for mean comparison - {Data} {Se}},
	url = {https://data-se.netlify.app/2020/06/02/plot-for-mean-comparison/},
	language = {en-us},
	urldate = {2020-11-22},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/DNIWP4YW/plot-for-mean-comparison.html:text/html},
}

@misc{noauthor_randomization_nodate,
	title = {Randomization in presence of an interaction effect - {Data} {Se}},
	url = {https://data-se.netlify.app/2020/07/07/randomization-in-presence-of-an-interaction-effect/},
	urldate = {2020-11-22},
	file = {Randomization in presence of an interaction effect - Data Se:/Users/isabelleborucki/Zotero/storage/3Y6TY4RU/randomization-in-presence-of-an-interaction-effect.html:text/html},
}

@misc{noauthor_visualizing_nodate,
	title = {Visualizing decision trees - {Data} {Se}},
	url = {https://data-se.netlify.app/2020/10/17/visualizing-decision-trees/},
	language = {en-us},
	urldate = {2020-11-22},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/CM2NGNXC/visualizing-decision-trees.html:text/html},
}

@misc{r_r-package_nodate,
	title = {Das {R}-{Package} dplyr: {Eine} ausführliche {Anleitung} (mit vielen {Beispielen})},
	shorttitle = {Das {R}-{Package} dplyr},
	url = {https://databraineo.com/ki-training-resources/r-programmierung/das-r-package-dplyr-eine-ausfuehrliche-anleitung-mit-vielen-beispielen/},
	abstract = {Hier ist es: Ein verständliches Tutorial zum R-Package dplyr, alles verständlich erklärt und mit Code-Beispielen + das JOIN-Cheatsheet zum Herunterladen!},
	language = {de-DE},
	urldate = {2020-11-22},
	journal = {DataBraineo - Data Science Blog},
	author = {R, 17 Mai 2019 {\textbar}},
	note = {Section: R},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/5BJ7Q2CM/das-r-package-dplyr-eine-ausfuehrliche-anleitung-mit-vielen-beispielen.html:text/html},
}

@misc{noauthor_r-toolbox_nodate,
	title = {R-{Toolbox}},
	url = {https://mmi.psycho.unibas.ch/r-toolbox/index.html},
	urldate = {2020-11-20},
	file = {R-Toolbox:/Users/isabelleborucki/Zotero/storage/DTTAS7JP/index.html:text/html},
}

@article{ifes_crashkurs_nodate,
	title = {Crashkurs {Datenanalyse} mit {R}},
	language = {de},
	author = {ifes, friends (Sebastian Sauer)},
	pages = {43},
	file = {ifes - Crashkurs Datenanalyse mit R.pdf:/Users/isabelleborucki/Zotero/storage/NSVXNV5V/ifes - Crashkurs Datenanalyse mit R.pdf:application/pdf},
}

@misc{noauthor_jorge_nodate,
	title = {Jorge {Cimentada}},
	url = {https://cimentadaj.github.io/blog/2016-08-22-producing-stargazer-tables-with-odds-ratios-and-standard-errors-in-r/producing-stargazer-tables-with-odds-ratios-and-standard-errors-in-r/},
	urldate = {2020-11-17},
	file = {Jorge Cimentada:/Users/isabelleborucki/Zotero/storage/ANFVKC2A/producing-stargazer-tables-with-odds-ratios-and-standard-errors-in-r.html:text/html},
}

@misc{noauthor_introduction_nodate,
	title = {An {Introduction} to margins},
	url = {https://cran.r-project.org/web/packages/margins/vignettes/Introduction.html#using_optional_arguments_in_margins},
	urldate = {2020-11-16},
	file = {An Introduction to margins:/Users/isabelleborucki/Zotero/storage/5XU2G9Q2/Introduction.html:text/html},
}

@misc{noauthor_lieblings-r-befehle_nodate,
	title = {Lieblings-{R}-{Befehle}},
	url = {https://sebastiansauer.github.io/Lieblingsbefehle/},
	abstract = {A blog about statistics including research methods, with a focus on data analysis using R and psychology.},
	language = {en},
	urldate = {2020-11-14},
	journal = {Sebastian Sauer Stats Blog},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/MGHSMEWZ/Lieblingsbefehle.html:text/html},
}

@misc{noauthor_einfuhrung_nodate,
	title = {Einführung in die {Datenanalyse} mit {R}-{Paket} 'dplyr' - {R} {User} {Group} {Nürnberg}},
	url = {https://sebastiansauer.github.io/Datenanalyse_mit_dplyr/},
	abstract = {A blog about statistics including research methods, with a focus on data analysis using R and psychology.},
	language = {en},
	urldate = {2020-11-14},
	journal = {Sebastian Sauer Stats Blog},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/FDGUM6WK/Datenanalyse_mit_dplyr.html:text/html},
}

@misc{noauthor_how_nodate,
	title = {How can {I} subset a data set? {\textbar} {R} {FAQ}},
	url = {https://stats.idre.ucla.edu/r/faq/frequently-asked-questions-about-rhow-can-i-subset-a-data-setthe-r-program-as-a-text-file-for-all-the-code-on-this-page-subsetting-is-a-very-important-component/},
	urldate = {2020-12-14},
	file = {How can I subset a data set? | R FAQ:/Users/isabelleborucki/Zotero/storage/A8ZRD3VN/frequently-asked-questions-about-rhow-can-i-subset-a-data-setthe-r-program-as-a-text-file-for-a.html:text/html},
}

@article{austin_intermediate_2017,
	title = {Intermediate and advanced topics in multilevel logistic regression analysis},
	volume = {36},
	copyright = {© 2017 The Authors. Statistics in Medicine published by John Wiley \& Sons Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7336},
	doi = {https://doi.org/10.1002/sim.7336},
	abstract = {Multilevel data occur frequently in health services, population and public health, and epidemiologic research. In such research, binary outcomes are common. Multilevel logistic regression models allow one to account for the clustering of subjects within clusters of higher-level units when estimating the effect of subject and cluster characteristics on subject outcomes. A search of the PubMed database demonstrated that the use of multilevel or hierarchical regression models is increasing rapidly. However, our impression is that many analysts simply use multilevel regression models to account for the nuisance of within-cluster homogeneity that is induced by clustering. In this article, we describe a suite of analyses that can complement the fitting of multilevel logistic regression models. These ancillary analyses permit analysts to estimate the marginal or population-average effect of covariates measured at the subject and cluster level, in contrast to the within-cluster or cluster-specific effects arising from the original multilevel logistic regression model. We describe the interval odds ratio and the proportion of opposed odds ratios, which are summary measures of effect for cluster-level covariates. We describe the variance partition coefficient and the median odds ratio which are measures of components of variance and heterogeneity in outcomes. These measures allow one to quantify the magnitude of the general contextual effect. We describe an R2 measure that allows analysts to quantify the proportion of variation explained by different multilevel logistic regression models. We illustrate the application and interpretation of these measures by analyzing mortality in patients hospitalized with a diagnosis of acute myocardial infarction. © 2017 The Authors. Statistics in Medicine published by John Wiley \& Sons Ltd.},
	language = {en},
	number = {20},
	urldate = {2020-12-11},
	journal = {Statistics in Medicine},
	author = {Austin, Peter C. and Merlo, Juan},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7336},
	keywords = {multilevel analysis, clustered data, hierarchical models, logistic regression, multilevel models},
	pages = {3257--3277},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/M72G9S3F/Austin and Merlo - 2017 - Intermediate and advanced topics in multilevel log.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/IMBRNGCB/sim.html:text/html},
}

@misc{noauthor_mixed_nodate-1,
	title = {Mixed {Effects} {Logistic} {Regression} {\textbar} {R} {Data} {Analysis} {Examples}},
	url = {https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/},
	urldate = {2020-12-11},
	file = {Mixed Effects Logistic Regression | R Data Analysis Examples:/Users/isabelleborucki/Zotero/storage/V63WYQIZ/mixed-effects-logistic-regression.html:text/html},
}

@misc{noauthor_logistic_nodate,
	title = {Logistic {Regression} {Assumptions} and {Diagnostics} in {R} - {Articles} - {STHDA}},
	url = {http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/},
	abstract = {Statistical tools for data analysis and visualization},
	language = {en},
	urldate = {2020-12-11},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/ZRRPF3B8/148-logistic-regression-assumptions-and-diagnostics-in-r.html:text/html},
}

@misc{statacorp_llc_tour_2013,
	title = {Tour of multilevel {GLMs} in {Stata}®},
	url = {https://www.youtube.com/watch?v=SbwApki_BnI&feature=youtu.be},
	abstract = {Explore the new multilevel modeling features in Stata 13, including support for binary outcomes via logistic, probit, and complementary log-log models; support for ordinal outcomes via ordered logit and ordered probit models; support for count outcomes via Poisson and negative binomial models; and support for multilevel generalized linear models (multilevel GLMs).  Copyright 2011-2019 StataCorp LLC. All rights reserved.},
	urldate = {2020-12-08},
	author = {{StataCorp LLC}},
	month = sep,
	year = {2013},
}

@misc{noauthor_multilevel_nodate,
	title = {Multilevel ordered logistic models {\textbar} {Stata}},
	url = {https://www.stata.com/features/overview/multilevel-ordered-logistic-models/},
	urldate = {2020-12-08},
	file = {Multilevel ordered logistic models | Stata:/Users/isabelleborucki/Zotero/storage/TL7YHJXW/multilevel-ordered-logistic-models.html:text/html},
}

@incollection{urban_ml-basierte_2018,
	address = {Wiesbaden},
	series = {Studienskripten zur {Soziologie}},
	title = {{ML}-basierte {Regressionsanalyse}},
	isbn = {978-3-658-01915-0},
	url = {https://doi.org/10.1007/978-3-658-01915-0_8},
	abstract = {In den vorangegangenen Kapiteln 1 bis 7 wurden alle Regressionsschätzungen nach der OLS-Methode durchgeführt. Denn die Ordinary-Least-Squares- bzw. die Kleinst-Quadrate-Schätzmethode ist dasjenige Verfahren, mit dem optimale Schätzwerte für die Koeffizienten der Regressionsgleichung ermittelt werden können. Die OLS-Schätzung kann optimale Schätzwerte mit BLUE-Eigenschaften errechnen (vgl. dazu Kapitel 3), wenn die dafür geltenden Modellvoraussetzungen gegeben sind (z. B. die Abwesenheit von Heteroskedastizität bzw. von Streuungsungleichheit, vgl. Kapitel 4.6).},
	language = {de},
	urldate = {2020-12-07},
	booktitle = {Angewandte {Regressionsanalyse}: {Theorie}, {Technik} und {Praxis}},
	publisher = {Springer Fachmedien},
	author = {Urban, Dieter and Mayerl, Jochen},
	editor = {Urban, Dieter and Mayerl, Jochen},
	year = {2018},
	doi = {10.1007/978-3-658-01915-0_8},
	pages = {379--435},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/RFNICHBS/Urban and Mayerl - 2018 - ML-basierte Regressionsanalyse.pdf:application/pdf},
}

@article{sommet_keep_2017,
	title = {Keep {Calm} and {Learn} {Multilevel} {Logistic} {Modeling}: {A} {Simplified} {Three}-{Step} {Procedure} {Using} {Stata}, {R}, {Mplus}, and {SPSS}},
	volume = {30},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2397-8570},
	shorttitle = {Keep {Calm} and {Learn} {Multilevel} {Logistic} {Modeling}},
	url = {http://www.rips-irsp.com/articles/10.5334/irsp.90/},
	doi = {10.5334/irsp.90},
	abstract = {This paper aims to introduce multilevel logistic regression analysis in a simple and practical way. First, we introduce the basic principles of logistic regression analysis (conditional probability, logit transformation, odds ratio). Second, we discuss the two fundamental implications of running this kind of analysis with a nested data structure: In multilevel logistic regression, the odds that the outcome variable equals one (rather than zero) may vary from one cluster to another (i.e. the intercept may vary) and the effect of a lower-level variable may also vary from one cluster to another (i.e. the slope may vary). Third and finally, we provide a simplified three-step “turnkey” procedure for multilevel logistic regression modeling:

 

-Preliminary phase: Cluster- or grand-mean centering variables
-Step \#1: Running an empty model and calculating the intraclass correlation coefficient (ICC)
-Step \#2: Running a constrained and an augmented intermediate model and performing a likelihood ratio test to determine whether considering the cluster-based variation of the effect of the lower-level variable improves the model fit
-Step \#3 Running a final model and interpreting the odds ratio and confidence intervals to determine whether data support your hypothesis
 

Command syntax for Stata, R, Mplus, and SPSS are included. These steps will be applied to a study on Justin Bieber, because everybody likes Justin Bieber.1},
	language = {eng},
	number = {1},
	urldate = {2020-12-07},
	journal = {International Review of Social Psychology},
	author = {Sommet, Nicolas and Morselli, Davide},
	month = sep,
	year = {2017},
	note = {Number: 1
Publisher: Ubiquity Press},
	keywords = {Logistic regression, grand-mean centering and cluster-mean centering, intraclass correlation coefficient, Justin Bieber, likelihood ratio test and random random slope variance, multilevel logistic modeling, three-step simplified procedure},
	pages = {203--218},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/XC4FJGST/Sommet and Morselli - 2017 - Keep Calm and Learn Multilevel Logistic Modeling .pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/FUT3SD3C/irsp.90.html:text/html},
}

@techreport{elff_no_2016,
	title = {No {Need} to {Turn} {Bayesian} in {Multilevel} {Analysis} with {Few} {Clusters}: {How} {Frequentist} {Methods} {Provide} {Unbiased} {Estimates} and {Accurate} {Inference}},
	shorttitle = {No {Need} to {Turn} {Bayesian} in {Multilevel} {Analysis} with {Few} {Clusters}},
	url = {https://osf.io/preprints/socarxiv/z65s4/},
	abstract = {Comparative political science has long worried about the performance of multilevel models when the number of upper-level units is small. Exacerbating these concerns, an influential Monte Carlo study by Stegmueller (2013) suggests that frequentist methods yield biased estimates and severely anti-conservative inference with small upper-level samples. Stegmueller recommends Bayesian techniques, which he claims to be superior in terms of both bias and inferential accuracy. In this paper, we reassess and refute these results. First, we formally prove that frequentist maximum likelihood estimators of coefficients are unbiased. The apparent bias found by Stegmueller is simply a manifestation of Monte Carlo Error. Second, we show how inferential problems can be overcome by using restricted maximum likelihood estimators for variance parameters and a t-distribution with appropriate degrees of freedom for statistical inference. Thus, accurate multilevel analysis is possible without turning to Bayesian methods, even if the number of upper-level units is small.},
	urldate = {2020-12-04},
	institution = {SocArXiv},
	author = {Elff, Martin and Heisig, Jan Paul and Schaeffer, Merlin and Shikano, Susumu},
	month = dec,
	year = {2016},
	doi = {10.31235/osf.io/z65s4},
	keywords = {Sociology, Methodology, Social and Behavioral Sciences, Models and Methods, Political Science, Multilevel analysis, Economics, Psychology, Maximum Likelihood, Bayesian inference, Bias, Comparative and Historical Sociology, Econometrics, Ethnomethodology and Conservation Analysis, History of Sociology, Mathematical Sociology, Mixed Effects Models, Quantitative Psychology, SocArxiv, Social Statistics},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/LKIKNZT2/Elff et al. - 2016 - No Need to Turn Bayesian in Multilevel Analysis wi.pdf:application/pdf},
}

@article{gallagher_generalized_2021,
	title = {Generalized word shift graphs: a method for visualizing and explaining pairwise comparisons between texts},
	volume = {10},
	copyright = {2021 The Author(s)},
	issn = {2193-1127},
	shorttitle = {Generalized word shift graphs},
	url = {https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-021-00260-3},
	doi = {10.1140/epjds/s13688-021-00260-3},
	abstract = {A common task in computational text analyses is to quantify how two corpora differ according to a measurement like word frequency, sentiment, or information content. However, collapsing the texts’ rich stories into a single number is often conceptually perilous, and it is difficult to confidently interpret interesting or unexpected textual patterns without looming concerns about data artifacts or measurement validity. To better capture fine-grained differences between texts, we introduce generalized word shift graphs, visualizations which yield a meaningful and interpretable summary of how individual words contribute to the variation between two texts for any measure that can be formulated as a weighted average. We show that this framework naturally encompasses many of the most commonly used approaches for comparing texts, including relative frequencies, dictionary scores, and entropy-based measures like the Kullback–Leibler and Jensen–Shannon divergences. Through a diverse set of case studies ranging from presidential speeches to tweets posted in urban green spaces, we demonstrate how generalized word shift graphs can be flexibly applied across domains for diagnostic investigation, hypothesis generation, and substantive interpretation. By providing a detailed lens into textual shifts between corpora, generalized word shift graphs help computational social scientists, digital humanists, and other text analysis practitioners fashion more robust scientific narratives.},
	language = {en},
	number = {1},
	urldate = {2021-01-22},
	journal = {EPJ Data Science},
	author = {Gallagher, Ryan J. and Frank, Morgan R. and Mitchell, Lewis and Schwartz, Aaron J. and Reagan, Andrew J. and Danforth, Christopher M. and Dodds, Peter Sheridan},
	month = dec,
	year = {2021},
	note = {Number: 1
Publisher: SpringerOpen},
	pages = {1--29},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/6Z7QJKTY/Gallagher et al. - 2021 - Generalized word shift graphs a method for visual.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/66NAVQLH/s13688-021-00260-3.html:text/html},
}

@misc{noauthor_ggplot2_nodate,
	title = {ggplot2 axis scales and transformations - {Easy} {Guides} - {Wiki} - {STHDA}},
	url = {http://www.sthda.com/english/wiki/ggplot2-axis-scales-and-transformations},
	abstract = {Statistical tools for data analysis and visualization},
	language = {en},
	urldate = {2021-01-21},
}

@misc{hsu_caret_2021,
	title = {Caret vs {Tidymodels}: {How} to {Use} {Both} {Packages} {Together}?},
	shorttitle = {Caret vs {Tidymodels}},
	url = {https://towardsdatascience.com/caret-vs-tidymodels-how-to-use-both-packages-together-ee3f85b381c},
	abstract = {An example of using both popular machine learning packages in R to predict bike sharing demand},
	language = {en},
	urldate = {2021-01-13},
	journal = {Medium},
	author = {Hsu, Yu En},
	month = jan,
	year = {2021},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/MW6F2BKV/caret-vs-tidymodels-how-to-use-both-packages-together-ee3f85b381c.html:text/html},
}

@misc{noauthor_notitle_nodate,
	url = {https://federicovegetti.github.io/teaching/heidelberg_2018/lab/sst_lab_day2.html},
	urldate = {2021-02-27},
	file = {https\://federicovegetti.github.io/teaching/heidelberg_2018/lab/sst_lab_day2.html:/Users/isabelleborucki/Zotero/storage/YGCVDSTM/sst_lab_day2.html:text/html},
}

@misc{noauthor_create_nodate,
	title = {Create {Maps} and {Visualize} {Data} in {2D} and {3D}},
	url = {https://www.rayshader.com/},
	abstract = {Uses a combination of raytracing and multiple hill shading methods to produce 2D and 3D data visualizations and maps. Includes water detection and layering functions, programmable color palette generation, several built-in textures for hill shading, 2D and 3D plotting options, a built-in path tracer, Wavefront OBJ file export, and the ability to save 3D visualizations to a 3D printable format.},
	language = {en},
	urldate = {2021-02-25},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/ZP87546E/www.rayshader.com.html:text/html},
}

@article{brey_temporal_2018,
	title = {Temporal {Network} {Analysis} with {R}},
	url = {https://programminghistorian.org/en/lessons/temporal-network-analysis-with-r},
	language = {en},
	urldate = {2021-02-23},
	journal = {Programming Historian},
	author = {Brey, Alex},
	month = nov,
	year = {2018},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/H46V44PJ/temporal-network-analysis-with-r.html:text/html},
}

@article{mallik_dynamic_nodate,
	title = {Dynamic {Network} {Regression} {Using} {R} {Package} dnr},
	language = {en},
	author = {Mallik, Abhirup},
	pages = {21},
	file = {Mallik - Dynamic Network Regression Using R Package dnr.pdf:/Users/isabelleborucki/Zotero/storage/9HE5GQW5/Mallik - Dynamic Network Regression Using R Package dnr.pdf:application/pdf},
}

@article{ramiro_radical-left_2017,
	title = {Radical-{Left} {Populism} during the {Great} {Recession}: {Podemos} and {Its} {Competition} with the {Established} {Radical} {Left}},
	volume = {65},
	url = {http://journals.sagepub.com/doi/abs/10.1177/0032321716647400 http://journals.sagepub.com/doi/pdf/10.1177/0032321716647400},
	doi = {doi:10.1177/0032321716647400},
	abstract = {The 2008 Great Recession has altered party allegiances in many countries. This has been very visible in some of the countries hardest hit by the crisis, such as Spain. The Spanish case stands out as the only one in which a fully newly created radical-left populist party, Podemos, has attracted sizeable support. Its success is more intriguing given its capacity to attract many former supporters of the established radical left, Izquierda Unida. This article analyses what factors explain the support for the new radical-left populist party Podemos, identifying the individual-level features that lead voters to support it rather than an already established anti-austerity radical-left party. As the results show, Podemos supporters do not correspond to the conventional descriptions of populist voters, the losers of ‘globalisation' and the economic crisis. Instead, a combination of elements – protest, anti-mainstream sentiment and unfulfilled expectations – distinguishes Podemos supporters from the established radical-left electorate.},
	number = {1\_suppl},
	journal = {Political Studies},
	author = {Ramiro, Luis and Gomez, Raul},
	year = {2017},
	keywords = {political parties, populism, Spain, elec, radical left},
	pages = {108--126},
	file = {Attachment:/Users/isabelleborucki/Zotero/storage/KERXCGZK/Ramiro, Gomez - 2017 - Radical-Left Populism during the Great Recession Podemos and Its Competition with the Established Radical Left.pdf:application/pdf},
}

@misc{noauthor_intro_nodate,
	title = {Intro to {GLM}},
	url = {https://federicovegetti.github.io/teaching/ecpr_glm/index.html},
	urldate = {2021-03-01},
	file = {Intro to GLM:/Users/isabelleborucki/Zotero/storage/UT78H6F3/index.html:text/html},
}

@misc{noauthor_notitle_nodate-1,
	url = {https://federicovegetti.github.io/teaching/heidelberg_2018/lab/sst_lab_day1.html},
	urldate = {2021-03-01},
	file = {https\://federicovegetti.github.io/teaching/heidelberg_2018/lab/sst_lab_day1.html:/Users/isabelleborucki/Zotero/storage/397INKUS/sst_lab_day1.html:text/html},
}

@misc{noauthor_introduction_nodate-1,
	title = {Introduction to data analysis and graphics with {R} (2012)},
	url = {https://federicovegetti.github.io/teaching/mannheim_2012/index.html},
	urldate = {2021-02-27},
	file = {Introduction to data analysis and graphics with R (2012):/Users/isabelleborucki/Zotero/storage/7JCGX28H/index.html:text/html},
}

@article{johnson_power_2015,
	title = {Power analysis for generalized linear mixed models in ecology and evolution},
	volume = {6},
	issn = {2041-210X, 2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12306},
	doi = {10.1111/2041-210X.12306},
	language = {en},
	number = {2},
	urldate = {2021-05-25},
	journal = {Methods in Ecology and Evolution},
	author = {Johnson, Paul C. D. and Barry, Sarah J. E. and Ferguson, Heather M. and Müller, Pie},
	editor = {Schielzeth, Holger},
	month = feb,
	year = {2015},
	pages = {133--142},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/F9CIUEHZ/Johnson et al. - 2015 - Power analysis for generalized linear mixed models.pdf:application/pdf},
}

@article{nakagawa_general_2013,
	title = {A general and simple method for obtaining \textit{{R}} $^{\textrm{2}}$ from generalized linear mixed-effects models},
	volume = {4},
	issn = {2041210X},
	url = {http://doi.wiley.com/10.1111/j.2041-210x.2012.00261.x},
	doi = {10.1111/j.2041-210x.2012.00261.x},
	language = {en},
	number = {2},
	urldate = {2021-05-25},
	journal = {Methods in Ecology and Evolution},
	author = {Nakagawa, Shinichi and Schielzeth, Holger},
	editor = {O'Hara, Robert B.},
	month = feb,
	year = {2013},
	pages = {133--142},
}

@misc{tomaszwinkels_tomaszwinkelspcc_daybyday_2021,
	title = {{TomasZwinkels}/{PCC}\_daybyday},
	url = {https://github.com/TomasZwinkels/PCC_daybyday/blob/a2c91d92cc0ea30b6f7b324e1a56ec6ea1185533/fluctuation_graphs.R},
	urldate = {2021-10-03},
	author = {TomasZwinkels},
	month = aug,
	year = {2021},
	note = {original-date: 2019-05-28T14:46:21Z},
}

@article{cohen_coefficient_1960,
	title = {A {Coefficient} of {Agreement} for {Nominal} {Scales}},
	volume = {20},
	issn = {0013-1644, 1552-3888},
	url = {http://journals.sagepub.com/doi/10.1177/001316446002000104},
	doi = {10.1177/001316446002000104},
	language = {en},
	number = {1},
	urldate = {2020-12-21},
	journal = {Educational and Psychological Measurement},
	author = {Cohen, Jacob},
	month = apr,
	year = {1960},
	pages = {37--46},
	file = {Submitted Version:/Users/isabelleborucki/Zotero/storage/W48QI7QZ/Cohen - 1960 - A Coefficient of Agreement for Nominal Scales.pdf:application/pdf;Submitted Version:/Users/isabelleborucki/Zotero/storage/A9NTWZ69/Cohen - 1960 - A Coefficient of Agreement for Nominal Scales.pdf:application/pdf},
}

@article{cordeiro_note_1998,
	title = {A note on {Bartlett}-type correction for the first few moments of test statistics},
	volume = {71},
	issn = {03783758},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378375898000056},
	doi = {10.1016/S0378-3758(98)00005-6},
	language = {en},
	number = {1-2},
	urldate = {2021-05-25},
	journal = {Journal of Statistical Planning and Inference},
	author = {Cordeiro, Gauss M. and Ferrari, Silvia L.P.},
	month = aug,
	year = {1998},
	pages = {261--269},
}

@article{cordeiro_improved_1994,
	title = {Improved {Likelihood} {Ratio} {Tests} for {Dispersion} {Models}},
	volume = {62},
	issn = {03067734},
	url = {https://www.jstor.org/stable/1403512?origin=crossref},
	doi = {10.2307/1403512},
	number = {2},
	urldate = {2021-05-25},
	journal = {International Statistical Review / Revue Internationale de Statistique},
	author = {Cordeiro, Gauss M. and Paula, Gilberto A. and Botter, Denise A.},
	month = aug,
	year = {1994},
	pages = {257},
}

@misc{roos_smart_2021,
	title = {Smart handling of missing data in {R}},
	url = {https://towardsdatascience.com/smart-handling-of-missing-data-in-r-6425f8a559f2},
	abstract = {Missing data are everywhere — learn how to summarise, visualize \& impute them while keeping an eye on statistical uncertainty.},
	language = {en},
	urldate = {2022-02-27},
	journal = {Medium},
	author = {Roos, Hannah},
	month = oct,
	year = {2021},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PF5BP3ZM/smart-handling-of-missing-data-in-r-6425f8a559f2.html:text/html},
}

@misc{noauthor_r-squared_nodate,
	title = {R-squared ({R2})},
	url = {https://easystats.github.io/performance/articles/r2.html},
	abstract = {performance},
	language = {en},
	urldate = {2022-02-26},
}

@misc{noauthor_zelig_nodate,
	title = {Zelig: {Everyone}'s {Statistical} {Software}},
	shorttitle = {Zelig},
	url = {https://gking.harvard.edu/ZELIG},
	abstract = {Click here to go to the Zelig homepage.  Zelig is a general purpose statistical package built on R, with a large and diverse array of methods from all theories of inference.  All documentation follows the same style and mathematical notation so that if you understand one method, you'll be able to learn any other one easily.  Zelig commands for all models involve the same simple three commands with the same syntax.},
	language = {en},
	urldate = {2022-11-01},
}

@misc{noauthor_test_performance_nodate,
	title = {test\_performance: {Test} if models are different in performance: {Assessment} of {Regression} {Models} {Performance}},
	shorttitle = {test\_performance},
	url = {https://rdrr.io/cran/performance/man/test_performance.html},
	language = {en},
	urldate = {2022-10-31},
}

@misc{noauthor_regexr_nodate,
	title = {{RegExr}: {Learn}, {Build}, \& {Test} {RegEx}},
	shorttitle = {{RegExr}},
	url = {https://regexr.com/},
	abstract = {RegExr is an online tool to learn, build, \& test Regular Expressions (RegEx / RegExp).},
	urldate = {2022-10-14},
	journal = {RegExr},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/MD5XW6JD/regexr.com.html:text/html},
}

@book{chandra_qualitative_2019,
	address = {Singapore},
	title = {Qualitative {Research} {Using} {R}: {A} {Systematic} {Approach}},
	isbn = {9789811331695 9789811331701},
	shorttitle = {Qualitative {Research} {Using} {R}},
	url = {http://link.springer.com/10.1007/978-981-13-3170-1},
	language = {en},
	urldate = {2022-11-15},
	publisher = {Springer Singapore},
	author = {Chandra, Yanto and Shang, Liang},
	year = {2019},
	doi = {10.1007/978-981-13-3170-1},
	file = {Chandra and Shang - 2019 - Qualitative Research Using R A Systematic Approac.pdf:/Users/isabelleborucki/Zotero/storage/I36C89EX/Chandra and Shang - 2019 - Qualitative Research Using R A Systematic Approac.pdf:application/pdf},
}

@misc{noauthor_research_nodate,
	title = {Research {Methods} in {R}},
	url = {http://www.andywills.info/rminr/},
	abstract = {Research Methods in R},
	language = {en-US},
	urldate = {2022-11-17},
	journal = {rminr},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/ZR4RN4QL/rminr.html:text/html},
}

@misc{noauthor_twitters_nodate,
	title = {Twitter's automation development rules {\textbar} {Twitter} {Help}},
	url = {https://help.twitter.com/en/rules-and-policies/twitter-automation},
	abstract = {Rules and information for developers about applying automations on Twitter.},
	language = {en},
	urldate = {2022-01-24},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/44HIRVCN/twitter-automation.html:text/html},
}

@misc{noauthor_about_nodate,
	title = {About {Twitter} {\textbar} {Our} logo, brand guidelines, and {Tweet} tools},
	url = {https://about.twitter.com/en/who-we-are/brand-toolkit.html},
	abstract = {Download the Twitter logo, assets, and Twitter Brand Guidelines — and learn how to embed a Tweet on your website.},
	language = {en},
	urldate = {2022-01-24},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/WLYV6BGG/brand-toolkit.html:text/html},
}

@misc{noauthor_display_nodate,
	title = {Display requirements – {Twitter} {Developers}},
	url = {https://developer.twitter.com/en/developer-terms/display-requirements},
	abstract = {Tweets are one of our most visible brand elements, so it’s important that they are presented correctly. You should comply with the display requirements below when you display Tweets, timelines, and other Twitter content.},
	language = {en},
	urldate = {2022-01-24},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/R38U8QTZ/display-requirements.html:text/html},
}

@misc{noauthor_developer_nodate,
	title = {Developer {Policy} – {Twitter} {Developers}},
	url = {https://developer.twitter.com/en/developer-terms/policy},
	abstract = {Developer Policy – Twitter Developers. In addition to the Developer Agreement, this Developer Policy (“Policy”) provides rules and guidelines for developers who interact with Twitter’s ecosystem of applications, services, website, web pages and content including any content that we may make available through our other covered services set forth at https://support.twitter.com/articles/20172501 (“Twitter Services”). Policy violations are also considered violations of the Developer Agreement. Take a look at the Definitions for the meaning of capitalized words used in this Policy. These policies may be changed from time to time without notice. Please check here for any updates.},
	language = {en},
	urldate = {2022-01-24},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/67JQTBLS/policy.html:text/html},
}

@incollection{zorell_revising_2019,
	address = {Cham},
	title = {Revising {Our} {Understanding} of {Political} {Consumerism}},
	isbn = {978-3-319-91047-5},
	url = {https://doi.org/10.1007/978-3-319-91047-5_1},
	abstract = {In this chapter the author describes the context in which political consumerism has been gaining its impressive relevance as a mode of political participation. In particular, she points to the important differences in and across countries in boycotting and buycotting involvement. The author proposes that these differences are connected to individual and cross-national preferences for how socio-political and economic concerns ought to be tackled. Such preferences vary and give rise to different patterns in labelling schemes and Corporate Social Responsibility (CSR) presence. These, in turn, will affect whether citizens become boycotters and/or buycotters. Thus, to understand political consumerism, the author suggests that one has to consider and understand the ‘varieties of political consumerism’ that exist. With this ambition for the book, the author presents two original sets of quantitative data, based on which the ideas are further investigated throughout the book.},
	language = {en},
	urldate = {2022-05-02},
	booktitle = {Varieties of {Political} {Consumerism}: {From} {Boycotting} to {Buycotting}},
	publisher = {Springer International Publishing},
	author = {Zorell, Carolin V.},
	editor = {Zorell, Carolin V.},
	year = {2019},
	doi = {10.1007/978-3-319-91047-5_1},
	keywords = {Buycotts, Corporate Social Responsibility (CSR), European Social Survey (ESS), Labeling Scheme, Political Consumerism},
	pages = {1--36},
}

@misc{noauthor_mermaid_nodate,
	title = {mermaid - {Markdownish} syntax for generating flowcharts, sequence diagrams, class diagrams, gantt charts and git graphs.},
	url = {http://mermaid-js.github.io/mermaid/#/},
	urldate = {2022-04-29},
	file = {mermaid - Markdownish syntax for generating flowcharts, sequence diagrams, class diagrams, gantt charts and git graphs.:/Users/isabelleborucki/Zotero/storage/WUI5728I/mermaid.html:text/html},
}

@book{noauthor_data_nodate,
	title = {Data {Visualization}},
	url = {https://socviz.co/},
	abstract = {A practical introduction.},
	urldate = {2022-04-03},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/7AYUR7YU/socviz.co.html:text/html},
}

@article{baden_three_2022,
	title = {Three {Gaps} in {Computational} {Text} {Analysis} {Methods} for {Social} {Sciences}: {A} {Research} {Agenda}},
	volume = {16},
	issn = {1931-2458, 1931-2466},
	shorttitle = {Three {Gaps} in {Computational} {Text} {Analysis} {Methods} for {Social} {Sciences}},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2021.2015574},
	doi = {10.1080/19312458.2021.2015574},
	abstract = {We identify three gaps that limit the utility and obstruct the progress of computational text analysis methods (CTAM) for social science research. First, we contend that CTAM development has prioritized technological over validity concerns, giving limited attention to the operationalization of social scientific measurements. Second, we identify a mismatch between CTAMs’ focus on extracting specific contents and document-level patterns, and social science researchers’ need for measuring multiple, often complex contents in the text. Third, we argue that the dominance of English language tools depresses comparative research and inclusivity toward scholarly commu­ nities examining languages other than English. We substantiate our claims by drawing upon a broad review of methodological work in the computa­ tional social sciences, as well as an inventory of leading research publications using quantitative textual analysis. Subsequently, we discuss implications of these three gaps for social scientists’ uneven uptake of CTAM, as well as the field of computational social science text research as a whole. Finally, we propose a research agenda intended to bridge the identified gaps and improve the validity, utility, and inclusiveness of CTAM.},
	language = {en},
	number = {1},
	urldate = {2022-03-31},
	journal = {Communication Methods and Measures},
	author = {Baden, Christian and Pipal, Christian and Schoonvelde, Martijn and van der Velden, Mariken A. C. G},
	month = jan,
	year = {2022},
	pages = {1--18},
	file = {Baden et al. - 2022 - Three Gaps in Computational Text Analysis Methods .pdf:/Users/isabelleborucki/Zotero/storage/HMXQDAUX/Baden et al. - 2022 - Three Gaps in Computational Text Analysis Methods .pdf:application/pdf},
}

@misc{noauthor_project_nodate,
	title = {Project reports},
	url = {https://opted.eu/results/project-reports/},
	abstract = {Project reports},
	language = {en},
	urldate = {2022-03-31},
}

@book{jilbert_46_nodate,
	title = {4.6 {Network} {Composition}-{Homophily} {Measures} {\textbar} {Social} {Networks}: {An} {Introduction}},
	shorttitle = {4.6 {Network} {Composition}-{Homophily} {Measures} {\textbar} {Social} {Networks}},
	url = {https://bookdown.org/omarlizardo/_main/4-6-network-composition-homophily-measures.html},
	abstract = {This is a draft of an introductory textbook on social networks and social network analysis.},
	urldate = {2022-03-25},
	author = {Jilbert, Omar Lizardo {and} Isaac},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/INL4FTB9/4-6-network-composition-homophily-measures.html:text/html},
}

@misc{dr_guy_prochilo__rstats_2022,
	type = {Tweet},
	title = {\#{Rstats}: {Copy} data from {Excel} and paste it into {R} as a dataframe or tibble using datapasta: install.packages("datapasta") -{\textgreater} set a useful keyboard paste shortcut \#phdchat https://t.co/{jS7kwndF1q}},
	url = {https://twitter.com/GuyProchilo/status/1506404403955310594},
	language = {en},
	urldate = {2022-03-23},
	journal = {@GuyProchilo},
	author = {{Dr. Guy Prochilo 🏳️‍🌈}},
	month = jan,
	year = {2022},
}

@misc{vincent_arel-bundock_marginaleffects_2022,
	type = {Tweet},
	title = {The \{marginaleffects\} 0.4.0 \#{RStats} 📦 is faster, more robust, and it supports 54 model types. {Use} it to compute and plot adjusted predictions, contrasts, marginal effects, and marginal means. {Short} 🧵 on the new `comparisons()` function for contrasts, and other nice stuff. https://t.co/{9FsPRvjVFf}},
	url = {https://twitter.com/VincentAB/status/1503351658566332416},
	language = {en},
	urldate = {2022-03-23},
	journal = {@VincentAB},
	author = {{Vincent Arel-Bundock}},
	month = jan,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/7AGD2MVG/1503351658566332416.html:text/html},
}

@misc{noauthor_list_nodate,
	title = {List {Experiments} - {DIME} {Wiki}},
	url = {https://dimewiki.worldbank.org/List_Experiments#Example_1},
	urldate = {2022-03-22},
	file = {List Experiments - DIME Wiki:/Users/isabelleborucki/Zotero/storage/IIB8F6VE/List_Experiments.html:text/html},
}

@article{tjur_coefficients_2009,
	title = {Coefficients of {Determination} in {Logistic} {Regression} {Models}—{A} {New} {Proposal}: {The} {Coefficient} of {Discrimination}},
	volume = {63},
	issn = {0003-1305},
	shorttitle = {Coefficients of {Determination} in {Logistic} {Regression} {Models}—{A} {New} {Proposal}},
	url = {https://www.jstor.org/stable/25652317},
	abstract = {Many analogues to the coefficient of determination R² in ordinary regression models have been proposed in the context of logistic regression. Our starting point is a study of three definitions related to quadratic measures of variation. We discuss the properties of these statistics, and show that the family can be extended in a natural way by a fourth statistic with an even simpler interpretation, namely the difference between the averages of fitted values for successes and failures, respectively. We propose the name "the coefficient of discrimination" for this statistic, and recommend its use as a standard measure of explanatory power. In its intuitive interpretation, this quantity has no immediate relation to the classical versions of R², but it turns out to be related to these by two exact relations, which imply that all these statistics are asymptotically equivalent.},
	number = {4},
	urldate = {2022-02-26},
	journal = {The American Statistician},
	author = {Tjur, Tue},
	year = {2009},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {366--372},
	file = {JSTOR Full Text PDF:/Users/isabelleborucki/Zotero/storage/MQWR6R7Q/Tjur - 2009 - Coefficients of Determination in Logistic Regressi.pdf:application/pdf},
}

@article{vardigan_qualitative_2013,
	title = {A {Qualitative} {Data} {Model} for {DDI}},
	url = {http://www.ddialliance.org/system/files/AQualitativeDataModelForDDI.pdf},
	doi = {10.3886/DDIWORKINGPAPER05},
	language = {de},
	urldate = {2022-02-11},
	author = {Vardigan, Mary},
	year = {2013},
	note = {Publisher: ICPSR - Interuniversity Consortium for Political and Social Research},
	file = {Vardigan - 2013 - A Qualitative Data Model for DDI.pdf:/Users/isabelleborucki/Zotero/storage/W6NM8UEP/Vardigan - 2013 - A Qualitative Data Model for DDI.pdf:application/pdf},
}

@misc{noauthor_bayesian_nodate,
	title = {Bayesian generalized linear models with group-specific terms via {Stan} — stan\_glmer},
	url = {https://mc-stan.org/rstanarm/reference/stan_glmer.html},
	abstract = {Bayesian inference for GLMs with group-specific coefficients that have 
unknown covariance matrices with flexible priors.},
	language = {en},
	urldate = {2022-02-11},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PPXRJFAA/stan_glmer.html:text/html},
}

@misc{noauthor_stan_glmer_nodate,
	title = {stan\_glmer: {Bayesian} generalized linear models with group-specific terms... in rstanarm: {Bayesian} {Applied} {Regression} {Modeling} via {Stan}},
	shorttitle = {stan\_glmer},
	url = {https://rdrr.io/cran/rstanarm/man/stan_glmer.html},
	abstract = {Bayesian inference for GLMs with group-specific coefficients that have 
unknown covariance matrices with flexible priors.},
	language = {en},
	urldate = {2022-02-11},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/X4ZVHC9F/stan_glmer.html:text/html},
}

@misc{holtz_bubble_nodate,
	title = {Bubble plot with ggplot2},
	url = {https://www.r-graph-gallery.com/320-the-basis-of-bubble-plot.html},
	abstract = {This post explains how to build a bubble chart with R and ggplot2. It provides several reproducible examples with explanation and R code.},
	language = {en},
	urldate = {2022-02-11},
	author = {Holtz, Yan},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/XHCKPNWM/320-the-basis-of-bubble-plot.html:text/html},
}

@misc{noauthor_methodentoolbox_nodate,
	title = {Methodentoolbox des {Methodenzentrums} - {Methodentoolbox} - {myWiki}},
	url = {https://mywiki.leuphana.de/display/MET/Methodentoolbox+des+Methodenzentrums},
	urldate = {2022-02-09},
	file = {Methodentoolbox des Methodenzentrums - Methodentoolbox - myWiki:/Users/isabelleborucki/Zotero/storage/KMVVYA9D/Methodentoolbox+des+Methodenzentrums.html:text/html},
}

@misc{doi_gov_nodate,
	title = {Gov 2003: {Causal} {Inference}: {Gov} 2003: {Causal} {Inference} with {Applications}},
	shorttitle = {Gov 2003},
	url = {https://mattblackwell.github.io/gov2003-f21-site/},
	abstract = {Information for Gov 2003 at Harvard University},
	urldate = {2022-02-12},
	journal = {Gov 2003: Causal Inference},
	author = {DOI, Authors Affiliations Published Not published yet},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/3MSRMZ8L/gov2003-f21-site.html:text/html},
}

@article{gibson_best_2021,
	title = {Best {Practices} for the {Use} of {Desk} {Rejects}},
	volume = {54},
	issn = {1049-0965, 1537-5935},
	url = {https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/best-practices-for-the-use-of-desk-rejects/FE4AD1D93E6EC5FA7BB8C907611A774F},
	doi = {10.1017/S104909652100055X},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS104909652100055X/resource/name/firstPage-S104909652100055Xa.jpg},
	language = {en},
	number = {4},
	urldate = {2021-11-09},
	journal = {PS: Political Science \& Politics},
	author = {Gibson, James L.},
	month = oct,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	pages = {703--705},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/NP24VVK4/Gibson - 2021 - Best Practices for the Use of Desk Rejects.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/4F3EQUUD/FE4AD1D93E6EC5FA7BB8C907611A774F.html:text/html},
}

@article{emmons_graduate_2020,
	title = {Graduate {Qualitative} {Methods} {Training} in {Political} {Science}: {A} {Disciplinary} {Crisis}},
	volume = {53},
	issn = {1049-0965, 1537-5935},
	shorttitle = {Graduate {Qualitative} {Methods} {Training} in {Political} {Science}},
	url = {https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/graduate-qualitative-methods-training-in-political-science-a-disciplinary-crisis/7B0EEB76E1CC234AFED7EED8DA71BA35},
	doi = {10.1017/S1049096519001719},
	abstract = {Most political scientists conduct and publish qualitative research, but what training in qualitative methods do political science doctoral programs offer? Do scholarly views converge on the proper content of such training? Analysis of methods curricula and syllabi from 25 leading US political science doctoral programs reveals a troubling gap: only 60\% of top departments offer any dedicated graduate training in qualitative methods. Departments can remedy this disjuncture between scholarship and training by enhancing their basic qualitative methods curricula. Our research shows that scholars agree broadly on the content of such training, effective pedagogical practices, major alternatives for curriculum design, and a menu of focused topics. Graduate programs that aspire to train professionally competent qualitative and multi-method researchers now can orient their reform efforts on shared disciplinary standards for qualitative methods training.},
	language = {en},
	number = {2},
	urldate = {2021-11-09},
	journal = {PS: Political Science \& Politics},
	author = {Emmons, Cassandra V. and Moravcsik, Andrew M.},
	month = apr,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	pages = {258--264},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/P82A3TGM/Emmons and Moravcsik - 2020 - Graduate Qualitative Methods Training in Political.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/3G9SB226/7B0EEB76E1CC234AFED7EED8DA71BA35.html:text/html},
}

@book{noauthor_quantitative_2018,
	title = {Quantitative {Social} {Science}},
	isbn = {978-0-691-17546-1},
	url = {https://press.princeton.edu/books/paperback/9780691175461/quantitative-social-science},
	abstract = {An introductory textbook on data analysis and statistics written especially for students in the social sciences and allied fields},
	language = {en},
	urldate = {2021-11-08},
	month = feb,
	year = {2018},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/DZBSIQKK/quantitative-social-science.html:text/html},
}

@misc{noauthor_kosuke_nodate,
	title = {Kosuke {Imai}'s {Teaching} {Page}},
	url = {https://imai.fas.harvard.edu/teaching/index.html},
	urldate = {2021-11-08},
	file = {Kosuke Imai's Teaching Page:/Users/isabelleborucki/Zotero/storage/3TQEV5CS/index.html:text/html},
}

@misc{noauthor_data_nodate-1,
	title = {Data {Visualization} {\textbar} {Princeton} {University} {Press}},
	url = {https://press.princeton.edu/books/paperback/9780691181622/data-visualization},
	urldate = {2021-11-08},
	file = {Data Visualization | Princeton University Press:/Users/isabelleborucki/Zotero/storage/XRW53ILU/data-visualization.html:text/html},
}

@article{grimmer_machine_2021,
	title = {Machine {Learning} for {Social} {Science}: {An} {Agnostic} {Approach}},
	volume = {24},
	shorttitle = {Machine {Learning} for {Social} {Science}},
	url = {https://doi.org/10.1146/annurev-polisci-053119-015921},
	doi = {10.1146/annurev-polisci-053119-015921},
	abstract = {Social scientists are now in an era of data abundance, and machine learning tools are increasingly used to extract meaning from data sets both massive and small. We explain how the inclusion of machine learning in the social sciences requires us to rethink not only applications of machine learning methods but also best practices in the social sciences. In contrast to the traditional tasks for machine learning in computer science and statistics, when machine learning is applied to social scientific data, it is used to discover new concepts, measure the prevalence of those concepts, assess causal effects, and make predictions. The abundance of data and resources facilitates the move away from a deductive social science to a more sequential, interactive, and ultimately inductive approach to inference. We explain how an agnostic approach to machine learning methods focused on the social science tasks facilitates progress across a wide range of questions.},
	number = {1},
	urldate = {2021-11-06},
	journal = {Annual Review of Political Science},
	author = {Grimmer, Justin and Roberts, Margaret E. and Stewart, Brandon M.},
	year = {2021},
	note = {\_eprint: https://doi.org/10.1146/annurev-polisci-053119-015921},
	keywords = {machine learning, research design, text as data},
	pages = {395--419},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/KT47RQYK/Grimmer et al. - 2021 - Machine Learning for Social Science An Agnostic A.pdf:application/pdf},
}

@article{sen_how_2021,
	title = {How {Does} {Counterfactually} {Augmented} {Data} {Impact} {Models} for {Social} {Computing} {Constructs}?},
	url = {http://arxiv.org/abs/2109.07022},
	abstract = {As NLP models are increasingly deployed in socially situated settings such as online abusive content detection, it is crucial to ensure that these models are robust. One way of improving model robustness is to generate counterfactually augmented data (CAD) for training models that can better learn to distinguish between core features and data artifacts. While models trained on this type of data have shown promising out-of-domain generalizability, it is still unclear what the sources of such improvements are. We investigate the benefits of CAD for social NLP models by focusing on three social computing constructs -- sentiment, sexism, and hate speech. Assessing the performance of models trained with and without CAD across different types of datasets, we find that while models trained on CAD show lower in-domain performance, they generalize better out-of-domain. We unpack this apparent discrepancy using machine explanations and find that CAD reduces model reliance on spurious features. Leveraging a novel typology of CAD to analyze their relationship with model performance, we find that CAD which acts on the construct directly or a diverse set of CAD leads to higher performance.},
	urldate = {2021-11-07},
	journal = {arXiv:2109.07022 [cs]},
	author = {Sen, Indira and Samory, Mattia and Floeck, Fabian and Wagner, Claudia and Augenstein, Isabelle},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.07022},
	keywords = {Computer Science - Computers and Society},
	annote = {Comment: Preprint of a paper accepted to EMNLP 2021},
	file = {arXiv Fulltext PDF:/Users/isabelleborucki/Zotero/storage/AD33T9V2/Sen et al. - 2021 - How Does Counterfactually Augmented Data Impact Mo.pdf:application/pdf;arXiv.org Snapshot:/Users/isabelleborucki/Zotero/storage/F5YFMWVV/2109.html:text/html},
}

@article{gray_data_2018,
	title = {Data infrastructure literacy},
	volume = {5},
	issn = {2053-9517},
	url = {https://doi.org/10.1177/2053951718786316},
	doi = {10.1177/2053951718786316},
	abstract = {A recent report from the UN makes the case for “global data literacy” in order to realise the opportunities afforded by the “data revolution”. Here and in many other contexts, data literacy is characterised in terms of a combination of numerical, statistical and technical capacities. In this article, we argue for an expansion of the concept to include not just competencies in reading and working with datasets but also the ability to account for, intervene around and participate in the wider socio-technical infrastructures through which data is created, stored and analysed – which we call “data infrastructure literacy”. We illustrate this notion with examples of “inventive data practice” from previous and ongoing research on open data, online platforms, data journalism and data activism. Drawing on these perspectives, we argue that data literacy initiatives might cultivate sensibilities not only for data science but also for data sociology, data politics as well as wider public engagement with digital data infrastructures. The proposed notion of data infrastructure literacy is intended to make space for collective inquiry, experimentation, imagination and intervention around data in educational programmes and beyond, including how data infrastructures can be challenged, contested, reshaped and repurposed to align with interests and publics other than those originally intended.},
	language = {en},
	number = {2},
	urldate = {2021-11-06},
	journal = {Big Data \& Society},
	author = {Gray, Jonathan and Gerlitz, Carolin and Bounegru, Liliana},
	month = jul,
	year = {2018},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {science and technology studies, critical data studies, data activism, data critique, Data infrastructures, data journalism, data literacy, data publics, data worlds, digital methods, information infrastructure studies},
	pages = {2053951718786316},
	file = {SAGE PDF Full Text:/Users/isabelleborucki/Zotero/storage/LL22LDV7/Gray et al. - 2018 - Data infrastructure literacy.pdf:application/pdf},
}

@article{sieberer_roll-call_2020,
	title = {Roll-{Call} {Votes} in the {German} {Bundestag}: {A} {New} {Dataset}, 1949–2013},
	volume = {50},
	issn = {0007-1234, 1469-2112},
	shorttitle = {Roll-{Call} {Votes} in the {German} {Bundestag}},
	url = {https://www.cambridge.org/core/journals/british-journal-of-political-science/article/rollcall-votes-in-the-german-bundestag-a-new-dataset-19492013/FB0AC94535D5AC6FB7B2DBD7A77E4963},
	doi = {10.1017/S0007123418000406},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0007123418000406/resource/name/firstPage-S0007123418000406a.jpg},
	language = {en},
	number = {3},
	urldate = {2021-04-23},
	journal = {British Journal of Political Science},
	author = {Sieberer, Ulrich and Saalfeld, Thomas and Ohmura, Tamaki and Bergmann, Henning and Bailer, Stefanie},
	month = jul,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	keywords = {Germany, datasets, legislative behavior, members of parliament, roll-call voting},
	pages = {1137--1145},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/PFZ2WCS8/Sieberer et al. - 2020 - Roll-Call Votes in the German Bundestag A New Dat.pdf:application/pdf;Sieberer et al. - 2020 - Roll-Call Votes in the German Bundestag A New Dat.pdf:/Users/isabelleborucki/Zotero/storage/KESVKGTD/Sieberer et al. - 2020 - Roll-Call Votes in the German Bundestag A New Dat.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/8J99ICIB/FB0AC94535D5AC6FB7B2DBD7A77E4963.html:text/html},
}

@article{schneider_linear_2010,
	title = {Linear {Regression} {Analysis}},
	issn = {1866-0452},
	url = {https://www.aerzteblatt.de/10.3238/arztebl.2010.0776},
	doi = {10.3238/arztebl.2010.0776},
	language = {de},
	urldate = {2021-09-27},
	journal = {Deutsches Aerzteblatt Online},
	author = {Schneider, Astrid and Hommel, Gerhard and Blettner, Maria},
	month = nov,
	year = {2010},
	file = {Schneider et al. - 2010 - Linear Regression Analysis.pdf:/Users/isabelleborucki/Zotero/storage/GKN6ZLCF/Schneider et al. - 2010 - Linear Regression Analysis.pdf:application/pdf},
}

@article{weydner-volkmann_technikvertrauen_2021,
	title = {Technikvertrauen: {Beiträge} zur {Technikfolgenabschätzung} jenseits von {Akzeptanz} und {Akzeptabilität}?},
	volume = {30},
	copyright = {Copyright (c) 2021 Sebastian Weydner-Volkmann},
	issn = {2567-8833},
	shorttitle = {Technikvertrauen},
	url = {https://tatup.de/index.php/tatup/article/view/6901},
	doi = {10.14512/tatup.30.2.53},
	abstract = {Der Beitrag lotet aus, inwiefern über den Begriff „Technikvertrauen“ komplementär zu den in der Technikfolgenabschätzung bereits etablierten Begriffen „Akzeptanz“ und „Akzeptabilität“ ein konzeptueller Beitrag für eine ethische Technikbewertung geleistet werden kann. Es wird gezeigt, dass gerade für Digitaltechniken Aspekte der Angriffssicherheit besser adressiert werden können, weil hier an die Begrifflichkeiten der IT-Sicherheitsforschung angeschlossen werden kann. Zudem erlaubt „vertrauenswürdige Technik“ eine bessere Einbeziehung von Laienperspektiven, da ein rational begründetes Vertrauen im Sinne von Risikoerwartungen interpersonell durch Expertisen vermittelt werden kann. Insbesondere für die Bewertung von Digitaltechniken kann „Technikvertrauen“ somit eine Lücke zwischen Akzeptanz und Akzeptabilität schließen.},
	language = {de},
	number = {2},
	urldate = {2021-09-05},
	journal = {TATuP - Zeitschrift für Technikfolgenabschätzung in Theorie und Praxis},
	author = {Weydner-Volkmann, Sebastian},
	month = jul,
	year = {2021},
	note = {Number: 2},
	keywords = {technology assessment},
	pages = {53--59},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/RRSC2GJ8/Weydner-Volkmann - 2021 - Technikvertrauen Beiträge zur Technikfolgenabschä.pdf:application/pdf},
}

@misc{noauthor_bio_nodate,
	title = {Bio – {Ethics} of {Digital} {Methods} and {Technologies}},
	url = {https://weydner-volkmann.de/?page_id=6},
	language = {en-US},
	urldate = {2021-09-05},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/8TY963E3/weydner-volkmann.de.html:text/html},
}

@misc{noauthor_toolissuecrawler_nodate,
	title = {{ToolIssueCrawler} {\textless} {Dmi} {\textless} {Foswiki}},
	url = {https://wiki.digitalmethods.net/Dmi/ToolIssueCrawler},
	urldate = {2021-09-05},
	file = {ToolIssueCrawler < Dmi < Foswiki:/Users/isabelleborucki/Zotero/storage/CGTNJU4B/ToolIssueCrawler.html:text/html},
}

@misc{noauthor_tool4cat_nodate,
	title = {{Tool4CAT} {\textless} {Dmi} {\textless} {Foswiki}},
	url = {https://wiki.digitalmethods.net/Dmi/Tool4CAT},
	urldate = {2021-09-05},
	file = {Tool4CAT < Dmi < Foswiki:/Users/isabelleborucki/Zotero/storage/4VYPKGXA/Tool4CAT.html:text/html},
}

@misc{noauthor_dmiabout_nodate,
	title = {{DmiAbout} {\textless} {Dmi} {\textless} {Foswiki}},
	url = {https://wiki.digitalmethods.net/Dmi/DmiAbout},
	urldate = {2021-09-05},
	file = {DmiAbout < Dmi < Foswiki:/Users/isabelleborucki/Zotero/storage/ML9QMF2H/DmiAbout.html:text/html},
}

@misc{noauthor_sobigdata_nodate,
	title = {{SoBigData} {Project} {\textbar}},
	url = {http://project.sobigdata.eu/},
	urldate = {2021-09-05},
	file = {SoBigData Project |:/Users/isabelleborucki/Zotero/storage/6EW758RI/project.sobigdata.eu.html:text/html},
}

@misc{noauthor_projects_nodate,
	title = {Projects {Archive}},
	url = {https://publicdatalab.org/},
	abstract = {The Public Data Lab is an interdisciplinary network exploring what difference the digital makes in attending to public problems.},
	language = {en-US},
	urldate = {2021-09-05},
	journal = {Public Data Lab},
}

@incollection{kneip_zusammenfassung_2020,
	address = {Wiesbaden},
	title = {Zusammenfassung und {Ausblick}: {Die} neue {Zerbrechlichkeit} der {Demokratie}},
	isbn = {978-3-658-29557-8 978-3-658-29558-5},
	shorttitle = {Zusammenfassung und {Ausblick}},
	url = {http://link.springer.com/10.1007/978-3-658-29558-5_16},
	language = {de},
	urldate = {2021-06-15},
	booktitle = {Legitimitätsprobleme},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Merkel, Wolfgang and Kneip, Sascha and Weßels, Bernhard},
	editor = {Kneip, Sascha and Merkel, Wolfgang and Weßels, Bernhard},
	year = {2020},
	doi = {10.1007/978-3-658-29558-5_16},
	pages = {389--407},
	file = {Merkel et al. - 2020 - Zusammenfassung und Ausblick Die neue Zerbrechlic.pdf:/Users/isabelleborucki/Zotero/storage/C7XDL2E8/Merkel et al. - 2020 - Zusammenfassung und Ausblick Die neue Zerbrechlic.pdf:application/pdf},
}

@misc{noauthor_introduction_nodate-2,
	title = {Introduction: {Plotting} {Adjusted} {Predictions} and {Marginal} {Effects}},
	url = {https://cran.r-project.org/web/packages/ggeffects/vignettes/introduction_plotmethod.html},
	urldate = {2021-06-15},
	file = {Introduction\: Plotting Adjusted Predictions and Marginal Effects:/Users/isabelleborucki/Zotero/storage/WW9EESGJ/introduction_plotmethod.html:text/html},
}

@misc{humanstxt_probleme_nodate,
	title = {Probleme der {Empirie} {\textbar} {Methodenportal} der {Uni} {Leipzig}},
	url = {https://home.uni-leipzig.de/methodenportal/probleme_der_empirie/},
	language = {de-DE},
	urldate = {2021-06-14},
	author = {humans.txt},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/EVTT2RT6/probleme_der_empirie.html:text/html},
}

@misc{holtz_horizontal_nodate,
	title = {Horizontal violin plot with ggplot2},
	url = {https://www.r-graph-gallery.com/violin_vertical_ggplot2.html},
	abstract = {Learn how to build an horizontal violin plot with R and ggplot2. Reproducible R code is provided, different input formats are considered.},
	language = {en},
	urldate = {2021-06-12},
	author = {Holtz, Yan},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PB52YEL5/violin_horizontal_ggplot2.html:text/html},
}

@misc{noauthor_top_nodate,
	title = {Top 50 ggplot2 {Visualizations} - {The} {Master} {List} ({With} {Full} {R} {Code})},
	url = {http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html},
	urldate = {2021-06-12},
	file = {Top 50 ggplot2 Visualizations - The Master List (With Full R Code):/Users/isabelleborucki/Zotero/storage/CN7TUWTQ/Top50-Ggplot2-Visualizations-MasterList-R-Code.html:text/html},
}

@misc{r_meine_2018,
	title = {Meine 15 nützlichsten {RStudio} {Shortcuts}},
	url = {https://databraineo.com/ki-training-resources/r-programmierung/meine-15-nuetzlichsten-rstudio-shortcuts/},
	abstract = {Vom Anfänger zum RStudio-Profi mit diesen 15 Shortcuts ...},
	language = {de-DE},
	urldate = {2021-06-11},
	journal = {DataBraineo - Data Science Blog},
	author = {R, 21 Nov 2018 {\textbar}},
	month = nov,
	year = {2018},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PZW5EJ9J/meine-15-nuetzlichsten-rstudio-shortcuts.html:text/html},
}

@book{anton_kapitel_nodate,
	title = {Kapitel 8 {Datenimport} {\textbar} {R} für {Psychos}},
	url = {https://r-intro.tadaa-data.de/book/},
	abstract = {Eine Einführung in R für Menschen so ganz ohne Vorkenntnisse},
	language = {de-DE},
	urldate = {2021-06-11},
	author = {Anton, Lukas Burk \& Tobias},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/D3X7WXMD/datenimport.html:text/html},
}

@misc{noauthor_logistische_nodate,
	title = {Logistische {Regression} - {Beispiel} in {R}},
	url = {https://www.inwt-statistics.de/blog-artikel-lesen/Logistische_Regression_Beispiel_mit_R.html},
	urldate = {2021-06-10},
	file = {Logistische Regression - Beispiel in R:/Users/isabelleborucki/Zotero/storage/Q2E9LDCQ/Logistische_Regression_Beispiel_mit_R.html:text/html},
}

@book{ragin_fuzzy-set_2000,
	address = {Chicago},
	edition = {2nd ed. Edition},
	title = {Fuzzy-{Set} {Social} {Science}},
	isbn = {978-0-226-70277-3},
	abstract = {In this innovative approach to the practice of social science, Charles Ragin explores the use of fuzzy sets to bridge the divide between quantitative and qualitative methods. Paradoxically, the fuzzy set is a powerful tool because it replaces an unwieldy, "fuzzy" instrument—the variable, which establishes only the positions of cases relative to each other, with a precise one—degree of membership in a well-defined set.  Ragin argues that fuzzy sets allow a far richer dialogue between ideas and evidence in social research than previously possible. They let quantitative researchers abandon "homogenizing assumptions" about cases and causes, they extend diversity-oriented research strategies, and they provide a powerful connection between theory and data analysis. Most important, fuzzy sets can be carefully tailored to fit evolving theoretical concepts, sharpening quantitative tools with in-depth knowledge gained through qualitative, case-oriented inquiry. This book will revolutionize research methods not only in sociology, political science, and anthropology but in any field of inquiry dealing with complex patterns of causation.},
	language = {Englisch},
	publisher = {University of Chicago Press},
	author = {Ragin, Charles C.},
	month = aug,
	year = {2000},
}

@book{bickel_multilevel_2007,
	title = {Multilevel {Analysis} for {Applied} {Research}: {It}'s {Just} {Regression}!},
	isbn = {978-1-60918-106-2},
	shorttitle = {Multilevel {Analysis} for {Applied} {Research}},
	abstract = {This book provides a uniquely accessible introduction to multilevel modeling, a powerful tool for analyzing relationships between an individual-level dependent variable, such as student reading achievement, and individual-level and contextual explanatory factors, such as gender and neighborhood quality. Helping readers build on the statistical techniques they already know, Robert Bickel emphasizes the parallels with more familiar regression models, shows how to do multilevel modeling using SPSS, and demonstrates how to interpret the results. He discusses the strengths and limitations of multilevel analysis and explains specific circumstances in which it offers (or does not offer) methodological advantages over more traditional techniques. Over 300 dataset examples from research on educational achievement, income attainment, voting behavior, and other timely issues are presented in numbered procedural steps.},
	language = {en},
	publisher = {Guilford Press},
	author = {Bickel, Robert},
	month = mar,
	year = {2007},
	note = {Google-Books-ID: Gd0yAAAAQBAJ},
	keywords = {Social Science / Methodology, Business \& Economics / Management, Education / Research, Medical / Nursing / General, Psychology / Research \& Methodology},
}

@phdthesis{robertson_characterising_2019,
	type = {doctoral},
	title = {Characterising semantically coherent classes of text through feature discovery},
	url = {http://sro.sussex.ac.uk/id/eprint/84841/},
	abstract = {There is a growing need to provide support for social scientists and humanities scholars to gather and “engage” with very large datasets of free text, to perform very bespoke analyses. method52 is a text analysis platform built for this purpose (Wibberley et al., 2014), and forms a foundation that this thesis builds upon. A central part of method52 and its methodologies is a classifier training component based on dualist (Settles, 2011), and the general process of data engagement with method52 is determined to constitute a continuous cycle of characterising semantically coherent sub-collections, classes, of the text. Two broad methodologies exist for supporting this type of engagement process: (1) a top-down approach wherein concepts and their relationships are explicitly modelled for reasoning, and (2) a more surface-level, bottom-up approach, which entails the use of key terms (surface features) to characterise data. Following the second of these approaches, this thesis examines ways of better supporting this type of data engagement to more effectively support the needs of social scientists and humanities scholars in engaging with text data. The classifier component provides an active learning training environment emphasising the labelling of individual features. However, it can be difficult to interpret and incorporate prior knowledge of features. The process of feature discovery based on the current classifier model does not always produce useful results. And understanding the data well enough to produce successful classifiers is timeconsuming. A new method for discovering features in a corpus is introduced, and feature discovery methods are explored to resolve these issues. When collecting social media data, documents are often obtained by querying an API with a set of key phrases. Therefore, the set of possible classes characterising the data is defined by these basic surface features. It is difficult to know exactly which terms must searched for, and the usefulness of terms can change over time as new discussions and vocabulary emerge. Building on the feature discovery techniques, a framework is presented in this thesis for streaming data with an automatically adapting query to deal with these issues.},
	language = {en},
	urldate = {2021-03-26},
	school = {University of Sussex},
	author = {Robertson, Andrew David},
	month = jul,
	year = {2019},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/UCH74Y6I/Robertson - 2019 - Characterising semantically coherent classes of te.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/LKHHDN6G/84841.html:text/html},
}

@article{breznau_crowdsourced_2018,
	title = {The {Crowdsourced} {Replication} {Initiative}},
	url = {https://osf.io/bs46f/},
	abstract = {Crowdsourced Research on Immigration and Social Policy Preferences 
    Hosted on the Open Science Framework},
	language = {en},
	urldate = {2021-03-26},
	author = {Breznau, Nate and Rinke, Eike Mark and Wuttke, Alexander and Adem, Muna and Adriaans, Jule and Alvarez-Benjumea, Amalia and Andersen, Henrik Kenneth and Auer, Daniel and Azevedo, Flavio and Bahnsen, Oke},
	month = jul,
	year = {2018},
	note = {Publisher: OSF},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/WWSVTZTU/bs46f.html:text/html},
}

@misc{noauthor_about_nodate-1,
	title = {About the {Living} {With} {Data} website},
	url = {https://livingwithdata.org/},
	abstract = {Living With Data is a group of research projects which aim to understand the new role of data in society, in times of ‘datafication’, a term to describe the way in which many aspects of social life are increasingly transformed into quantitative data. Advocates of datafication argue that data-driven change results in a wide range […]},
	language = {en-GB},
	urldate = {2021-03-23},
	journal = {Living with data},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/JTRGCEG9/livingwithdata.org.html:text/html},
}

@misc{saltzer_interpellar_2016,
	title = {{InterpellaR}},
	url = {https://msaeltzer.com/project/interpellar/},
	abstract = {Linking Parliamentary documents of German federal states to a relational legislator database.},
	language = {en-us},
	urldate = {2021-03-19},
	journal = {Marius Sältzer},
	author = {Sältzer, Marius},
	month = apr,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/W7PBBERQ/interpellar.html:text/html},
}

@misc{noauthor_gnu_nodate,
	title = {{GNU} {R}: {Umgang} mit {Datensätzen} ({Erstellen}, {Auswählen} und {Filtern})},
	shorttitle = {{GNU} {R}},
	url = {https://de.wikibooks.org/wiki/GNU_R:_Umgang_mit_Datens%C3%A4tzen_(Erstellen,_Ausw%C3%A4hlen_und_Filtern)},
	language = {de},
	urldate = {2021-03-16},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/8MZEGN4V/GNU_R_Umgang_mit_Datensätzen_(Erstellen,_Auswählen_und_Filtern).html:text/html},
}

@article{maak_rechenzentrum_nodate,
	title = {Rechenzentrum in {Flammen}: {Am} {Rhein} brennt {Europas} {Datenschatz}},
	issn = {0174-4909},
	shorttitle = {Rechenzentrum in {Flammen}},
	url = {https://www.faz.net/1.7241629},
	abstract = {Ein ikonisches Bild: Europas größtes Rechenzentrum geht in Flammen auf, viele Daten sind für immer verloren. Was bedeutet das für uns Internetnutzer?},
	language = {de},
	urldate = {2021-03-14},
	journal = {FAZ.NET},
	author = {Maak, Niklas},
	keywords = {Europa, Bitcoin, Rechenzentrum, Rhein},
}

@article{kinder-kurlanda_perspective_2020,
	title = {Perspective: {Acknowledging} {Data} {Work} in the {Social} {Media} {Research} {Lifecycle}},
	volume = {3},
	issn = {2624-909X},
	shorttitle = {Perspective},
	url = {https://www.frontiersin.org/articles/10.3389/fdata.2020.509954/full},
	doi = {10.3389/fdata.2020.509954},
	abstract = {This paper provides a novel perspective to the discussion about quality and validity of research based on data collected from social media platforms. We highlight everyday research data management practices and the concrete everyday work required to accomplish social media research along different phases in a data lifecycle. Our perspective is informed by results from a series of qualitative interviews with social media researchers, practical experience of working at a research infrastructure institute, as well as recent literature in the field. We emphasize how social media researchers are entangled in complexities between social media platform providers, social media users, other actors, as well as legal and ethical frameworks, that all affect their everyday research practices. Research design decisions are made iteratively at different stages, involving many decisions that may potentially impact the quality of research. We show that these decisions are often hidden, but that making them visible allows to better understand what drives social media research into specific directions. Consequently, we argue that untangling and documenting choices during the research lifecycle, especially when researchers pursue specific approaches and may have actively decided against others (often due to external factors) is necessary and will help to spot and address structural challenges in the social media research ecosystem that go beyond critiques of individual opportunistic approaches to easily accessible data.},
	language = {English},
	urldate = {2021-03-13},
	journal = {Frontiers in Big Data},
	author = {Kinder-Kurlanda, Katharina E. and Weller, Katrin},
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {methodology, Data archiving and distribution, Data life cycle, Digital trace data, epistemology, research data management, Social media research},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/SDEKV9RT/Kinder-Kurlanda and Weller - 2020 - Perspective Acknowledging Data Work in the Social.pdf:application/pdf},
}

@misc{noauthor_5_nodate,
	title = {5 {Data} transformation {\textbar} {R} for {Data} {Science}},
	url = {https://r4ds.had.co.nz/transform.html},
	urldate = {2021-03-07},
}

@book{legler_chapter_nodate,
	title = {Chapter 2 {Beyond} {Least} {Squares}: {Using} {Likelihoods} {\textbar} {Beyond} {Multiple} {Linear} {Regression}},
	shorttitle = {Chapter 2 {Beyond} {Least} {Squares}},
	url = {https://bookdown.org/roback/bookdown-BeyondMLR/ch-beyondmost.html},
	abstract = {An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling.},
	urldate = {2021-03-07},
	author = {Legler, Paul Roback {and} Julie},
}

@misc{noauthor_gut_2017,
	title = {Gut in {Form} - {So} klappts mit der {Datenaufbereitung} in {R}, {Stata} und {SPSS}},
	url = {https://www.statworx.com/de/blog/gut-in-form-so-klappts-mit-der-datenaufbereitung-in-r-stata-und-spss/},
	abstract = {Datenaufbereitung für die optimale Analyse in R, Stata oder SPSS. So werden auch Vor- oder Nachteile der verschiedenen Programme sichtbar.},
	language = {de-DE},
	urldate = {2021-03-07},
	journal = {STATWORX},
	month = nov,
	year = {2017},
}

@misc{noauthor_creating_nodate,
	title = {Creating {New} {Variables} in {R} with mutate() and ifelse()},
	url = {https://rstudio-pubs-static.s3.amazonaws.com/116317_e6922e81e72e4e3f83995485ce686c14.html#/6},
	urldate = {2021-03-07},
	file = {Creating New Variables in R with mutate() and ifelse():/Users/isabelleborucki/Zotero/storage/47CJUATL/116317_e6922e81e72e4e3f83995485ce686c14.html:text/html},
}

@misc{noauthor_markdown_nodate,
	title = {Markdown {Crash} {Course} {\textbar} {Learn} {Markdown} in 60 minutes + {Markdown} {Cheatsheet}},
	url = {https://www.abhaytalreja.me/markdown-crash-course-learn-markdown-in-30-minutes-markdown-cheatsheet/},
	abstract = {Markdown can be used for everything you can create - Websites, Documents, Notes, Books, presentations, Emails and even this blog article you are reading is in Markdown},
	urldate = {2021-03-06},
	journal = {Abhay Talreja},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/3P8H33EL/markdown-crash-course-learn-markdown-in-30-minutes-markdown-cheatsheet.html:text/html},
}

@misc{noauthor_welcome_nodate,
	title = {Welcome {\textbar} {R} for {Data} {Science}},
	url = {https://r4ds.had.co.nz/},
	urldate = {2021-03-06},
	file = {Welcome | R for Data Science:/Users/isabelleborucki/Zotero/storage/69NZZKF7/r4ds.had.co.nz.html:text/html},
}

@book{riederer_r_nodate,
	title = {R {Markdown} {Cookbook}},
	url = {https://bookdown.org/yihui/rmarkdown-cookbook/},
	abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
	urldate = {2021-03-06},
	author = {Riederer, Christophe Dervieux, Emily, Yihui Xie},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/7R97QV4L/rmarkdown-cookbook.html:text/html},
}

@book{mcconville_statistical_nodate,
	title = {Statistical {Inference} via {Data} {Science}},
	url = {https://moderndive.com/},
	abstract = {An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools.},
	urldate = {2021-03-06},
	author = {McConville, Chester Ismay {and} Albert Y. Kim Foreword by Kelly S.},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/36NCNL3N/moderndive.com.html:text/html},
}

@book{legler_beyond_nodate,
	title = {Beyond {Multiple} {Linear} {Regression}},
	url = {https://bookdown.org/roback/bookdown-BeyondMLR/},
	abstract = {An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling.},
	urldate = {2021-03-06},
	author = {Legler, Paul Roback {and} Julie},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/Q8BUAJIM/bookdown-BeyondMLR.html:text/html},
}

@article{buttler_clusteranalyse_nodate,
	title = {Clusteranalyse mit gemischtskalierten {Merkmalen}},
	abstract = {Ziel einer Clusteranalyse ist es, eine Menge von Objekten anhand gegebener Merkmale in möglichst homogene Gruppen aufzuteilen. Probleme treten immer dann auf, wenn Merkmale unterschiedlichen Skalenniveaus vorliegen. Vorgeschlagen wird, durch eine geeignete Normierung vom Skalenniveau zu abstrahieren. Dies geschieht, indem die merkmalsspezifischen paarweisen Abstände durch die jeweiligen durchschnittlichen paarweisen Abstände dividiert werden. Ergebnis sind nicht nur dimensionslose, sondern auch in der Streuung vereinheitlichte Werte, die zu einem Gesamtabstand von je zwei Objekten addiert werden können. Als Maß für die Güte der Klassifikation kann der Anteil der paarweisen Distanzen zwischen den Klassen verwendet werden, und zwar sowohl insgesamt als auch gesondert für die einzelnen Merkmale.},
	language = {de},
	author = {Buttler, Günter and Fickel, Norman},
	pages = {24},
	file = {Buttler and Fickel - Clusteranalyse mit gemischtskalierten Merkmalen.pdf:/Users/isabelleborucki/Zotero/storage/8VDIABR9/Buttler and Fickel - Clusteranalyse mit gemischtskalierten Merkmalen.pdf:application/pdf},
}

@misc{noauthor_dimension_2015,
	title = {Dimension {Reduction} {\textbar} {Dimensionality} {Reduction} {Techniques}},
	url = {https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/},
	abstract = {A tutorial for beginners to learn about dimension reduction in machine learning and dimensionality reduction techniques, methods to reduce dimensions.},
	urldate = {2021-02-20},
	journal = {Analytics Vidhya},
	month = jul,
	year = {2015},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/SJWX52LK/dimension-reduction-methods.html:text/html},
}

@misc{noauthor_tsne_nodate,
	title = {tsne: {The} t-{SNE} method for dimensionality reduction in tsne: {T}-{Distributed} {Stochastic} {Neighbor} {Embedding} for {R} (t-{SNE})},
	shorttitle = {tsne},
	url = {https://rdrr.io/cran/tsne/man/tsne.html},
	abstract = {Provides a simple function interface for specifying t-SNE dimensionality reduction on R matrices or "dist" objects.},
	language = {en},
	urldate = {2021-02-20},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/S78DVPUS/tsne.html:text/html},
}

@misc{noauthor_clustering_nodate,
	title = {Clustering in {R}},
	url = {https://blog.dominodatalab.com/clustering-in-r/},
	abstract = {This article covers clustering including K-means and hierarchical clustering. A complementary Domino project is available. Introduction Clustering is a machine learning technique that enables researchers and data scientists to partition and segment data. Segmenting data into appropriate groups is a core task when conducting exploratory analysis. As Domino seeks to support the acceleration of data […]},
	language = {en-US},
	urldate = {2021-02-20},
	journal = {Data Science Blog by Domino},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/X4WLMIIV/clustering-in-r.html:text/html},
}

@misc{adam_clustering_2016,
	title = {Clustering categorical data with {R}},
	url = {https://dabblingwithdata.wordpress.com/2016/10/10/clustering-categorical-data-with-r/},
	abstract = {Clustering is one of the most common unsupervised machine learning tasks. In Wikipedia’s current words, it is: the task of grouping a set of objects in such a way that objects in the same gro…},
	language = {en},
	urldate = {2021-02-20},
	journal = {Dabbling with Data},
	author = {{Adam}},
	month = oct,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PG78KLLQ/clustering-categorical-data-with-r.html:text/html},
}

@article{huang_extensions_1998,
	title = {Extensions to the k-{Means} {Algorithm} for {Clustering} {Large} {Data} {Sets} with {Categorical} {Values}},
	abstract = {The k-means algorithm is well known for its efﬁciency in clustering large data sets. However, working only on numeric values prohibits it from being used to cluster real world data containing categorical values. In this paper we present two algorithms which extend the k-means algorithm to categorical domains and domains with mixed numeric and categorical values. The k-modes algorithm uses a simple matching dissimilarity measure to deal with categorical objects, replaces the means of clusters with modes, and uses a frequency-based method to update modes in the clustering process to minimise the clustering cost function. With these extensions the k-modes algorithm enables the clustering of categorical data in a fashion similar to k-means. The k-prototypes algorithm, through the deﬁnition of a combined dissimilarity measure, further integrates the k-means and k-modes algorithms to allow for clustering objects described by mixed numeric and categorical attributes. We use the well known soybean disease and credit approval data sets to demonstrate the clustering performance of the two algorithms. Our experiments on two real world data sets with half a million objects each show that the two algorithms are efﬁcient when clustering large data sets, which is critical to data mining applications.},
	language = {en},
	journal = {Data Mining and Knowledge Discovery},
	author = {Huang, Zhexue},
	year = {1998},
	pages = {22},
	file = {Huang - 1998 - Extensions to the k-Means Algorithm for Clustering.pdf:/Users/isabelleborucki/Zotero/storage/FBPGSS6L/Huang - 1998 - Extensions to the k-Means Algorithm for Clustering.pdf:application/pdf},
}

@article{maaten_visualizing_2008,
	title = {Visualizing {Data} using t-{SNE}},
	volume = {9},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v9/vandermaaten08a.html},
	number = {86},
	urldate = {2021-02-20},
	journal = {Journal of Machine Learning Research},
	author = {Maaten, Laurens van der and Hinton, Geoffrey},
	year = {2008},
	pages = {2579--2605},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/CCLK2ZP8/Maaten and Hinton - 2008 - Visualizing Data using t-SNE.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/BKKJEXAC/vandermaaten08a.html:text/html},
}

@incollection{wilson_hierarchical_2015,
	address = {Cham},
	series = {{ICSA} {Book} {Series} in {Statistics}},
	title = {Hierarchical {Logistic} {Regression} {Models}},
	isbn = {978-3-319-23805-0},
	url = {https://doi.org/10.1007/978-3-319-23805-0_10},
	abstract = {This chapter extends the results in Chap. 9. It is common to come into contact with data that have a hierarchical or clustered structure. Examples include patients within a hospital, students within a class, factories within an industry, or families within a neighborhood. In such cases, there is variability between the clusters, as well as variability between the units which are nested within the clusters. Hierarchical models take into account the variability at each level of the hierarchy, and thus allow for the cluster effects at different levels to be analyzed within the models (The Annals of Thoracic Surgery 72(6):2155–2168, 2001). This chapter tells how one can use the information from different levels to produce a subject-specific model. This is a three-level nested design but can be expanded to higher levels, though readily available computing may be challenge.},
	language = {en},
	urldate = {2021-04-30},
	booktitle = {Modeling {Binary} {Correlated} {Responses} using {SAS}, {SPSS} and {R}},
	publisher = {Springer International Publishing},
	author = {Wilson, Jeffrey R. and Lorenz, Kent A.},
	editor = {Wilson, Jeffrey R. and Lorenz, Kent A.},
	year = {2015},
	doi = {10.1007/978-3-319-23805-0_10},
	keywords = {Adaptive Gaussian Quadrature, PROC NLMIXED, Random Slope, Standard Logistic Regression Model, Three-level Random Intercept},
	pages = {201--224},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/JIS6AHSE/Wilson and Lorenz - 2015 - Hierarchical Logistic Regression Models.pdf:application/pdf},
}

@incollection{calderaro_internet_2014,
	address = {Cham},
	series = {Public {Administration} and {Information} {Technology}},
	title = {Internet {Politics} {Beyond} the {Digital} {Divide}},
	isbn = {978-3-319-04666-2},
	url = {https://doi.org/10.1007/978-3-319-04666-2_1},
	abstract = {The Digital Divide has been considered key to understanding the relation between Internet and politics. However, today the use of the Internet is following a normalization trend and new country contextual factors must be taken into consideration in explaining the unequal use of the Internet in politics. This study focuses on the unequal presence of political parties online across political systems. By combining multiple sources, this study explores the relation between the unequal online presence of political parties in 190 countries, and country-contextual factors, including level of Digital Divide, and economic and democratic indicators. Here, the empirical findings resize the relation of causality between the Digital Divide and the use of the Internet for politics. They highlight that democratic status, among various other country-contextual specificities, is the strongest contextual factor in determining the unequal use of the Internet in politics for political parties.},
	language = {en},
	urldate = {2021-04-23},
	booktitle = {Social {Media} in {Politics}: {Case} {Studies} on the {Political} {Power} of {Social} {Media}},
	publisher = {Springer International Publishing},
	author = {Calderaro, Andrea},
	editor = {Pătruţ, Bogdan and Pătruţ, Monica},
	year = {2014},
	doi = {10.1007/978-3-319-04666-2_1},
	keywords = {Digital divide, Democracy, Comparativism in internet studies, Internet and international politics, Political systems},
	pages = {3--17},
}

@misc{noauthor_opted_nodate,
	title = {{OPTED}},
	url = {https://compcommlab.univie.ac.at/research-teaching/research-projects/opted/},
	abstract = {OPTED},
	language = {en},
	urldate = {2021-04-23},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/TDSNELR6/opted.html:text/html},
}

@misc{noauthor_dr_nodate,
	title = {Dr. {Christian} {Rauh} - {OPTED} {WP5} {Inventory}},
	url = {https://sites.google.com/site/christianrauh/opted-wp5-inventory},
	abstract = {OPTED WP5 Inventory},
	language = {de},
	urldate = {2021-04-23},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/KIMK2QDS/opted-wp5-inventory.html:text/html},
}

@article{couture_funder-imposed_2018,
	title = {A funder-imposed data publication requirement seldom inspired data sharing},
	volume = {13},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0199789},
	doi = {10.1371/journal.pone.0199789},
	language = {en},
	number = {7},
	urldate = {2021-04-23},
	journal = {PLOS ONE},
	author = {Couture, Jessica L. and Blake, Rachael E. and McDonald, Gavin and Ward, Colette L.},
	editor = {Wicherts, Jelte M.},
	month = jul,
	year = {2018},
	pages = {e0199789},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/CM39NRBR/Couture et al. - 2018 - A funder-imposed data publication requirement seld.pdf:application/pdf},
}

@article{hampton_tao_2015,
	title = {The {Tao} of open science for ecology},
	volume = {6},
	issn = {2150-8925},
	url = {http://doi.wiley.com/10.1890/ES14-00402.1},
	doi = {10.1890/ES14-00402.1},
	language = {en},
	number = {7},
	urldate = {2021-04-23},
	journal = {Ecosphere},
	author = {Hampton, Stephanie E. and Anderson, Sean S. and Bagby, Sarah C. and Gries, Corinna and Han, Xueying and Hart, Edmund M. and Jones, Matthew B. and Lenhardt, W. Christopher and MacDonald, Andrew and Michener, William K. and Mudge, Joe and Pourmokhtarian, Afshin and Schildhauer, Mark P. and Woo, Kara H. and Zimmerman, Naupaka},
	month = jul,
	year = {2015},
	pages = {art120},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/YBN3SILY/Hampton et al. - 2015 - The Tao of open science for ecology.pdf:application/pdf},
}

@article{mah_environmental_2017,
	title = {Environmental justice in the age of big data: challenging toxic blind spots of voice, speed, and expertise},
	volume = {3},
	issn = {2325-1042},
	shorttitle = {Environmental justice in the age of big data},
	url = {https://www.tandfonline.com/doi/full/10.1080/23251042.2016.1220849},
	doi = {10.1080/23251042.2016.1220849},
	language = {en},
	number = {2},
	urldate = {2021-04-23},
	journal = {Environmental Sociology},
	author = {Mah, Alice},
	month = apr,
	year = {2017},
	pages = {122--133},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/WDYGWNIV/Mah - 2017 - Environmental justice in the age of big data chal.pdf:application/pdf},
}

@misc{lter_structural_2017,
	title = {Structural size measurements and isotopic signatures of foraging among adult male and female {Adélie} penguins ({Pygoscelis} adeliae) nesting along the {Palmer} {Archipelago} near {Palmer} {Station}, 2007-2009},
	url = {https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-pal.219.3},
	urldate = {2021-04-23},
	publisher = {Environmental Data Initiative},
	author = {LTER, Palmer Station Antarctica and Gorman, Kristen},
	year = {2017},
	doi = {10.6073/PASTA/ABC50EED9138B75F54EAADA0841B9B86},
	note = {type: dataset},
}

@misc{noauthor_overview_nodate,
	title = {Overview},
	url = {https://stanfordnlp.github.io/CoreNLP/},
	abstract = {NLP Processing In Java},
	language = {en-US},
	urldate = {2021-04-23},
	journal = {CoreNLP},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/N8B5SWCH/CoreNLP.html:text/html},
}

@misc{noauthor_publications_nodate,
	title = {Publications},
	url = {https://inception-project.github.io/publications/},
	abstract = {Towards an Infrastructure for the Distributed Exploration and Annotation of Large Corpora and Knowledge Bases},
	language = {en},
	urldate = {2021-04-23},
	journal = {INCEpTION},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/CRRCBJMY/publications.html:text/html},
}

@article{bergmann_btvote_2018,
	title = {{BTVote} {MP} {Characteristics}},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/QSFXLQ},
	doi = {10.7910/DVN/QSFXLQ},
	abstract = {The dataset contains characteristics of the all members of parliament (MPs) participating in at least one roll call vote in the first 17 legislativ...},
	language = {en},
	urldate = {2021-04-23},
	author = {Bergmann, Henning and Bailer, Stefanie and Ohmura, Tamaki and Saalfeld, Thomas and Sieberer, Ulrich},
	month = dec,
	year = {2018},
	note = {Publisher: Harvard Dataverse
type: dataset},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/K37K967C/dataset.html:text/html},
}

@misc{noauthor_consortium_nodate,
	title = {Consortium for the {Social}, {Behavioural}, {Educational}, and {Economic} {Sciences} ({KonsortSWD}) {\textbar} {Zenodo}},
	url = {https://zenodo.org/record/3968372#.YIJrLpMzZTZ},
	urldate = {2021-04-23},
	file = {Consortium for the Social, Behavioural, Educational, and Economic Sciences (KonsortSWD) | Zenodo:/Users/isabelleborucki/Zotero/storage/ET8UQJGY/3968372.html:text/html},
}

@article{menard_standards_2011,
	title = {Standards for {Standardized} {Logistic} {Regression} {Coefficients}},
	volume = {89},
	issn = {0037-7732},
	url = {https://doi.org/10.1093/sf/89.4.1409},
	doi = {10.1093/sf/89.4.1409},
	abstract = {Standardized coefficients in logistic regression analysis have the same utility as standardized coefficients in linear regression analysis. Although there has been no consensus on the best way to construct standardized logistic regression coefficients, there is now sufficient evidence to suggest a single best approach to the construction of a standardized logistic regression coefficient that can be used in the same way across a broad range of problems as the standardized linear regression coefficient and also to suggest the adequacy of other approaches for limited purposes. This article reviews the state of knowledge regarding the use of standardized coefficients in general and standardized logistic regression coefficients in particular, and makes specific recommendations on how to best use (and avoid abusing) standardized logistic regression coefficients.},
	number = {4},
	urldate = {2021-04-22},
	journal = {Social Forces},
	author = {Menard, Scott},
	month = jun,
	year = {2011},
	pages = {1409--1428},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/8ZMT27QF/Menard - 2011 - Standards for Standardized Logistic Regression Coe.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/EF2WIXX2/2235544.html:text/html},
}

@article{tonidandel_relative_2011,
	title = {Relative {Importance} {Analysis}: {A} {Useful} {Supplement} to {Regression} {Analysis}},
	volume = {26},
	issn = {1573-353X},
	shorttitle = {Relative {Importance} {Analysis}},
	url = {https://doi.org/10.1007/s10869-010-9204-3},
	doi = {10.1007/s10869-010-9204-3},
	abstract = {This article advocates for the wider use of relative importance indices as a supplement to multiple regression analyses. The goal of such analyses is to partition explained variance among multiple predictors to better understand the role played by each predictor in a regression equation. Unfortunately, when predictors are correlated, typically relied upon metrics are flawed indicators of variable importance. To that end, we highlight the key benefits of two relative importance analyses, dominance analysis and relative weight analysis, over estimates produced by multiple regression analysis. We also describe numerous situations where relative importance weights should be used, while simultaneously cautioning readers about the limitations and misconceptions regarding the use of these weights. Finally, we present step-by-step recommendations for researchers interested in incorporating these analyses in their own work and point them to available web resources to assist them in producing these weights.},
	language = {en},
	number = {1},
	urldate = {2021-04-22},
	journal = {Journal of Business and Psychology},
	author = {Tonidandel, Scott and LeBreton, James M.},
	month = mar,
	year = {2011},
	pages = {1--9},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/NR37KXCI/Tonidandel and LeBreton - 2011 - Relative Importance Analysis A Useful Supplement .pdf:application/pdf},
}

@misc{noauthor_beamer_nodate,
	title = {Beamer {Theme} {Matrix}},
	url = {https://hartwork.org/beamer-theme-matrix/},
	urldate = {2021-06-03},
	file = {Beamer Theme Matrix:/Users/isabelleborucki/Zotero/storage/SLJI39YE/beamer-theme-matrix.html:text/html},
}

@misc{posted_by_l_v_on_november_6_10_nodate,
	title = {10 great books about {R}},
	url = {https://www.datasciencecentral.com/profiles/blogs/10-great-books-about-r-1},
	abstract = {Books about the R programming language fall in different categories: Learning R Reference books for the professional R programmer Books about data science or…},
	language = {en},
	urldate = {2021-06-03},
	author = {Posted by L. V. on November 6, 2015 at 8:30am and Blog, View},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/RF8MIEUK/10-great-books-about-r-1.html:text/html},
}

@book{zoglauer_einfuhrung_2016,
	address = {Göttingenn Bristol, CT, U.S.A},
	edition = {5., durchgesehene Auflage},
	series = {{UTB}},
	title = {Einführung in die formale {Logik} für {Philosophen}},
	isbn = {978-3-8252-1999-4 978-3-8252-4592-4},
	language = {ger},
	number = {1999},
	publisher = {Vandenhoeck \& Ruprecht},
	author = {Zoglauer, Thomas},
	year = {2016},
	note = {OCLC: 940968567},
	annote = {Literaturverzeichnis: Seite 184-187},
	file = {Table of Contents PDF:/Users/isabelleborucki/Zotero/storage/UMUNR649/Zoglauer - 2016 - Einführung in die formale Logik für Philosophen.pdf:application/pdf},
}

@misc{noauthor_r_nodate,
	title = {R {Packages} [{Book}]},
	url = {https://www.oreilly.com/library/view/r-packages/9781491910580/},
	abstract = {Turn your R code into packages that others can easily download and use. This practical book shows you how to bundle reusable R functions, sample data, and documentation together by … - Selection from R Packages [Book]},
	language = {en},
	urldate = {2021-06-02},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/YA8CZ3F6/9781491910580.html:text/html},
}

@misc{gruber_introducing_2019,
	title = {Introducing rwhatsapp},
	url = {https://johannesbgruber.eu/post/introducing-rwhatsapp/},
	abstract = {I’m happy to announce that rwhatsapp is now on CRAN. After being tested by users on GitHub for a year now, I decided it is time to make the package available to a wider audience. The goal of the package is to make working with ‘WhatsApp’ chat logs as easy as possible.
‘WhatsApp’ seems to become increasingly important not just as a messaging service but also as a social network—thanks to its group chat capabilities.},
	language = {en-GB},
	urldate = {2021-07-31},
	journal = {Johannes B. Gruber},
	author = {Gruber, Johannes B.},
	month = sep,
	year = {2019},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/EKYFCFY2/introducing-rwhatsapp.html:text/html},
}

@misc{gruber_much_2019,
	title = {({Much}) faster unnesting with data.table},
	url = {https://johannesbgruber.eu/post/a-faster-unnest/},
	abstract = {Today I was struggling with a relatively simple operation: unnest() from the tidyr package. What it’s supposed to do is pretty simple. When you have a data.frame where one or multiple columns are lists, you can unlist these columns while duplicating the information in other columns if the length of an element is larger than 1.
library(tibble) df {\textless}- tibble( a = LETTERS[1:5], b = LETTERS[6:10], list\_column = list(c(LETTERS[1:5]), "F", "G", "H", "I") ) df \#\# \# A tibble: 5 x 3 \#\# a b list\_column \#\# {\textless}chr{\textgreater} {\textless}chr{\textgreater} {\textless}list{\textgreater} \#\# 1 A F {\textless}chr [5]{\textgreater} \#\# 2 B G {\textless}chr [1]{\textgreater} \#\# 3 C H {\textless}chr [1]{\textgreater} \#\# 4 D I {\textless}chr [1]{\textgreater} \#\# 5 E J {\textless}chr [1]{\textgreater} library(tidyr) unnest(df, list\_column) \#\# \# A tibble: 9 x 3 \#\# a b list\_column \#\# {\textless}chr{\textgreater} {\textless}chr{\textgreater} {\textless}chr{\textgreater} \#\# 1 A F A \#\# 2 A F B \#\# 3 A F C \#\# 4 A F D \#\# 5 A F E \#\# 6 B G F \#\# 7 C H G \#\# 8 D I H \#\# 9 E J I I came across this a lot while working on data from Twitter since individual tweets can contain multiple hashtags, mentions, URLs and so on, which is why they are stored in lists.},
	language = {en-GB},
	urldate = {2021-07-31},
	journal = {Johannes B. Gruber},
	author = {Gruber, Johannes B.},
	month = oct,
	year = {2019},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/L2ETVXQM/a-faster-unnest.html:text/html},
}

@misc{noauthor_generalised_nodate,
	title = {Generalised {Linear} {Models} with glm and lme4},
	url = {https://www.rensvandeschoot.com/tutorials/generalised-linear-models-with-glm-and-lme4/},
	abstract = {Intro to Frequentist (Multilevel) Generalised Linear Models (GLM) in R with glm and lme4 Qixiang Fang and Rens van de Schoot Last modified: date: 14 October 2019 This tutorial provides the reader with a basic introduction to genearlised linear models (GLM) using the frequentist approach....},
	language = {en-US},
	urldate = {2021-07-30},
	journal = {Rens van de Schoot},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/CZQPJWA5/generalised-linear-models-with-glm-and-lme4.html:text/html},
}

@article{nakagawa_coefficient_2017,
	title = {The coefficient of determination {R2} and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded},
	volume = {14},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0213},
	doi = {10.1098/rsif.2017.0213},
	abstract = {The coefficient of determination R2 quantifies the proportion of variance explained by a statistical model and is an important summary statistic of biological interest. However, estimating R2 for generalized linear mixed models (GLMMs) remains challenging. We have previously introduced a version of R2 that we called  for Poisson and binomial GLMMs, but not for other distributional families. Similarly, we earlier discussed how to estimate intra-class correlation coefficients (ICCs) using Poisson and binomial GLMMs. In this paper, we generalize our methods to all other non-Gaussian distributions, in particular to negative binomial and gamma distributions that are commonly used for modelling biological data. While expanding our approach, we highlight two useful concepts for biologists, Jensen's inequality and the delta method, both of which help us in understanding the properties of GLMMs. Jensen's inequality has important implications for biologically meaningful interpretation of GLMMs, whereas the delta method allows a general derivation of variance associated with non-Gaussian distributions. We also discuss some special considerations for binomial GLMMs with binary or proportion data. We illustrate the implementation of our extension by worked examples from the field of ecology and evolution in the R environment. However, our method can be used across disciplines and regardless of statistical environments.},
	number = {134},
	urldate = {2021-07-15},
	journal = {Journal of The Royal Society Interface},
	author = {Nakagawa, Shinichi and Johnson, Paul C. D. and Schielzeth, Holger},
	month = sep,
	year = {2017},
	note = {Publisher: Royal Society},
	keywords = {goodness of fit, heritability, model fit, reliability analysis, repeatability, variance decomposition},
	pages = {20170213},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/4534VC5W/Nakagawa et al. - 2017 - The coefficient of determination R2 and intra-clas.pdf:application/pdf},
}

@article{huang_multilevel_2018,
	title = {Multilevel modeling myths.},
	volume = {33},
	issn = {1939-1560, 1045-3830},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/spq0000272},
	doi = {10.1037/spq0000272},
	language = {en},
	number = {3},
	urldate = {2021-07-12},
	journal = {School Psychology Quarterly},
	author = {Huang, Francis L.},
	month = sep,
	year = {2018},
	pages = {492--499},
	file = {Huang - 2018 - Multilevel modeling myths..pdf:/Users/isabelleborucki/Zotero/storage/BXN7VG5U/Huang - 2018 - Multilevel modeling myths..pdf:application/pdf},
}

@misc{noauthor_notitle_nodate-2,
	url = {http://localhost:14682/session/file28d1a684b94.html},
	urldate = {2021-07-12},
	file = {localhost\:14682/session/file28d1a684b94.html:/Users/isabelleborucki/Zotero/storage/HJUB3IDA/file28d1a684b94.html:text/html},
}

@misc{noauthor_diskriminanzanalyse_nodate,
	title = {Diskriminanzanalyse versus {Logistische} {Regression} - bank},
	url = {http://doczz.net/doc/2122970/diskriminanzanalyse-versus-logistische-regression},
	abstract = {Diskriminanzanalyse versus Logistische Regression},
	urldate = {2021-07-11},
	journal = {doczz.net},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/UUI87YS2/diskriminanzanalyse-versus-logistische-regression.html:text/html},
}

@article{noauthor_modellannahmen_nodate,
	title = {Modellannahmen der linearen {Regression}},
	language = {de},
	pages = {4},
	file = {Modellannahmen der linearen Regression.pdf:/Users/isabelleborucki/Zotero/storage/NMBGWQRN/Modellannahmen der linearen Regression.pdf:application/pdf},
}

@misc{noauthor_indrajeetpatilgroupedstats_nodate,
	title = {{IndrajeetPatil}/groupedstats: {Grouped} {Statistical} {Analyses} in a {Tidy} {Way} version 2.1.0.9000 from {GitHub}},
	url = {https://rdrr.io/github/IndrajeetPatil/groupedstats/},
	urldate = {2021-07-09},
	file = {IndrajeetPatil/groupedstats\: Grouped Statistical Analyses in a Tidy Way version 2.1.0.9000 from GitHub:/Users/isabelleborucki/Zotero/storage/GBHE7277/groupedstats.html:text/html},
}

@misc{noauthor_logit_nodate,
	title = {Logit {Regression} {\textbar} {R} {Data} {Analysis} {Examples}},
	url = {https://stats.idre.ucla.edu/r/dae/logit-regression/},
	urldate = {2021-07-09},
	file = {Logit Regression | R Data Analysis Examples:/Users/isabelleborucki/Zotero/storage/J43PHWJJ/logit-regression.html:text/html},
}

@misc{noauthor_notitle_nodate-3,
	url = {http://localhost:19732/session/file668701c0c45.html},
	urldate = {2021-07-09},
	file = {localhost\:19732/session/file668701c0c45.html:/Users/isabelleborucki/Zotero/storage/X5G6C756/file668701c0c45.html:text/html},
}

@misc{noauthor_world_nodate,
	title = {World {Happiness} {Report} 2021 {\textbar} {Kaggle}},
	url = {https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021},
	urldate = {2021-07-09},
	file = {World Happiness Report 2021 | Kaggle:/Users/isabelleborucki/Zotero/storage/APFRRWVQ/world-happiness-report-2021.html:text/html},
}

@misc{noauthor_visualizing_nodate-1,
	title = {Visualizing {Distributions} with {Raincloud} {Plots} with ggplot2 - {Cédric} {Scherer}},
	url = {https://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-with-ggplot2/#back2},
	urldate = {2021-07-09},
	file = {Visualizing Distributions with Raincloud Plots with ggplot2 - Cédric Scherer:/Users/isabelleborucki/Zotero/storage/LZX7FRQK/visualizing-distributions-with-raincloud-plots-with-ggplot2.html:text/html},
}

@misc{noauthor_how_2020,
	title = {How {To} {Make} {Ridgeline} {Plot} with ggridges in {R}?},
	url = {https://datavizpyr.com/ridgeline-plot-with-ggridges-in-r/},
	abstract = {Customizing Ridgeline plots in R with ggridges},
	language = {en-US},
	urldate = {2021-07-09},
	journal = {Data Viz with Python and R},
	month = feb,
	year = {2020},
}

@misc{noauthor_word_nodate,
	title = {Word search {Shiny} app},
	url = {https://kaggle.com/rekasol/word-search-shiny-app},
	abstract = {Explore and run machine learning code with Kaggle Notebooks {\textbar} Using data from 2016 US Presidential Debates},
	language = {en},
	urldate = {2021-07-08},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PN8W5A6B/word-search-shiny-app.html:text/html},
}

@misc{noauthor_shiny_2016,
	title = {Shiny {\textbar} {Data} {Visualization} {Using} {Shiny} {App} {In} {R}},
	url = {https://www.analyticsvidhya.com/blog/2016/10/creating-interactive-data-visualization-using-shiny-app-in-r-with-examples/},
	abstract = {An introduction to Shiny App and data visualization using this app in R. It contains detailed explanations in UI.R and Server.R along with codes.},
	urldate = {2021-07-08},
	journal = {Analytics Vidhya},
	month = oct,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/JIZQNW6Z/creating-interactive-data-visualization-using-shiny-app-in-r-with-examples.html:text/html},
}

@misc{noauthor_visualizing_nodate-2,
	title = {Visualizing {Distributions} with {Raincloud} {Plots} with ggplot2},
	url = {https://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-with-ggplot2/},
	abstract = {Raincloud plots, that provide an overview of the raw data, its distribution, and important statistical properties, are a good alternative to classical boxplots. In this tutorial, I highlight the potential problem of boxplots, illustrate why raincloud plots are great, and show numerous ways how to create such hybrid charts in R with \{ggplot2\}.},
	language = {en-us},
	urldate = {2021-07-08},
	journal = {Cédric Scherer},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/FSEU7LEZ/visualizing-distributions-with-raincloud-plots-with-ggplot2.html:text/html},
}

@misc{noauthor_estimating_nodate,
	title = {Estimating {Generalized} ({Non}-){Linear} {Models} with {Group}-{Specific} {Terms} with rstanarm},
	url = {https://cran.r-project.org/web/packages/rstanarm/vignettes/glmer.html#glms-with-group-specific-terms},
	urldate = {2021-07-05},
	file = {Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm:/Users/isabelleborucki/Zotero/storage/3RKXKUB3/glmer.html:text/html},
}

@misc{seawright_case_nodate,
	title = {Case {Studies} and {Regression} {Analysis}},
	language = {en},
	author = {Seawright, Jason},
	file = {Seawright - Case Studies and Regression Analysis.pdf:/Users/isabelleborucki/Zotero/storage/2GH5AKCV/Seawright - Case Studies and Regression Analysis.pdf:application/pdf},
}

@book{giesselmann_regressionsmodelle_2012,
	address = {Wiesbaden},
	title = {Regressionsmodelle zur {Analyse} von {Paneldaten}},
	isbn = {978-3-531-18694-8 978-3-531-18695-5},
	url = {http://link.springer.com/10.1007/978-3-531-18695-5},
	language = {de},
	urldate = {2021-11-05},
	publisher = {VS Verlag für Sozialwissenschaften},
	author = {Giesselmann, Marco and Windzio, Michael},
	year = {2012},
	doi = {10.1007/978-3-531-18695-5},
	file = {Giesselmann and Windzio - 2012 - Regressionsmodelle zur Analyse von Paneldaten.pdf:/Users/isabelleborucki/Zotero/storage/VLD4N8KE/Giesselmann and Windzio - 2012 - Regressionsmodelle zur Analyse von Paneldaten.pdf:application/pdf},
}

@book{deppert_theorie_2019,
	address = {Wiesbaden},
	title = {Theorie der {Wissenschaft}},
	isbn = {978-3-658-15123-2 978-3-658-15124-9},
	url = {http://link.springer.com/10.1007/978-3-658-15124-9},
	language = {de},
	urldate = {2021-11-05},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Deppert, Wolfgang},
	year = {2019},
	doi = {10.1007/978-3-658-15124-9},
	file = {Deppert - 2019 - Theorie der Wissenschaft.pdf:/Users/isabelleborucki/Zotero/storage/R9FQQZWT/Deppert - 2019 - Theorie der Wissenschaft.pdf:application/pdf},
}

@article{shin_enhancing_2020,
	title = {Enhancing {Social} {Media} {Analysis} with {Visual} {Data} {Analytics}: {A} {Deep} {Learning} {Approach}},
	volume = {44},
	issn = {02767783, 21629730},
	shorttitle = {Enhancing {Social} {Media} {Analysis} with {Visual} {Data} {Analytics}},
	url = {https://misq.org/enhancing-social-media-analysis-with-visual-data-analytics-a-deep-learning-approach.html},
	doi = {10.25300/MISQ/2020/14870},
	language = {en},
	number = {4},
	urldate = {2021-11-05},
	journal = {MIS Quarterly},
	author = {Shin, Donghyuk and He, Shu and Lee, Gene Moo and Whinston, Andrew B. and Cetintas, Suleyman and Lee, Kuang-Chih},
	month = dec,
	year = {2020},
	pages = {1459--1492},
	file = {Shin et al. - 2020 - Enhancing Social Media Analysis with Visual Data A.pdf:/Users/isabelleborucki/Zotero/storage/TF3PIYDS/Shin et al. - 2020 - Enhancing Social Media Analysis with Visual Data A.pdf:application/pdf},
}

@article{bauer_writing_nodate,
	title = {Writing a reproducible paper in {R} {Markdown}},
	abstract = {The present paper provides a template for a reproducible scientiﬁc paper written in R Markdown. Below I outline some of the “tricks”/code (e.g., referencing tables, sections etc.) I had to ﬁgure out to produce this document. The underlying ﬁles which produce this document can be downloaded here. I think I got pretty far but there is always room for improvement and more automatization, in parallel to the incredible developments in R and Rstudio (bookdown etc.). I intend to update this ﬁle when I discover more convenient code (you can follow any updates through the corresponding github repo).},
	language = {en},
	author = {Bauer, Paul C},
	pages = {19},
	file = {Bauer - Writing a reproducible paper in R Markdown.pdf:/Users/isabelleborucki/Zotero/storage/YUHPMZQA/Bauer - Writing a reproducible paper in R Markdown.pdf:application/pdf},
}

@misc{noauthor_python_nodate,
	title = {Python {Bootcamp} 2021 - {Jetzt} {Programmieren} {Lernen}},
	url = {https://kurse.lerneprogrammieren.de/lp/python/},
	language = {de-DE},
	urldate = {2021-12-20},
}

@misc{noauthor_docker_nodate,
	title = {Docker {Lernen} für {Anfänger} - {Das} {Einsteiger}-{Tutorial} 2021},
	url = {https://lerneprogrammieren.de/docker/},
	abstract = {Docker ist ein sehr nützliches DevOps-Tool, dass sich schnell lernen lässt. Jedoch wirkt es für viele Anfänger zunächst abschreckend.},
	language = {de-DE},
	urldate = {2021-12-20},
	note = {Section: Blog},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/WK3H9FLD/docker.html:text/html},
}

@misc{gitlab_unfiltered_createsource_2020,
	title = {Create:{Source} {Code} {Walk} {Through} - {Jan} 2020},
	shorttitle = {Create},
	url = {https://www.youtube.com/watch?v=wTQ3aXJswtM},
	abstract = {This is a walk through of the Source Code Management and Code Review categories of GitLab.},
	urldate = {2021-12-20},
	author = {{GitLab Unfiltered}},
	month = jan,
	year = {2020},
}

@article{husted_political_2021,
	title = {Political {Parties} and {Organization} {Studies}: {The} party as a critical case of organizing},
	issn = {0170-8406},
	shorttitle = {Political {Parties} and {Organization} {Studies}},
	url = {https://doi.org/10.1177/01708406211010979},
	doi = {10.1177/01708406211010979},
	abstract = {Organization scholars have extensively studied both the politics of organization and the organization of politics. Contributing to the latter, we argue for further and deeper consideration of political parties, since: (1) parties illuminate organizational dynamics of in- and exclusion; (2) internal struggles related to the constitution of identities, practices and procedures are accentuated in parties; (3) the study of parties allow for the isolation of processes of normative and affective commitment; (4) parties prioritize and intensify normative control mechanisms; (5) party organizing currently represents an example of profound institutional change, as new (digital) formations challenge old bureaucratic models. Consequently, we argue that political parties should be seen as ‘critical cases’ of organizing, meaning that otherwise commonplace phenomena are intensified and exposed in parties. This allows researchers to use parties as magnifying glasses for zooming-in on organizational dynamics that may be suppressed or concealed by the seemingly non-political façade of many contemporary organizations. In conclusion, we argue that organization scholars are in a privileged position to investigate how political parties function today and how their democratic potential can be improved in the future. To this end, we call on Organization and Management Studies to engage actively with alternative parties in an attempt to explore and promote progressive change within the formal political system.},
	language = {en},
	urldate = {2021-12-20},
	journal = {Organization Studies},
	author = {Husted, Emil and Moufahim, Mona and Fredriksson, Martin},
	month = apr,
	year = {2021},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {political parties, democracy, commitment, alternative organization, inclusion and exclusion, intellectual activism, normative control, organizational politics},
	pages = {01708406211010979},
	file = {SAGE PDF Full Text:/Users/isabelleborucki/Zotero/storage/P6KX33Y4/Husted et al. - 2021 - Political Parties and Organization Studies The pa.pdf:application/pdf},
}

@misc{noauthor_mac_2019,
	title = {The {Mac} {Terminal} {Commands} {Cheat} {Sheet}},
	url = {https://www.makeuseof.com/tag/mac-terminal-commands-cheat-sheet/},
	abstract = {Our mega cheat sheet of Mac terminal commands provides a great reference for all the important commands you should know.},
	language = {en-US},
	urldate = {2021-12-18},
	journal = {MUO},
	month = dec,
	year = {2019},
	note = {Section: Mac},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/DQYJ44GD/mac-terminal-commands-cheat-sheet.html:text/html},
}

@article{amrhein_scientists_2019,
	title = {Scientists rise up against statistical significance},
	volume = {567},
	copyright = {2021 Nature},
	url = {https://www.nature.com/articles/d41586-019-00857-9},
	doi = {10.1038/d41586-019-00857-9},
	abstract = {Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories call for an end to hyped claims and the dismissal of possibly crucial effects.},
	language = {en},
	number = {7748},
	urldate = {2021-12-13},
	journal = {Nature},
	author = {Amrhein, Valentin and Greenland, Sander and McShane, Blake},
	month = mar,
	year = {2019},
	note = {Bandiera\_abtest: a
Cg\_type: Comment
Number: 7748
Publisher: Nature Publishing Group
Subject\_term: Research data, Research management},
	keywords = {Research data, Research management},
	pages = {305--307},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/ZHZMUF24/Amrhein et al. - 2019 - Scientists rise up against statistical significanc.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/ERVRGHTX/d41586-019-00857-9.html:text/html},
}

@article{szreder_statistical_2019,
	title = {Statistical significance in the era of big data},
	volume = {64},
	issn = {2543-8476},
	url = {https://wiadomosci-statystyczne.publisherspanel.com/gicid/01.3001.0013.7583},
	doi = {10.5604/01.3001.0013.7583},
	abstract = {The development of new technologies has affected both the procedures of traditional statistical surveys and the perception of their results in the light of other availa-ble sources of information. In this connection, the roleof the verification of statistical hypotheses and of the interpretation and presentation of its results, including the use of statistical significance and p-value, has recently returned as a frequent topic for discussion among the scientific community. The author was inspired to write this paper by a wave of discussion regarding this matter held at the beginning of 2019 in the Natureand The American Statistician journals. The aim of the paper is to present the opportunities provided and challenges posedby the use of big data to the hypothesis verification process and to statistical inference, both in the traditional and Bayesian approaches. The author explains the necessity of discontinuing adopting excessivesimplifications while performing statisticalinference and pre-senting the results of the verification of hypotheses. This involves both the postulate to pay greater attention tothe quality of sampling data, especially in the case of data originating from big data sets, as well as the postulate to providefull information about the statistical model on the basis of which the inference is being performed.},
	language = {en},
	number = {11},
	urldate = {2021-12-13},
	journal = {Wiadomości Statystyczne. The Polish Statistician},
	author = {Szreder, Mirosław},
	month = nov,
	year = {2019},
	note = {Publisher: Index Copernicus},
	pages = {42--57},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/V85P8GPW/Szreder - 2019 - Statistical significance in the era of big data.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/9A5CSFF5/details.html:text/html},
}

@article{gandomi_beyond_2015,
	title = {Beyond the hype: {Big} data concepts, methods, and analytics},
	volume = {35},
	issn = {0268-4012},
	shorttitle = {Beyond the hype},
	url = {https://www.sciencedirect.com/science/article/pii/S0268401214001066},
	doi = {10.1016/j.ijinfomgt.2014.10.007},
	abstract = {Size is the first, and at times, the only dimension that leaps out at the mention of big data. This paper attempts to offer a broader definition of big data that captures its other unique and defining characteristics. The rapid evolution and adoption of big data by industry has leapfrogged the discourse to popular outlets, forcing the academic press to catch up. Academic journals in numerous disciplines, which will benefit from a relevant discussion of big data, have yet to cover the topic. This paper presents a consolidated description of big data by integrating definitions from practitioners and academics. The paper's primary focus is on the analytic methods used for big data. A particular distinguishing feature of this paper is its focus on analytics related to unstructured data, which constitute 95\% of big data. This paper highlights the need to develop appropriate and efficient analytical methods to leverage massive volumes of heterogeneous data in unstructured text, audio, and video formats. This paper also reinforces the need to devise new tools for predictive analytics for structured big data. The statistical methods in practice were devised to infer from sample data. The heterogeneity, noise, and the massive size of structured big data calls for developing computationally efficient algorithms that may avoid big data pitfalls, such as spurious correlation.},
	language = {en},
	number = {2},
	urldate = {2021-12-13},
	journal = {International Journal of Information Management},
	author = {Gandomi, Amir and Haider, Murtaza},
	month = apr,
	year = {2015},
	keywords = {Big data analytics, Big data definition, Predictive analytics, Unstructured data analytics},
	pages = {137--144},
}

@article{khalilzadeh_large_2017,
	title = {Large sample size, significance level, and the effect size: {Solutions} to perils of using big data for academic research},
	volume = {62},
	issn = {0261-5177},
	shorttitle = {Large sample size, significance level, and the effect size},
	url = {https://www.sciencedirect.com/science/article/pii/S026151771730078X},
	doi = {10.1016/j.tourman.2017.03.026},
	abstract = {The increasing availability of and attention to big data accumulated on different aspects of demand and supply side of industries has resulted in utilization of large samples for academic publications as well. Using large samples, however, creates the issue of guaranteed statistical significance and thus demands reporting the practical significance by using effect size measures. This manuscript is a guide to inform tourism and hospitality academia of the effect size measures for the most commonly used statistical tests.},
	language = {en},
	urldate = {2021-12-13},
	journal = {Tourism Management},
	author = {Khalilzadeh, Jalayer and Tasci, Asli D. A.},
	month = oct,
	year = {2017},
	keywords = {Big data, Effect size, Large sample, Practical significance, Statistical significance},
	pages = {89--96},
	file = {ScienceDirect Snapshot:/Users/isabelleborucki/Zotero/storage/RBMSUTHQ/S026151771730078X.html:text/html},
}

@article{hassani_forecasting_2015,
	title = {Forecasting with {Big} {Data}: {A} {Review}},
	volume = {2},
	issn = {2198-5812},
	shorttitle = {Forecasting with {Big} {Data}},
	url = {https://doi.org/10.1007/s40745-015-0029-9},
	doi = {10.1007/s40745-015-0029-9},
	abstract = {Big Data is a revolutionary phenomenon which is one of the most frequently discussed topics in the modern age, and is expected to remain so in the foreseeable future. In this paper we present a comprehensive review on the use of Big Data for forecasting by identifying and reviewing the problems, potential, challenges and most importantly the related applications. Skills, hardware and software, algorithm architecture, statistical significance, the signal to noise ratio and the nature of Big Data itself are identified as the major challenges which are hindering the process of obtaining meaningful forecasts from Big Data. The review finds that at present, the fields of Economics, Energy and Population Dynamics have been the major exploiters of Big Data forecasting whilst Factor models, Bayesian models and Neural Networks are the most common tools adopted for forecasting with Big Data.},
	language = {en},
	number = {1},
	urldate = {2021-12-13},
	journal = {Annals of Data Science},
	author = {Hassani, Hossein and Silva, Emmanuel Sirimal},
	month = mar,
	year = {2015},
	pages = {5--19},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/5WH967EQ/Hassani and Silva - 2015 - Forecasting with Big Data A Review.pdf:application/pdf},
}

@article{pochat_audit_nodate,
	title = {An {Audit} of {Facebook}’s {Political} {Ad} {Policy} {Enforcement}},
	abstract = {Major technology companies strive to protect the integrity of political advertising on their platforms by implementing and enforcing self-regulatory policies that impose transparency requirements on political ads. In this paper, we quantify whether Facebook’s current enforcement correctly identiﬁes political ads and ensures compliance by advertisers. In a comprehensive, large-scale analysis of 4.2 million political and 29.6 million non-political ads from 215,030 advertisers, we identify ads correctly detected as political (true positives), ads incorrectly detected (false positives), and ads missed by detection (false negatives). Facebook’s current enforcement appears imprecise: 61\% more ads are missed than are detected worldwide, and 55\% of U.S. detected ads are in fact non-political. Detection performance is uneven across countries, with some having up to 53 times higher false negative rates among clearly political pages than in the U.S. Moreover, enforcement appears inadequate for preventing systematic violations of political advertising policies: for example, advertisers were able to continue running political ads without disclosing them while they were temporarily prohibited in the U.S. We attribute these ﬂaws to ﬁve gaps in Facebook’s current enforcement and transparency implementation, and close with recommendations to improve the security of the online political ad ecosystem.},
	language = {en},
	author = {Pochat, Victor Le and Edelson, Laura and Goethem, Tom Van},
	pages = {22},
	file = {Pochat et al. - An Audit of Facebook’s Political Ad Policy Enforce.pdf:/Users/isabelleborucki/Zotero/storage/G6NTTFK7/Pochat et al. - An Audit of Facebook’s Political Ad Policy Enforce.pdf:application/pdf},
}

@book{noauthor_apis_nodate,
	title = {{APIs} for social scientists:{A} collaborative review {\textbar} 2021\_apis\_for\_social\_scientists\_a\_collaborative\_review.knit},
	shorttitle = {{APIs} for social scientists},
	url = {https://bookdown.org/paul/apis_for_social_scientists/},
	abstract = {This book provides an introduction to different APIs that may be useful to social scientists.},
	urldate = {2021-12-12},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/6Y2Q4EDU/apis_for_social_scientists.html:text/html},
}

@article{wang_connecting_2021,
	title = {Connecting the {Parts} with the {Whole}: {Toward} an {Information} {Ecology} {Theory} of {Digital} {Innovation} {Ecosystems}},
	volume = {45},
	issn = {02767783, 21629730},
	shorttitle = {Connecting the {Parts} with the {Whole}},
	url = {https://misq.org/connecting-the-parts-with-the-whole-toward-an-information-ecology-theory-of-digital-innovation-ecosystems.html},
	doi = {10.25300/MISQ/2021/15864},
	number = {1},
	urldate = {2021-12-10},
	journal = {MIS Quarterly},
	author = {Wang, Ping},
	month = mar,
	year = {2021},
	pages = {397--422},
}

@misc{noauthor_ensemble_nodate,
	title = {Ensemble methods: bagging, boosting and stacking {\textbar} by {Joseph} {Rocca} {\textbar} {Towards} {Data} {Science}},
	url = {https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205},
	urldate = {2021-12-10},
	file = {Ensemble methods\: bagging, boosting and stacking | by Joseph Rocca | Towards Data Science:/Users/isabelleborucki/Zotero/storage/TMQWPWS4/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205.html:text/html},
}

@misc{noauthor_ttrodrigziterake_nodate,
	title = {ttrodrigz/iterake: {Create} weights with iterative raking.},
	url = {https://github.com/ttrodrigz/iterake},
	urldate = {2021-12-07},
	keywords = {Gewichte berechnen},
}

@misc{noauthor_logistische_nodate-1,
	title = {Logistische {Regression} - {Beispiel} in {R}},
	url = {https://www.inwt-statistics.de/blog-artikel-lesen/Logistische_Regression_Beispiel_mit_R.html},
	urldate = {2021-12-04},
	file = {Logistische Regression - Beispiel in R:/Users/isabelleborucki/Zotero/storage/MPNCPTF6/Logistische_Regression_Beispiel_mit_R.html:text/html},
}

@misc{noauthor_passende_nodate,
	title = {Das passende {Statistik}-{Paket} finden - fu:stat thesis - {Wikis} der {Freien} {Universität} {Berlin}},
	url = {https://wikis.fu-berlin.de/display/fustat/Das+passende+Statistik-Paket+finden},
	urldate = {2021-12-04},
	file = {Das passende Statistik-Paket finden - fu\:stat thesis - Wikis der Freien Universität Berlin:/Users/isabelleborucki/Zotero/storage/QXMK6SW4/Das+passende+Statistik-Paket+finden.html:text/html},
}

@article{kolb_verlasslichkeit_2004,
	title = {Verlässlichkeit von {Inhaltsanalysedaten}. {Reliabilitätstest}, {Errechnen} und {Interpretieren} von {Reliabilitätskoeffizienten} für mehr als zwei {Codierer}},
	volume = {52},
	issn = {1615-634X},
	url = {https://www.nomos-elibrary.de/10.5771/1615-634x-2004-3-335/verlaesslichkeit-von-inhaltsanalysedaten-reliabilitaetstest-errechnen-und-interpretieren-von-reliabilitaetskoeffizienten-fuer-mehr-als-zwei-codierer-volume-52-2004-issue-3},
	doi = {10.5771/1615-634x-2004-3-335},
	abstract = {eBook: Verlässlichkeit von Inhaltsanalysedaten. Reliabilitätstest, Errechnen und Interpretieren von Reliabilitätskoeffizienten für mehr als zwei Codierer (ISSN1615-634X) von aus dem Jahr 2004},
	language = {de},
	number = {3},
	urldate = {2021-12-02},
	journal = {M\&K Medien \& Kommunikationswissenschaft},
	author = {Kolb, Steffen},
	month = sep,
	year = {2004},
	note = {Publisher: Nomos Verlagsgesellschaft mbH \& Co. KG},
	pages = {335--354},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/FW8ZSUSL/Kolb - 2004 - Verlässlichkeit von Inhaltsanalysedaten. Reliabili.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/I4UKLPYB/verlaesslichkeit-von-inhaltsanalysedaten-reliabilitaetstest-errechnen-und-interpretieren-von-re.html:text/html},
}

@misc{noauthor_notitle_nodate-4,
	url = {http://localhost:17360/session/viewhtml143212b02bf7/index.html},
	urldate = {2022-02-27},
	file = {localhost\:17360/session/viewhtml143212b02bf7/index.html:/Users/isabelleborucki/Zotero/storage/LS4Y6CY9/index.html:text/html},
}

@misc{noauthor_faq_nodate,
	title = {{FAQ}: {What} are pseudo {R}-squareds?},
	url = {https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/},
	urldate = {2022-02-27},
	file = {FAQ\: What are pseudo R-squareds?:/Users/isabelleborucki/Zotero/storage/Z32H9PY4/faq-what-are-pseudo-r-squareds.html:text/html},
}

@misc{noauthor_stat-ease_nodate,
	title = {Stat-{Ease} » v12 » {Advanced} {Topics} » {Logistic} {Regression} » {Fit} {Statistics} » {Pseudo} {R}-{Squared} » {Tjur} {R}-{Squared}},
	url = {https://www.statease.com/docs/v12/contents/advanced-topics/glm/tjur-pseudo-r-squared/},
	urldate = {2022-02-26},
	file = {Stat-Ease » v12 » Advanced Topics » Logistic Regression » Fit Statistics » Pseudo R-Squared » Tjur R-Squared:/Users/isabelleborucki/Zotero/storage/B9CY5GKT/tjur-pseudo-r-squared.html:text/html},
}

@misc{noauthor_graphpad_nodate,
	title = {{GraphPad} {Prism} 9 {Curve} {Fitting} {Guide} - {Pseudo} {R} squared values for multiple logistic regression},
	url = {https://www.graphpad.com/guides/prism/latest/curve-fitting/reg_mult_logistic_gof_pseudo_r_squared.htm},
	urldate = {2022-02-26},
	file = {GraphPad Prism 9 Curve Fitting Guide - Pseudo R squared values for multiple logistic regression:/Users/isabelleborucki/Zotero/storage/36FLPDHP/reg_mult_logistic_gof_pseudo_r_squared.html:text/html},
}

@article{de_zuniga_abating_2022,
	title = {Abating {Dissonant} {Public} {Spheres}: {Exploring} the {Effects} of {Affective}, {Ideological} and {Perceived} {Societal} {Political} {Polarization} on {Social} {Media} {Political} {Persuasion}},
	volume = {0},
	issn = {1058-4609},
	shorttitle = {Abating {Dissonant} {Public} {Spheres}},
	url = {https://doi.org/10.1080/10584609.2022.2139310},
	doi = {10.1080/10584609.2022.2139310},
	abstract = {Prior research underscores the utility of political persuasion to sustain more engaged democracies and as a vital element in political campaigning processes. When citizens display increased openness to political attitude change, societies benefit as diverse viewpoints thrive, and less dissonant public spheres may be fostered. This contrasts with today’s contentious political and media environment. With political polarization on the rise, and new social media avenues enabling citizens to curate more diverse news consumption patterns, little is known about how this polarization influences the ability for citizens to be politically persuaded in social media environments. Relying on representative US panel survey data, this study seeks to shed light on this phenomenon by testing the effects of three distinct types of political polarization: Affective, ideological, and perceived societal. Panel autoregressive causal order regression and structural equation models clarify the direct and indirect negative role of polarization in predicting social media political persuasion. Theoretical implications of these findings, limitations of the study, and suggestions for future research are all discussed.},
	number = {0},
	urldate = {2022-11-07},
	journal = {Political Communication},
	author = {De Zúñiga, Homero Gil and Marné, Hugo Marcos and Carty, Emily},
	month = nov,
	year = {2022},
	keywords = {democracy, political polarization, dissonant public spheres, social media news use, Social media political persuasion},
	pages = {1--19},
}

@misc{lewinson_dealing_2022,
	title = {Dealing with {Outliers} {Using} {Three} {Robust} {Linear} {Regression} {Models}},
	url = {https://towardsdatascience.com/dealing-with-outliers-using-three-robust-linear-regression-models-544cfbd00767},
	abstract = {With a hands-on example of using Huber, RANSAC and Theil-Sen regression algorithms},
	language = {en},
	urldate = {2022-10-22},
	journal = {Medium},
	author = {Lewinson, Eryk},
	month = aug,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/U38M7DC3/dealing-with-outliers-using-three-robust-linear-regression-models-544cfbd00767.html:text/html},
}

@book{bogner_interviews_2014,
	address = {Wiesbaden},
	title = {Interviews mit {Experten}},
	isbn = {978-3-531-19415-8 978-3-531-19416-5},
	url = {http://link.springer.com/10.1007/978-3-531-19416-5},
	language = {de},
	urldate = {2022-10-14},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5},
	keywords = {Datenerhebung, Auswertungsverfahren, Gesprächsführung, Qualitative Methoden},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/EFCDYT7M/Bogner et al. - 2014 - Interviews mit Experten.pdf:application/pdf},
}

@incollection{bogner_zugang_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Der {Zugang} zu den {Experten}: die {Vorbereitung} der {Erhebung}},
	isbn = {978-3-531-19416-5},
	shorttitle = {Der {Zugang} zu den {Experten}},
	url = {https://doi.org/10.1007/978-3-531-19416-5_4},
	abstract = {Nach unseren theoretischen Überlegungen zum Begriff des Experteninterviews und Expertenwissens wenden wir uns nun verstärkt forschungspraktischen Themen zu: Welche Vorarbeiten müssen wir erledigen, bevor wir uns in die konkrete Gesprächssituation begeben können? Interviews mit Experten und Expertinnen bedürfen der sorgfältigen Planung. Dazu gehört die gründliche Entwicklung eines Interviewleitfadens, der vor allem als Checkliste und Richtschnur des Interviews dient (4.1.). Zu den vorbereitenden Arbeiten gehört auch die nachvollziehbare Auswahl der zu befragenden Experten (das sogenannte Sampling) sowie die Kontaktaufnahme und Terminvereinbarung für das Interview (4.2). Insbesondere letzterer Aspekt ist nicht zu unterschätzen, geht es doch darum Personen, für die Zeitknappheit fast schon zum Professionshabitus gehört, von der Notwendigkeit eines wissenschaftlichen Interviews zu überzeugen. Bereits bei der Interviewplanung sollte zudem entschieden werden, wie die Sprachdaten dokumentiert werden (4.3). Besondere Herausforderungen beinhalten Experteninterviews, die fremdsprachlich geführt werden – hier ist besondere Sorgfalt bei der Vorbereitung der Gespräche angezeigt (4.4).},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_4},
	pages = {27--47},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/FGWZCL2R/Bogner et al. - 2014 - Der Zugang zu den Experten die Vorbereitung der E.pdf:application/pdf},
}

@incollection{bogner_interaktion_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Die {Interaktion} im {Interview}: {Frageformulierung} und {Strategien} der {Gesprächsführung}},
	isbn = {978-3-531-19416-5},
	shorttitle = {Die {Interaktion} im {Interview}},
	url = {https://doi.org/10.1007/978-3-531-19416-5_5},
	abstract = {Das Interview selbst ist eine komplexe soziale Interaktionssituation, in der die Interviewer nicht nur methodisch-regelgeleitet, sondern häufig auch intuitiv agieren und reagieren (müssen). Das bedeutet allerdings nicht, dass eine tiefer gehende methodische Reflexion deshalb müßig wäre – ganz im Gegenteil. Zunächst möchten wir uns typische Interaktionssituationen, wie sie in Experteninterviews häufig vorkommen, näher anschauen (Kap. 5.1): Welche Rollenerwartungen und Einschätzungen gibt es, die den Gesprächsverlauf prägen? Welchen Nutzen und welche Gefahren bieten sie für den Erhebungserfolg? Anschließend wird die Interaktionssituation unter Gender-Aspekten analysiert. Im Mittelpunkt steht die Frage, auf welche Art und Weise die Kategorie Geschlecht im Interview wirksam werden kann – und was dies für die Durchführung von Interviews heißt (Kap. 5.2). Abschließend wird dann dargelegt, welche Hinweise für die Formulierung von Interviewfragen sich aus unseren Analysen der Interviewsituation gewinnen lassen (Kap. 5.3).},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_5},
	pages = {49--69},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/ADRMV333/Bogner et al. - 2014 - Die Interaktion im Interview Frageformulierung un.pdf:application/pdf},
}

@incollection{bogner_wissens-_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Wissens- und {Interviewformen} – {Varianten} des {Experteninterviews}},
	isbn = {978-3-531-19416-5},
	url = {https://doi.org/10.1007/978-3-531-19416-5_3},
	abstract = {Wie wir im vorangegangenen Kapitel gesehen haben, ist es nicht einfach ihr Verfügen über ein „besonderes Wissen“, das das Interesse der Sozialwissenschaftler an den Experten erweckt. Vielmehr sind Expertinnen für unsere Untersuchungen deshalb relevant, weil sie in einer sozialen oder organisationalen Position stehen, in der sie ihr Wissen und ihre Deutungen für einen breiteren sozialen Kontext relevant oder prägend machen können.},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_3},
	pages = {17--25},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/NCSBR5YT/Bogner et al. - 2014 - Wissens- und Interviewformen – Varianten des Exper.pdf:application/pdf},
}

@incollection{bogner_qualitatskriterien_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Qualitätskriterien der {Forschung}},
	isbn = {978-3-531-19416-5},
	url = {https://doi.org/10.1007/978-3-531-19416-5_7},
	abstract = {Im letzten Kapitel dieser Einführung wird es nicht darum gehen, die umfangreichen Qualitätskriterien qualitativer Sozialforschung darzulegen. Diese sind in der einschlägigen Literatur hinlänglich diskutiert worden. Vielmehr werden Besonderheiten im Hinblick auf das Experteninterview thematisiert werden. Dabei geht es in erster Linie um zentrale Aspekte der Forschungsethik, also spezifische Fragen der Instrumentalisierung der Befragten, der Freiwilligkeit der Teilnahme am Interview und das nicht zu unterschätzende Problem der Anonymisierung von Experteninterviews (7.1). Im Anschluss daran werden wir diskutieren, wie die Güte des Forschungsprozesses sichergestellt werden kann. Letztlich wird damit die Fundamentalfrage angerissen, wie gute von schlechter Forschung unterschieden werden kann. (7.2).},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_7},
	pages = {87--95},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/QABCB2W5/Bogner et al. - 2014 - Qualitätskriterien der Forschung.pdf:application/pdf},
}

@incollection{bogner_auswertungsverfahren_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Auswertungsverfahren für {Experteninterviews}},
	isbn = {978-3-531-19416-5},
	url = {https://doi.org/10.1007/978-3-531-19416-5_6},
	abstract = {Für die Auswertung von Experteninterviews gibt es (noch) kein kanonisiertes Verfahren. Das heißt, bislang hat sich keines der bekannten Auswertungsverfahren qualitativer Sozialforschung zu der Experteninterview-spezifischen Methode entwickelt; es hat sich auch noch keine eigenständige Auswertungsmethode spezifisch für Experteninterviews herausgebildet. Im Prinzip können daher alle Auswertungsverfahren zur Anwendung kommen, z. B. Code-basierte Verfahren wie sie in der Grounded Theory oder in der qualitativen Inhaltsanalyse üblich sind. Es können aber auch sequenzanalytische Verfahren zur Anwendung kommen, wie dies etwa im Rahmen der hermeneutischen Wissenssoziologie oder der objektiven Hermeneutik der Fall ist (vgl. dazu die entsprechenden Beiträge in Flick et al. 2003). Auch Kombinationen von Auswertungsmethoden sind möglich.},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_6},
	pages = {71--86},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/R8R348J9/Bogner et al. - 2014 - Auswertungsverfahren für Experteninterviews.pdf:application/pdf},
}

@incollection{bogner_ausblick_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Ausblick},
	isbn = {978-3-531-19416-5},
	url = {https://doi.org/10.1007/978-3-531-19416-5_8},
	abstract = {Das vorliegende Buch versteht sich in erster Linie als pragmatische Einführung und praktischer Leitfaden zur Vorbereitung, Durchführung und Interpretation von Experteninterviews. Gleichzeitig gibt es den aktuellen Stand der methodologischen und methodischen Diskussion wieder. Dabei wird zweierlei deutlich: Zum einen hat sich die Debatte darüber vertieft, wer als Experte gelten kann und vor allem: welches Wissen wir uns durch Experteninterviews verfügbar machen können und wollen. Diese wissenssoziologische Debatte ist deswegen zentral, weil sie das theoretische Fundament der Methodenpraxis darstellt; sie begründet den Anwendungs- und Geltungsbereich des Experteninterviews. Zum anderen hat sich die methodische Debatte merklich intensiviert; das Experteninterview hat auf diese Weise ein schärferes methodisches Profil gewonnen. Es gibt – bei aller Diversität der Zwecke und Anwendungsbereiche von Experteninterviews – viele Gemeinsamkeiten hinsichtlich des generellen Settings, des Zugangs, der Interviewtechniken usw. Das heißt nicht, dass das Experteninterview bereits ein kanonisches Verfahren qualitativer Forschung und die Debatte darüber weitgehend abgeschlossen wäre. Letzteres ist wenig realistisch und wahrscheinlich auch gar nicht wünschenswert. Denn wie bei allen Methodendiskussionen beruhen Beiträge zum Experteninterview auf der Reflexion über Forschungspraktiken; letztlich sind Methoden ja Instrumente der Generierung und Analyse von empirischem Datenmaterial. Insofern sind die Ausführungen über methodische Standards auch immer vorläufig. Methoden verändern sich mit der Forschung selbst. Sie werden revidiert, modifiziert und verfeinert.},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_8},
	pages = {97--98},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/P47AT3V4/Bogner et al. - 2014 - Ausblick.pdf:application/pdf},
}

@incollection{bogner_einleitung_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Einleitung: {Das} {Expertinneninterview} – eine {Methode} qualitativer {Sozialforschung}},
	isbn = {978-3-531-19416-5},
	shorttitle = {Einleitung},
	url = {https://doi.org/10.1007/978-3-531-19416-5_1},
	abstract = {Dieses Buch versteht sich als praktische und weitgehend pragmatische Einführung in das Expertinneninterview. Unser Ziel besteht darin, Studierenden sozial- und kulturwissenschaftlicher Fachrichtungen sowie all jenen, die sich in der Forschungspraxis mit Experteninterviews auseinandersetzen, ein gut strukturiertes und didaktisch orientiertes Lehrbuch für die Vorbereitung, Durchführung und Auswertung von Expertinneninterviews vorzulegen. Weitläufige methodologische Grundsatzdebatten werden daher vermieden.},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_1},
	pages = {1--7},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/SPNEIU7H/Bogner et al. - 2014 - Einleitung Das Expertinneninterview – eine Method.pdf:application/pdf},
}

@incollection{bogner_wer_2014,
	address = {Wiesbaden},
	series = {Qualitative {Sozialforschung}},
	title = {Wer ist ein {Experte}? {Wissenssoziologische} {Grundlagen} des {Expertinneninterviews}},
	isbn = {978-3-531-19416-5},
	shorttitle = {Wer ist ein {Experte}?},
	url = {https://doi.org/10.1007/978-3-531-19416-5_2},
	abstract = {Wir möchten nun dem Begriff des Experten etwas genauer nachgehen. Dies ist keine bloße akademische Pflichtübung. Tatsächlich ist ja das Experteninterview zunächst – anders als andere Formen des qualitativen Interviews – nicht über eine bestimmte methodische Vorgehensweise definiert, so wie dies z. B. beim problemzentrierten Interview, beim episodischen oder beim narrativen Interview der Fall ist. Das Experteninterview definiert sich vielmehr – jedenfalls der unmittelbaren Wortbedeutung nach – über den Gegenstand seines Interesses: den Experten. Diese Tatsache ruft immer wieder Kritik hervor. Kann sich eine Methode sinnvoll über den Kreis der Untersuchungspersonen bestimmen? Ein zentraler Einwand lautet: Es gebe schließlich ja auch nicht das „Beamteninterview“ oder das „Hausfraueninterview“.},
	language = {de},
	urldate = {2022-10-14},
	booktitle = {Interviews mit {Experten}: {Eine} praxisorientierte {Einführung}},
	publisher = {Springer Fachmedien},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	editor = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_2},
	pages = {9--15},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/K85WA3BI/Bogner et al. - 2014 - Wer ist ein Experte Wissenssoziologische Grundlag.pdf:application/pdf},
}

@article{estrada_qualitative_2017,
	title = {Qualitative {Analysis} {Using} {R}: {A} {Free} {Analytic} {Tool}},
	issn = {2160-3715, 1052-0147},
	shorttitle = {Qualitative {Analysis} {Using} {R}},
	url = {https://nsuworks.nova.edu/tqr/vol22/iss4/2/},
	doi = {10.46743/2160-3715/2017.2659},
	abstract = {R (R Development Core Team, 2011) is a powerful tool to analyze statistical data. In recent years R has gained popularity because the software is free and open source. However, evaluators and researchers do not exclusively use quantitative data. It is possible to perform qualitative analysis in R. Using data from a case study exploring a family psychoeducation recovery course, this article provides users a tutorial on how to perform a qualitative analysis and data visualization using R.},
	language = {en},
	urldate = {2022-10-14},
	journal = {The Qualitative Report},
	author = {Estrada, Samantha},
	month = apr,
	year = {2017},
	file = {Estrada - 2017 - Qualitative Analysis Using R A Free Analytic Tool.pdf:/Users/isabelleborucki/Zotero/storage/RSUH4X2E/Estrada - 2017 - Qualitative Analysis Using R A Free Analytic Tool.pdf:application/pdf},
}

@incollection{tiropanis_data_2022,
	title = {Data {Observatories}: {Decentralized} {Data} and {Interdisciplinary} {Research}},
	isbn = {978-1-00-325047-0},
	shorttitle = {Data {Observatories}},
	abstract = {Sharing data and observations has been at the center of academic discourse for centuries. The Internet has provided a decentralized platform for communication that supports data discovery and data sharing on an unprecedented scale. Data analysis methodologies and digital platforms can provide observations on those data. Such methodologies often cross disciplines; interdisciplinary areas such as Web science and Internet science have explored techniques that enable meaningful analysis of data on activity taking place on the Web and the Internet. Scientific discourse could greatly benefit from these techniques if challenges on sharing data and observations could be addressed.
                     This chapter identifies such challenges and discusses the extent to which current data-sharing platforms and decentralized data infrastructures are in a position to address them. It identifies the shortcomings of existing systems in capturing meta-information, which is essential for rigorous scientific discourse, and in providing ethical and legal safeguards on data collection and analysis, taking into account the consent of data subjects and of data publishers. It subsequently discusses the concept of data observatories as decentralized platforms for sharing data and observations on the Internet and the lessons learned from the design and deployment of such systems in academia over the past decade. Further, it outlines a reference architecture for the deployment of data observatories and it discusses their potential to support scientific discourse within and across disciplines.
                     Beyond academia, the paper discusses the potential impact of decentralized data observatories in society and the economy by supporting evidence-based discourse and by enabling data-driven innovation by small and medium-sized enterprises, lowering the data barrier to innovation. It concludes with discussion on the necessary conditions of decentralization, digital literacy requirements and policies to support wider engagement in scientific discourse.},
	booktitle = {The {Internet} and {Philosophy} of {Science}},
	publisher = {Routledge},
	author = {Tiropanis, Thanassis},
	year = {2022},
	note = {Num Pages: 17},
}

@misc{editors_old_2022,
	title = {Old {Principles}, {New} {Approaches}: {Bayes} in {Practice}},
	shorttitle = {Old {Principles}, {New} {Approaches}},
	url = {https://towardsdatascience.com/old-principles-new-approaches-bayes-in-practice-f0c3714a68d3},
	abstract = {Our weekly selection of must-read Editors’ Picks and original features},
	language = {en},
	urldate = {2022-09-23},
	journal = {Medium},
	author = {Editors, T. D. S.},
	month = sep,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/VIAD2EBC/old-principles-new-approaches-bayes-in-practice-f0c3714a68d3.html:text/html},
}

@misc{brownell_3_2022,
	title = {3 {Common} {Strategies} to {Measure} {Bias} in {NLP} {Models} (2022)},
	url = {https://towardsdatascience.com/3-common-strategies-to-measure-bias-in-nlp-models-2022-b948a671d257},
	abstract = {Strategies of quantifying bias in language models for responsible AI},
	language = {en},
	urldate = {2022-09-23},
	journal = {Medium},
	author = {Brownell, Adam},
	month = sep,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/YREVP79N/3-common-strategies-to-measure-bias-in-nlp-models-2022-b948a671d257.html:text/html},
}

@misc{long_new_2019,
	title = {A new package for panel data analysis in {R} {\textbar} {R}-bloggers},
	url = {https://www.r-bloggers.com/2019/05/a-new-package-for-panel-data-analysis-in-r/},
	abstract = {It has been a long time coming, but my R package panelr is now on CRAN. Since I started work on it well over a year ago, it has become essential to my own workflow and I hope it can be useful for others. panel\_data object class One key contribution, that I hope can help other developers, is the creation of a panel\_data object class. It is a modified tibble, which is itself a modified data.frame. panel\_data frames are grouped by entity, so many operations (e.g., mean(), cumsum()) performed by dplyr’s mutate() are groupwise operations. The panel\_data frame also works very hard to stay in sequential order to ensure that lag and lead operations within mutate() make sense. panel\_data frames are in “long” format, in which each row is a unique combination of entity and time point. Let’s run through a quick example. First, the package includes the example “raw’ dataset called WageData, which comes from the Panel Study of Income Dynamics. This is what it looks like: library(panelr) data("WageData") head(WageData) exp wks occ ind south smsa ms fem union ed blk lwage t id 1 3 32 0 0 1 0 1 0 0 9 0 5.56068 1 1 2 4 43 0 0 1 0 1 0 0 9 0 5.72031 2 1 3 5 40 0 0 1 0 1 0 0 9 0 5.99645 3 1 4 6 39 0 0 1 0 1 0 0 9 0 5.99645 4 1 5 7 42 0 1 1 0 1 0 0 9 0 6.06146 5 1 6 8 35 0 1 1 0 1 0 0 9 0 6.17379 6 1 The key columns are id and t. They tell you which respondent and which time point the row refers to, respectively. Let’s convert it into a panel\_data frame. wages \% mutate( wks\_mean = mean(wks), \# this is the person-level mean wks\_lag = lag(wks), \# this will have a value of NA when t = 1 cumu\_wages = cumsum(exp(lwage)) \# cumulative summation works within person ) \%{\textgreater}\% select(wks, wks\_mean, wks\_lag, lwage, cumu\_wages) \# Panel data: 4,165 x 7 \# entities: id [595] \# wave variable: t [1, 2, 3, ... (7 waves)] id t wks wks\_mean wks\_lag lwage cumu\_wages 1 1 1 32 37.6 NA 5.56 260. 2 1 2 43 37.6 32 5.72 565. 3 1 3 40 37.6 43 6.00 967. 4 1 4 39 37.6 40 6.00 1369. 5 1 5 42 37.6 39 6.06 1798. 6 1 6 35 37.6 42 6.17 2278. 7 1 7 32 37.6 35 6.24 2793. 8 2 1 34 31.6 NA 6.16 475. 9 2 2 27 31.6 34 6.21 975. 10 2 3 33 31.6 27 6.26 1500. \# ... with 4,155 more rows Notice also that when you use select, the id and t columns ride along even though you didn’t explicitly ask for them. The idea here is that it isn’t panel\_data frame without them. It works the same way using base R subsetting: wages["wks"] \# Panel data: 4,165 x 3 \# entities: id [595] \# wave variable: t [1, 2, 3, ... (7 waves)] id t wks 1 1 1 32 2 1 2 43 3 1 3 40 4 1 4 39 5 1 5 42 6 1 6 35 7 1 7 32 8 2 1 34 9 2 2 27 10 2 3 33 \# ... with 4,155 more rows You can get just the one column using double brackets or the \$ subsetting method. But note that using base R sub-assignment, you don’t need to sweat those extra columns: wages["wage"]},
	language = {en-US},
	urldate = {2022-09-23},
	author = {Long, R. on Jacob},
	month = may,
	year = {2019},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/7M8GB3B8/a-new-package-for-panel-data-analysis-in-r.html:text/html},
}

@misc{w_answer_2014,
	title = {Answer to "{Design} matrix for {MLM} from library(lme4) with fixed and random effects"},
	url = {https://stackoverflow.com/a/25559158},
	urldate = {2022-09-23},
	journal = {Stack Overflow},
	author = {W, Alex},
	month = aug,
	year = {2014},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/K6LW5G4G/design-matrix-for-mlm-from-librarylme4-with-fixed-and-random-effects.html:text/html},
}

@misc{w_design_2014,
	type = {Forum post},
	title = {Design matrix for {MLM} from library(lme4) with fixed and random effects},
	url = {https://stackoverflow.com/q/25538199},
	urldate = {2022-09-23},
	journal = {Stack Overflow},
	author = {W, Alex},
	month = aug,
	year = {2014},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/72MJES3Q/design-matrix-for-mlm-from-librarylme4-with-fixed-and-random-effects.html:text/html},
}

@misc{noauthor_recoding_nodate,
	title = {Recoding ({Variable}) {Values} in {R}},
	url = {https://www.anyamemensah.com/blog/recoding},
	abstract = {Recoding (variable) values is a common data cleaning task. In this post, I share several methods for quickly recoding the values of many variables in the R Environment…},
	language = {en-US},
	urldate = {2022-09-23},
	journal = {Ama Nyame-Mensah},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/ELLRRAFM/recoding.html:text/html},
}

@misc{brugger_guide_2021,
	title = {A {Guide} to {Panel} {Data} {Regression}: {Theoretics} and {Implementation} with {Python}.},
	shorttitle = {A {Guide} to {Panel} {Data} {Regression}},
	url = {https://towardsdatascience.com/a-guide-to-panel-data-regression-theoretics-and-implementation-with-python-4c84c5055cf8},
	abstract = {Panel data regression is a powerful way to control dependencies of unobserved, independent variables on a dependent variable, which can…},
	language = {en},
	urldate = {2022-09-15},
	journal = {Medium},
	author = {Brugger, Bernhard},
	month = feb,
	year = {2021},
	keywords = {Panel data regression},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/4XIZ384W/a-guide-to-panel-data-regression-theoretics-and-implementation-with-python-4c84c5055cf8.html:text/html},
}

@article{cassino_moving_2020,
	title = {Moving {Beyond} {Sex}: {Measuring} {Gender} {Identity} in {Telephone} {Surveys}},
	volume = {13},
	shorttitle = {Moving {Beyond} {Sex}},
	url = {https://www.surveypractice.org/article/13697-moving-beyond-sex-measuring-gender-identity-in-telephone-surveys},
	doi = {10.29115/SP-2020-0009},
	abstract = {While researchers have long understood that sex and gender are theoretically distinct concepts, much survey research continues to rely on the sex of respondents as a proxy for their gender. Recent work on political and social attitudes has shown that gender has far-reaching consequences for attitudes that are not neatly summed up by measures of sex, but measures of gender identity have generally been used either in forms that are too lengthy for most survey research or have only been used in online modalities. Longer sets of gender identity items may be theoretically desirable, but a gender identity item embedded in a live-caller random digit dialing survey in New Jersey shows that just one gender identity item can account for a great deal of within-sex variance in political and social attitudes without leading to an overly high rate of refusals.},
	language = {en},
	number = {1},
	urldate = {2022-09-15},
	journal = {Survey Practice},
	author = {Cassino, Dan},
	month = jul,
	year = {2020},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/CD5TPHZV/Cassino - 2020 - Moving Beyond Sex Measuring Gender Identity in Te.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/CAIQ9M7I/13697-moving-beyond-sex-measuring-gender-identity-in-telephone-surveys.html:text/html},
}

@misc{noauthor_fair_nodate,
	title = {{FAIR} {Enough}},
	url = {https://fair-enough.semanticscience.org/collections},
	urldate = {2022-09-04},
	file = {FAIR Enough:/Users/isabelleborucki/Zotero/storage/Y8Q9VCWR/collections.html:text/html},
}

@article{amrhein_discuss_2022,
	title = {Discuss practical importance of results based on interval estimates and p-value functions, not only on point estimates and null p-values},
	volume = {37},
	issn = {0268-3962},
	url = {https://doi.org/10.1177/02683962221105904},
	doi = {10.1177/02683962221105904},
	abstract = {It has long been argued that we need to consider much more than an observed point estimate and a p-value to understand statistical results. One of the most persistent misconceptions about p-values is that they are necessarily calculated assuming a null hypothesis of no effect is true. Instead, p-values can and should be calculated for multiple hypothesized values for the effect size. For example, a p-value function allows us to visualize results continuously by examining how the p-value varies as we move across possible effect sizes. For more focused discussions, a 95\% confidence interval shows the subset of possible effect sizes that have p-values larger than 0.05 as calculated from the same data and the same background statistical assumptions. In this sense a confidence interval can be taken as showing the effect sizes that are most compatible with the data, given the assumptions, and thus may be better termed a compatibility interval. The question that should then be asked is whether any or all of the effect sizes within the interval are substantial enough to be of practical importance.},
	language = {en},
	number = {3},
	urldate = {2022-09-04},
	journal = {Journal of Information Technology},
	author = {Amrhein, Valentin and Greenland, Sander},
	month = sep,
	year = {2022},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {p-value, Compatibility curve, confidence interval, credible interval, s-value, Shannon information, statistical significance, uncertainty interval},
	pages = {316--320},
	file = {SAGE PDF Full Text:/Users/isabelleborucki/Zotero/storage/5Q2IKDAD/Amrhein and Greenland - 2022 - Discuss practical importance of results based on i.pdf:application/pdf},
}

@book{noauthor_chapter_nodate,
	title = {Chapter 18 {Internet} {Archive} {API} and {archiveRetriever} {\textbar} 2021\_apis\_for\_social\_scientists\_a\_collaborative\_review.knit},
	url = {https://bookdown.org/paul/apis_for_social_scientists/internet-archive-api-and-archiveretriever.html},
	abstract = {This book provides an introduction to different APIs that may be useful to social scientists.},
	urldate = {2022-06-28},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/VGZEUP6B/internet-archive-api-and-archiveretriever.html:text/html},
}

@misc{wellman_replication_2022,
	title = {Replication {Data} for "{The} {Extraterritorial} {Voting} {Rights} and {Restrictions} {Dataset} (1950 - 2020)"},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DIJQ3H},
	abstract = {This paper introduces the Extraterritorial Rights and Restrictions dataset (EVRR), the first global time-series dataset of non-resident citizen vot...},
	language = {en},
	urldate = {2022-06-23},
	publisher = {Harvard Dataverse},
	author = {Wellman, Elizabeth Iams and Allen, Nathan Wallace and Nyblade, Benjamin},
	month = jun,
	year = {2022},
	doi = {10.7910/DVN/DIJQ3H},
	note = {Type: dataset},
	keywords = {Social Sciences},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/H7DFT2BG/dataset.html:text/html},
}

@article{ranganathan_common_2017,
	title = {Common pitfalls in statistical analysis: {Logistic} regression},
	volume = {8},
	issn = {2229-3485},
	shorttitle = {Common pitfalls in statistical analysis},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543767/},
	doi = {10.4103/picr.PICR_87_17},
	abstract = {Logistic regression analysis is a statistical technique to evaluate the relationship between various predictor variables (either categorical or continuous) and an outcome which is binary (dichotomous). In this article, we discuss logistic regression analysis and the limitations of this technique.},
	number = {3},
	urldate = {2022-06-22},
	journal = {Perspectives in Clinical Research},
	author = {Ranganathan, Priya and Pramesh, C. S. and Aggarwal, Rakesh},
	year = {2017},
	pmid = {28828311},
	pmcid = {PMC5543767},
	pages = {148--151},
}

@misc{noauthor_residuenplots_nodate,
	title = {Residuenplots - fu:stat thesis - {Wikis} der {Freien} {Universität} {Berlin}},
	url = {https://wikis.fu-berlin.de/display/fustat/Residuenplots},
	urldate = {2022-06-14},
	file = {Residuenplots - fu\:stat thesis - Wikis der Freien Universität Berlin:/Users/isabelleborucki/Zotero/storage/LDLR6DNF/Residuenplots.html:text/html},
}

@misc{noauthor_statistik_nodate,
	title = {Statistik – {MM}*{Stat}},
	url = {https://wikis.hu-berlin.de/mmstat/Statistik},
	urldate = {2022-06-14},
	file = {Statistik – MM*Stat:/Users/isabelleborucki/Zotero/storage/YGYNPS99/Statistik.html:text/html},
}

@misc{noauthor_schlussel_nodate,
	title = {Ein {Schlüssel} erfolgreicher {Verhandlungen}},
	url = {https://www.forschung-und-lehre.de/karriere/professur/ein-schluessel-erfolgreicher-verhandlungen-300/},
	abstract = {Spätestens für die Berufungsverhandlungen müssen Anwerbende auf eine Professur ein Konzeptionspapier vorbereiten. Das gilt es mit Vorlauf anzugehen.},
	language = {de},
	urldate = {2022-06-13},
}

@book{wittenberg_einfuhrung_2008,
	address = {Nürnberg},
	series = {Arbeits- und {Diskussionspapiere} / {Universität} {Erlangen}-{Nürnberg}, {Lehrstuhl} für {Soziologie} und empirische {Sozialforschung}, insb. {Arbeitsmarktsoziologie}},
	title = {Einführung in die empirische {Sozialforschung} {I}: {Skript}},
	volume = {08-01},
	shorttitle = {Einführung in die empirische {Sozialforschung} {I}},
	abstract = {Bei dem vorliegenden Text handelt es sich um die überarbeitete und aktualisierte sechste Auflage des Skriptes zur "Einführung in die sozialwissenschaftlichen Methoden und ihre Anwendung in empirischen Untersuchungen I" aus dem Jahr 1999, allerdings mit neuer Überschrift: "Einführung in die empirische Sozialforschung". Die Überarbeitung bezieht sich insbesondere auf die erforderliche Aktualisierung in Folge neuerer Entwicklungen von Auswahl- und Befragungsmethoden sowie der Netzwerkanalyse. Außerdem wird die zwischenzeitlich erschienene Methodenliteratur berücksichtigt. Der diesem Skript zugrunde liegende Stoff bezieht sich auf den ersten Teil der auf zwei Semester angelegten "Einführung in die empirische Sozialforschung" im Bachelorstudiengang "Sozialökonomik". Es geht darum, z. T. aufbauend auf den Veranstaltungen zur Einführung in die Soziologie, mit jenem Forschungsinstrumentarium vertraut zu machen, das in der Soziologie für Fragen von Exploration, Deskription und Analyse sozialer Gegebenheiten zur Verfügung steht. Im Zentrum stehen - neben der Erörterung eher wissenschafts- und messtheoretischer Probleme - grundlegende Methoden der Datenerhebung und Auswahlverfahren. Sie werden ergänzt durch die Vorstellung spezieller Formen der Datenerhebung sowie ausgewählter Untersuchungsformen. (ICD2)},
	language = {de},
	publisher = {Universität Erlangen-Nürnberg, Rechts- und Wirtschaftswissenschaftliche Fakultät, Institut für Arbeitsmarkt und Sozialökonomik Lehrstuhl für Soziologie und empirische Sozialforschung, insb. Arbeitsmarktsoziologie},
	author = {Wittenberg, Reinhard and Knecht, Andrea},
	year = {2008},
	note = {ISSN: 1438-4663},
	keywords = {data capture, Datengewinnung, qualitative method, qualitative Methode, quantitative method, quantitative Methode, empirical social research, empirische Sozialforschung, data collection method, data preparation, Datenaufbereitung, empirical research, empirische Forschung, Erhebungsmethode},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/X3E84WG5/36030.html:text/html},
}

@misc{noauthor_show_nodate,
	title = {Show and {Tell} {II} {Sprachkorpora} 20220610 {\textbar} {Etherpad}},
	url = {https://etherpad.wikimedia.org/p/Show_and_Tell_II_Sprachkorpora_20220610},
	urldate = {2022-06-13},
	file = {Show and Tell II Sprachkorpora 20220610 | Etherpad:/Users/isabelleborucki/Zotero/storage/LWTLX9ZU/Show_and_Tell_II_Sprachkorpora_20220610.html:text/html},
}

@misc{noauthor_show_nodate-1,
	title = {Show and {Tell} {I} {Twitter} {Tools} 20220513 {\textbar} {Etherpad}},
	url = {https://etherpad.wikimedia.org/p/Show_and_Tell_I_Twitter_Tools_20220513},
	urldate = {2022-06-13},
	file = {Show and Tell I Twitter Tools 20220513 | Etherpad:/Users/isabelleborucki/Zotero/storage/QLEA6QMK/Show_and_Tell_I_Twitter_Tools_20220513.html:text/html},
}

@book{noauthor_introduction_nodate-3,
	title = {An {Introduction} to {R} for {Quantitative} {Economics}},
	url = {https://link.springer.com/book/10.1007/978-81-322-2340-5},
	abstract = {This book gives an introduction to R to build up graphing, simulating and computing skills to enable one to see theoretical and statistical models in economics in a unified way. The great advantage of R is that it is free, extremely flexible and extensible.},
	language = {en},
	urldate = {2022-06-13},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/KUJ7JXN5/978-81-322-2340-5.html:text/html},
}

@misc{noauthor_text_nodate,
	title = {Text {Networks}},
	url = {https://sicss.io/2020/materials/day3-text-analysis/text-networks/rmarkdown/Text_Networks.html},
	urldate = {2022-06-11},
}

@book{noauthor_einfuhrung_nodate-1,
	title = {Einführung in die {Statistik}},
	url = {https://link.springer.com/book/10.1007/978-3-662-56440-0},
	abstract = {Dieses Lehrbuch motiviert und erklärt die Inhalte der deskriptiven und induktiven Statistik, indem es die mathematischen Grundlagen mit vielfältigen, leicht nachvollziehbaren Anwendungen und Beispielen verbindet. Dabei kommen Papier und Stift sowie die statistische Software R zum Einsatz.},
	language = {en},
	urldate = {2022-06-10},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/2SWISMUN/978-3-662-56440-0.html:text/html},
}

@misc{banda_large-scale_2022,
	title = {A large-scale {COVID}-19 {Twitter} chatter dataset for open scientific research - an international collaboration},
	url = {https://zenodo.org/record/6618186},
	abstract = {Version 117 of the dataset. MAJOR CHANGE NOTE: The dataset files: full\_dataset.tsv.gz and full\_dataset\_clean.tsv.gz have been split in 1 GB parts using the Linux utility called Split. So make sure to join the parts before unzipping. We had to make this change as we had huge issues uploading files larger than 2GB's (hence the delay in the dataset releases). The peer-reviewed publication for this dataset has now been published  in Epidemiologia an MDPI journal, and can be accessed here: https://doi.org/10.3390/epidemiologia2030024. Please cite this when using the dataset. Due to the relevance of the COVID-19 global pandemic, we are releasing our dataset of tweets acquired from the Twitter Stream related to COVID-19 chatter. Since our first release we have received additional data from our new collaborators, allowing this resource to grow to its current size. Dedicated data gathering started from March 11th yielding over 4 million tweets a day. We have added additional data provided by our new collaborators from January 27th to March 27th, to provide extra longitudinal coverage. Version 10 added {\textasciitilde}1.5 million tweets in the Russian language collected between January 1st and May 8th, gracefully provided to us by: Katya Artemova (NRU HSE) and Elena Tutubalina (KFU). From version 12 we have included daily hashtags, mentions and emoijis and their frequencies the respective zip files. From version 14 we have included the tweet identifiers and their respective language for the clean version of the dataset. Since version 20 we have included language and place location for all tweets. The data collected from the stream captures all languages, but the higher prevalence are:  English, Spanish, and French. We release all tweets and retweets on the full\_dataset.tsv file (1,341,292,548 unique tweets), and a cleaned version with no retweets on the full\_dataset-clean.tsv file (347,137,128 unique tweets). There are several practical reasons for us to leave the retweets, tracing important tweets and their dissemination is one of them. For NLP tasks we provide the top 1000 frequent terms in frequent\_terms.csv, the top 1000 bigrams in frequent\_bigrams.csv, and the top 1000 trigrams in frequent\_trigrams.csv. Some general statistics per day are included for both datasets in the full\_dataset-statistics.tsv and full\_dataset-clean-statistics.tsv files. For more statistics and some visualizations visit: http://www.panacealab.org/covid19/  More details can be found (and will be updated faster at: https://github.com/thepanacealab/covid19\_twitter) and our pre-print about the dataset (https://arxiv.org/abs/2004.03688)  As always, the tweets distributed here are only tweet identifiers (with date and time added) due to the terms and conditions of Twitter to re-distribute Twitter data ONLY for research purposes. They need to be hydrated to be used.},
	language = {eng},
	urldate = {2022-06-08},
	publisher = {Zenodo},
	author = {Banda, Juan M. and Tekumalla, Ramya and Wang, Guanyu and Yu, Jingyuan and Liu, Tuo and Ding, Yuning and Artemova, Katya and Tutubalina, Elena and Chowell, Gerardo},
	month = jun,
	year = {2022},
	doi = {10.5281/zenodo.6618186},
	note = {Type: dataset},
	keywords = {social media, twitter, covid-19, covid19, nlp},
	annote = {This dataset will be updated bi-weekly at least with additional tweets, look at the github repo for these updates.
Release: We have standardized the name of the resource to match our pre-print manuscript and to not have to update it every week.},
	file = {Zenodo Snapshot:/Users/isabelleborucki/Zotero/storage/WIA96KDI/6618186.html:text/html},
}

@misc{noauthor_quarto_nodate,
	title = {Quarto - {Beamer} {Options}},
	url = {https://quarto.org/docs/reference/formats/presentations/beamer.html},
	abstract = {Beamer is a LaTeX class for producing presentations and slides. To learn more about Beamer see https://ctan.org/pkg/beamer.},
	language = {en},
	urldate = {2022-08-31},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/R3NJPQAV/beamer.html:text/html},
}

@inproceedings{cavalin_building_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Building a {Question}-{Answering} {Corpus} {Using} {Social} {Media} and {News} {Articles}},
	isbn = {978-3-319-41552-9},
	doi = {10.1007/978-3-319-41552-9_36},
	abstract = {Is it possible to develop a reliable QA-Corpus using social media data? What are the challenges faced when attempting such a task? In this paper, we discuss these questions and present our findings when developing a QA-Corpus on the topic of Brazilian finance. In order to populate our corpus, we relied on opinions from experts on Brazilian finance that are active on the Twitter application. From these experts, we extracted information from news websites that are used as answers in the corpus. Moreover, to effectively provide rankings of answers to questions, we employ novel word vector based similarity measures between short sentences (that accounts for both questions and Tweets). We validated our methods on a recently released dataset of similarity between short Portuguese sentences. Finally, we also discuss the effectiveness of our approach when used to rank answers to questions from real users.},
	language = {en},
	booktitle = {Computational {Processing} of the {Portuguese} {Language}},
	publisher = {Springer International Publishing},
	author = {Cavalin, Paulo and Figueiredo, Flavio and de Bayser, Maíra and Moyano, Luis and Candello, Heloisa and Appel, Ana and Souza, Renan},
	editor = {Silva, João and Ribeiro, Ricardo and Quaresma, Paulo and Adami, André and Branco, António},
	year = {2016},
	keywords = {Social media, Finance, Question and Answer},
	pages = {353--358},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/FKU4ID6U/Cavalin et al. - 2016 - Building a Question-Answering Corpus Using Social .pdf:application/pdf},
}

@misc{noauthor_how_2016,
	title = {How to build a corpus from the web {\textbar} {Sketch} {Engine}},
	url = {https://www.sketchengine.eu/guide/create-a-corpus-from-the-web/},
	abstract = {Create a multi-million-word corpus from the web within minutes. Fully automatic corpus building, lemmatization and tagging in 30+ languages.},
	language = {en-GB},
	urldate = {2022-08-30},
	month = jun,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/UQ384PHN/create-a-corpus-from-the-web.html:text/html},
}

@misc{noauthor_corpus_2020,
	type = {Text},
	title = {Corpus {Approaches} to {Social} {Media}},
	url = {https://www.jbe-platform.com/content/books/9789027260499},
	abstract = {From Twitter to Reddit, Facebook, and WhatsApp – social media is a part of modern everyday life. Studying the language used on social media platforms presents great opportunities as well as challenges to corpus linguists. The contributions in Corpus Approaches to Social Media address technical, ethical, and methodological issues by showcasing in-depth social media studies as conducted by corpus scholars. The chapters are based on a variety of social media platforms and include corpus perspectives on the language of online communities, linguistic variation in short media texts, and the role of images in computer-mediated communication. A particularly strong point of the collection are the detailed accounts of the methodological aspects of working with social media corpora. The volume features research applying traditional corpus linguistic methods to social media data as well as novel and innovative research methods for the analysis of multimodal material and atypical corpus texts.},
	language = {en},
	urldate = {2022-08-30},
	month = nov,
	year = {2020},
	note = {Publisher: John Benjamins},
}

@misc{aprilliant_introduction_2021,
	title = {Introduction to {Correspondence} {Analysis} {Using} {R} and {Indonesia} {Real} {Dataset}},
	url = {https://towardsdatascience.com/correspondence-analysis-using-r-cd57675ffc3a},
	abstract = {Indonesian Creative Economy Agency 2016},
	language = {en},
	urldate = {2022-08-30},
	journal = {Medium},
	author = {Aprilliant, Audhi},
	month = jun,
	year = {2021},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/2RF29DWV/correspondence-analysis-using-r-cd57675ffc3a.html:text/html},
}

@misc{noauthor_four_2022,
	title = {Four announcements from rstudio::conf(2022)},
	shorttitle = {Four announcements from rstudio},
	url = {https://www.rstudio.com/blog/four-announcements-from-rstudio-conf-2022/},
	abstract = {rstudio::conf was an eventful four days! This post details some of the bigger announcements from RStudio.},
	language = {en},
	urldate = {2022-08-17},
	month = aug,
	year = {2022},
}

@misc{noauthor_latex_nodate,
	title = {{LaTeX} {Base} {\textbar} {Styles} index},
	url = {https://docs.latexbase.com/styles/},
	urldate = {2022-08-15},
}

@book{planing_statistik_nodate,
	title = {Statistik {Grundlagen}},
	url = {https://statistikgrundlagen.de/ebook/},
	language = {de},
	urldate = {2022-08-14},
	publisher = {Patrick Planing},
	author = {Planing, Patrick},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/Q4WTHA9W/ebook.html:text/html},
}

@misc{loo_markvanderloostringdist_2022,
	title = {markvanderloo/stringdist},
	url = {https://github.com/markvanderloo/stringdist},
	abstract = {String distance functions for R},
	urldate = {2022-08-12},
	author = {Loo, Mark van der},
	month = jun,
	year = {2022},
	note = {original-date: 2013-01-16T20:09:30Z},
}

@article{khodak_large_nodate,
	title = {A {Large} {Self}-{Annotated} {Corpus} for {Sarcasm}},
	abstract = {We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for sarcasm research and for training and evaluating systems for sarcasm detection. The corpus has 1.3 million sarcastic statements — 10 times more than any previous dataset — and many times more instances of non-sarcastic statements, allowing for learning in both balanced and unbalanced label regimes. Each statement is furthermore self-annotated — sarcasm is labeled by the author, not an independent annotator — and provided with user, topic, and conversation context. We evaluate the corpus for accuracy, construct benchmarks for sarcasm detection, and evaluate baseline methods.},
	language = {en},
	author = {Khodak, Mikhail and Saunshi, Nikunj and Vodrahalli, Kiran},
	pages = {6},
	file = {Khodak et al. - A Large Self-Annotated Corpus for Sarcasm.pdf:/Users/isabelleborucki/Zotero/storage/UXYY536L/Khodak et al. - A Large Self-Annotated Corpus for Sarcasm.pdf:application/pdf},
}

@misc{noauthor_nrc_nodate,
	title = {{NRC} {Emotion} {Lexicon}},
	url = {https://www.saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm},
	urldate = {2022-08-12},
}

@misc{team_word_2019,
	title = {Word {Embedding} — {Natural} {Language} {Processing}},
	url = {https://datascience.eu/natural-language-processing/a-beginners-guide-to-word2vec-and-neural-word-embeddings/},
	abstract = {You will understand the basic concept of word2vec through this guide and how the word embedding helps convert word form into vector form.},
	language = {en},
	urldate = {2022-08-12},
	journal = {DATA SCIENCE},
	author = {Team, Data Science},
	month = dec,
	year = {2019},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/VGV6AVGW/a-beginners-guide-to-word2vec-and-neural-word-embeddings.html:text/html},
}

@book{noauthor_elements_nodate,
	title = {The {Elements} of {Statistical} {Learning}},
	url = {https://link.springer.com/book/10.1007/978-0-387-84858-7},
	language = {en},
	urldate = {2022-08-11},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/7YFWF9JQ/978-0-387-84858-7.html:text/html},
}

@article{bentejac_comparative_2021,
	title = {A comparative analysis of gradient boosting algorithms},
	volume = {54},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-020-09896-5},
	doi = {10.1007/s10462-020-09896-5},
	abstract = {The family of gradient boosting algorithms has been recently extended with several interesting proposals (i.e. XGBoost, LightGBM and CatBoost) that focus on both speed and accuracy. XGBoost is a scalable ensemble technique that has demonstrated to be a reliable and efficient machine learning challenge solver. LightGBM is an accurate model focused on providing extremely fast training performance using selective sampling of high gradient instances. CatBoost modifies the computation of gradients to avoid the prediction shift in order to improve the accuracy of the model. This work proposes a practical analysis of how these novel variants of gradient boosting work in terms of training speed, generalization performance and hyper-parameter setup. In addition, a comprehensive comparison between XGBoost, LightGBM, CatBoost, random forests and gradient boosting has been performed using carefully tuned models as well as using their default settings. The results of this comparison indicate that CatBoost obtains the best results in generalization accuracy and AUC in the studied datasets although the differences are small. LightGBM is the fastest of all methods but not the most accurate. Finally, XGBoost places second both in accuracy and in training speed. Finally an extensive analysis of the effect of hyper-parameter tuning in XGBoost, LightGBM and CatBoost is carried out using two novel proposed tools.},
	language = {en},
	number = {3},
	urldate = {2022-08-11},
	journal = {Artificial Intelligence Review},
	author = {Bentéjac, Candice and Csörgő, Anna and Martínez-Muñoz, Gonzalo},
	month = mar,
	year = {2021},
	keywords = {CatBoost, Ensembles of classifiers, Gradient boosting, LightGBM, Random forest, XGBoost},
	pages = {1937--1967},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/FUBVBGU9/Bentéjac et al. - 2021 - A comparative analysis of gradient boosting algori.pdf:application/pdf},
}

@misc{gupta_regularization_2017,
	title = {Regularization in {Machine} {Learning}},
	url = {https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a},
	abstract = {One of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is…},
	language = {en},
	urldate = {2022-08-09},
	journal = {Medium},
	author = {Gupta, Prashant},
	month = nov,
	year = {2017},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/UR65Y2DR/regularization-in-machine-learning-76441ddcf99a.html:text/html},
}

@misc{anwar_types_2021,
	title = {Types of {Regularization} in {Machine} {Learning}},
	url = {https://towardsdatascience.com/types-of-regularization-in-machine-learning-eb5ce5f9bf50},
	abstract = {A beginner's guide to regularization in machine learning.},
	language = {en},
	urldate = {2022-08-09},
	journal = {Medium},
	author = {Anwar, Aqeel},
	month = apr,
	year = {2021},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/LIC883CZ/types-of-regularization-in-machine-learning-eb5ce5f9bf50.html:text/html},
}

@misc{may_impurity_2020,
	title = {Impurity \& {Judging} {Splits} — {How} a {Decision} {Tree} {Works}},
	url = {https://towardsdatascience.com/impurity-judging-splits-how-a-decision-tree-works-235f2e9e63b7},
	abstract = {If you want to learn how machine learning algorithms work then you cannot go wrong by starting at the humble Decision Tree.},
	language = {en},
	urldate = {2022-08-09},
	journal = {Medium},
	author = {May, Paul},
	month = mar,
	year = {2020},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/WQI35473/impurity-judging-splits-how-a-decision-tree-works-235f2e9e63b7.html:text/html},
}

@misc{noauthor_accessing_nodate,
	title = {Accessing the {SQP} 3.0 {API}},
	url = {https://sociometricresearch.github.io/sqpr/articles/accesing-sqp-api.html},
	abstract = {sqpr},
	language = {en},
	urldate = {2022-08-09},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PZUTJ9LQ/accesing-sqp-api.html:text/html},
}

@misc{noauthor_extract_nodate,
	title = {Extract the {Quality} of your {Survey} {Questions} with {SQP} 3.0},
	url = {https://sociometricresearch.github.io/sqpr/},
	abstract = {Using the database of the SQP 3.0 API, sqpr allows downloading data on the quality of over 40,000 questions, including the quality, validity and reliability of each question.},
	language = {en},
	urldate = {2022-08-09},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/HNIY9CUV/sqpr.html:text/html},
}

@article{lever_principal_2017,
	title = {Principal component analysis},
	volume = {14},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.4346},
	doi = {10.1038/nmeth.4346},
	abstract = {PCA helps you interpret your data, but it will not always find the important patterns.},
	language = {en},
	number = {7},
	urldate = {2022-08-09},
	journal = {Nature Methods},
	author = {Lever, Jake and Krzywinski, Martin and Altman, Naomi},
	month = jul,
	year = {2017},
	note = {Number: 7
Publisher: Nature Publishing Group},
	keywords = {Publishing, Statistical methods, Research data},
	pages = {641--642},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/NYEE7XVW/Lever et al. - 2017 - Principal component analysis.pdf:application/pdf;Snapshot:/Users/isabelleborucki/Zotero/storage/SQE6ITYU/nmeth.html:text/html},
}

@article{galesic_human_2021,
	title = {Human social sensing is an untapped resource for computational social science},
	volume = {595},
	copyright = {2021 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03649-2},
	doi = {10.1038/s41586-021-03649-2},
	abstract = {The ability to ‘sense’ the social environment and thereby to understand the thoughts and actions of others allows humans to fit into their social worlds, communicate and cooperate, and learn from others’ experiences. Here we argue that, through the lens of computational social science, this ability can be used to advance research into human sociality. When strategically selected to represent a specific population of interest, human social sensors can help to describe and predict societal trends. In addition, their reports of how they experience their social worlds can help to build models of social dynamics that are constrained by the empirical reality of human social systems.},
	language = {en},
	number = {7866},
	urldate = {2022-08-08},
	journal = {Nature},
	author = {Galesic, Mirta and Bruine de Bruin, Wändi and Dalege, Jonas and Feld, Scott L. and Kreuter, Frauke and Olsson, Henrik and Prelec, Drazen and Stein, Daniel L. and van der Does, Tamara},
	month = jul,
	year = {2021},
	note = {Number: 7866
Publisher: Nature Publishing Group},
	keywords = {Sociology, Human behaviour, Interdisciplinary studies},
	pages = {214--222},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/2UEF35KA/Galesic et al. - 2021 - Human social sensing is an untapped resource for c.pdf:application/pdf},
}

@article{sohil_introduction_2022,
	title = {An introduction to statistical learning with applications in {R}: by {Gareth} {James}, {Daniela} {Witten}, {Trevor} {Hastie}, and {Robert} {Tibshirani}, {New} {York}, {Springer} {Science} and {Business} {Media}, 2013, \$41.98, {eISBN}: 978-1-4614-7137-7},
	volume = {6},
	issn = {2475-4269, 2475-4277},
	shorttitle = {An introduction to statistical learning with applications in {R}},
	url = {https://www.tandfonline.com/doi/full/10.1080/24754269.2021.1980261},
	doi = {10.1080/24754269.2021.1980261},
	language = {en},
	number = {1},
	urldate = {2022-08-08},
	journal = {Statistical Theory and Related Fields},
	author = {Sohil, Fariha and Sohali, Muhammad Umair and Shabbir, Javid},
	month = jan,
	year = {2022},
	pages = {87--87},
	file = {Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:/Users/isabelleborucki/Zotero/storage/6LCA2M92/Sohil et al. - 2022 - An introduction to statistical learning with appli.pdf:application/pdf},
}

@book{lane_chapter_nodate,
	title = {Chapter 2 {Working} with {Web} {Data} and {APIs} {\textbar} {Big} {Data} and {Social} {Science}},
	url = {https://textbook.coleridgeinitiative.org/chap-web.html},
	abstract = {Chapter 2 Working with Web Data and APIs {\textbar} Big Data and Social Science},
	urldate = {2022-08-08},
	author = {Lane, Rayid Ghani, Ron S. Jarmin, Frauke Kreuter {and} Julia, Ian Foster},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/RRN9FBW9/chap-web.html:text/html},
}

@misc{noauthor_sosci_nodate,
	title = {{SoSci} {Panel} - offenes wissenschaftliches {Befragungspanel}},
	url = {https://www.soscipanel.de/},
	urldate = {2022-06-29},
	file = {SoSci Panel - offenes wissenschaftliches Befragungspanel:/Users/isabelleborucki/Zotero/storage/ZFMJCENI/www.soscipanel.de.html:text/html},
}

@book{simmons_rethinking_2021,
	address = {Cambridge},
	title = {Rethinking {Comparison}: {Innovative} {Methods} for {Qualitative} {Political} {Inquiry}},
	isbn = {978-1-108-83279-3},
	shorttitle = {Rethinking {Comparison}},
	url = {https://www.cambridge.org/core/books/rethinking-comparison/7ACD40CFC796F9A00104A74E4FFE5756},
	abstract = {Qualitative comparative methods – and specifically controlled qualitative comparisons – are central to the study of politics. They are not the only kind of comparison, though, that can help us better understand political processes and outcomes. Yet there are few guides for how to conduct non-controlled comparative research. This volume brings together chapters from more than a dozen leading methods scholars from across the discipline of political science, including positivist and interpretivist scholars, qualitative methodologists, mixed-methods researchers, ethnographers, historians, and statisticians. Their work revolutionizes qualitative research design by diversifying the repertoire of comparative methods available to students of politics, offering readers clear suggestions for what kinds of comparisons might be possible, why they are useful, and how to execute them. By systematically thinking through how we engage in qualitative comparisons and the kinds of insights those comparisons produce, these collected essays create new possibilities to advance what we know about politics.},
	urldate = {2022-11-17},
	publisher = {Cambridge University Press},
	editor = {Simmons, Erica S. and Rush Smith, Nicholas},
	year = {2021},
	doi = {10.1017/9781108966009},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/2FH6QWMU/7ACD40CFC796F9A00104A74E4FFE5756.html:text/html},
}

@misc{usr11852_answer_2016,
	title = {Answer to ""{Model} failed to converge" warning in lmer()"},
	url = {https://stats.stackexchange.com/a/243225},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {usεr11852},
	month = oct,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/EV65SVDX/model-failed-to-converge-warning-in-lmer.html:text/html},
}

@misc{r_answer_2017,
	title = {Answer to ""{Model} failed to converge" warning in lmer()"},
	url = {https://stats.stackexchange.com/a/261090},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {R, Syamkumar},
	month = feb,
	year = {2017},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/N6FDA823/model-failed-to-converge-warning-in-lmer.html:text/html},
}

@misc{r_model_2016,
	type = {Forum post},
	title = {"{Model} failed to converge" warning in lmer()},
	url = {https://stats.stackexchange.com/q/242109},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {R, Syamkumar},
	month = oct,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/BVRVSCXL/model-failed-to-converge-warning-in-lmer.html:text/html},
}

@misc{guy_answer_2022,
	title = {Answer to ""{Model} failed to converge" warning in lmer()"},
	url = {https://stats.stackexchange.com/a/568846},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {Guy},
	month = mar,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/U9C5Q4T2/model-failed-to-converge-warning-in-lmer.html:text/html},
}

@misc{ocram_answer_2013,
	title = {Answer to "{What} is "restricted maximum likelihood" and when should it be used?"},
	shorttitle = {Answer to "{What} is "restricted maximum likelihood" and when should it be used?},
	url = {https://stats.stackexchange.com/a/48676},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {ocram},
	month = jan,
	year = {2013},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/GQQTG3QZ/what-is-restricted-maximum-likelihood-and-when-should-it-be-used.html:text/html},
}

@misc{long_answer_2013,
	title = {Answer to "{What} is "restricted maximum likelihood" and when should it be used?"},
	shorttitle = {Answer to "{What} is "restricted maximum likelihood" and when should it be used?},
	url = {https://stats.stackexchange.com/a/48770},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {Long, Robert},
	month = jan,
	year = {2013},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/PUEDPCR2/what-is-restricted-maximum-likelihood-and-when-should-it-be-used.html:text/html},
}

@misc{king_what_2018,
	type = {Forum post},
	title = {What is "restricted maximum likelihood" and when should it be used?},
	url = {https://stats.stackexchange.com/q/48671},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {King, Joe},
	month = feb,
	year = {2018},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/YRDCFM8R/what-is-restricted-maximum-likelihood-and-when-should-it-be-used.html:text/html},
}

@misc{skan_answer_2016,
	title = {Answer to "{What} is "restricted maximum likelihood" and when should it be used?"},
	shorttitle = {Answer to "{What} is "restricted maximum likelihood" and when should it be used?},
	url = {https://stats.stackexchange.com/a/205505},
	urldate = {2022-11-21},
	journal = {Cross Validated},
	author = {skan},
	month = apr,
	year = {2016},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/6PW3UGJU/what-is-restricted-maximum-likelihood-and-when-should-it-be-used.html:text/html},
}

@article{macdonald_traditional_2017,
	title = {Traditional and {Critical} {Theory} {Today}: {Toward} a {Critical} {Political} {Science}},
	volume = {39},
	issn = {0739-3148, 1469-9931},
	shorttitle = {Traditional and {Critical} {Theory} {Today}},
	url = {https://www.tandfonline.com/doi/full/10.1080/07393148.2017.1378857},
	doi = {10.1080/07393148.2017.1378857},
	abstract = {In the famous early theoretical manifesto of the Frankfurt School, “Traditional and Critical Theory” (1937), Max Horkheimer proclaimed the necessity of rethinking the direction in which theory was moving in the context of the circulating intellectual traditions of phenomenology, sociology of knowledge, neo-Kantianism, and positivism. For Horkheimer, while the theoretical terrain associated with 1930s Europe seemed diverse and possibly open to radical directions and progressive articulations, it ultimately conspired to reinforce the socio-economic status quo in which human beings were controlled by the very practices they created and continue to recreate. Drawing on the spirit and concepts of Horkheimer’s opening salvo for critical theory published eighty years ago, I argue that it is time to reinvest in the commitments heralded in the problematic of critical theory and continue to promote a critical political science that takes seriously the importance of critique and human emancipation.},
	language = {en},
	number = {4},
	urldate = {2022-11-22},
	journal = {New Political Science},
	author = {Macdonald, Bradley J.},
	month = oct,
	year = {2017},
	pages = {511--522},
	file = {Macdonald - 2017 - Traditional and Critical Theory Today Toward a Cr.pdf:/Users/isabelleborucki/Zotero/storage/W42YZCMF/Macdonald - 2017 - Traditional and Critical Theory Today Toward a Cr.pdf:application/pdf},
}

@misc{noauthor_gesis_nodate,
	title = {{GESIS} {Training} {Courses}},
	url = {https://training.gesis.org/?site=pDetails&child=full&pID=0x12B83793E7C34D779B0ADB72C085E7D9},
	urldate = {2022-12-05},
	file = {GESIS Training Courses:/Users/isabelleborucki/Zotero/storage/PLWI3DGK/training.gesis.org.html:text/html},
}

@incollection{bogner_interaktion_2014-1,
	address = {Wiesbaden},
	title = {Die {Interaktion} im {Interview}: {Frageformulierung} und {Strategien} der {Gesprächsführung}},
	isbn = {978-3-531-19415-8 978-3-531-19416-5},
	shorttitle = {Die {Interaktion} im {Interview}},
	url = {http://link.springer.com/10.1007/978-3-531-19416-5_5},
	language = {de},
	urldate = {2022-12-06},
	booktitle = {Interviews mit {Experten}},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	collaborator = {Bogner, Alexander and Littig, Beate and Menz, Wolfgang},
	year = {2014},
	doi = {10.1007/978-3-531-19416-5_5},
	pages = {49--69},
	file = {Bogner et al. - 2014 - Die Interaktion im Interview Frageformulierung un.pdf:/Users/isabelleborucki/Zotero/storage/K3UT3V9N/Bogner et al. - 2014 - Die Interaktion im Interview Frageformulierung un.pdf:application/pdf},
}

@incollection{mayring_qualitative_2019,
	address = {Wiesbaden},
	title = {Qualitative {Inhaltsanalyse}},
	isbn = {978-3-658-21308-4},
	url = {https://doi.org/10.1007/978-3-658-21308-4_42},
	abstract = {Qualitative Inhaltsanalyse stellt eine Auswertungsmethode dar, die Texte bearbeitet, welche im Rahmen sozialwissenschaftlicher Forschungsprojekte in der Datenerhebung anfallen, z.B. Transkripte von offenen Interviews (Helfferich, Kapitel 44 in diesem Band) oder Fokusgruppen (Vogl, Kapitel 46 in diesem Band), offene Fragen aus standardisierten Befragungen (Züll/Menold, Kapitel 59 in diesem Band), Beobachtungsprotokolle aus Feldstudien (Thierbach/Petschick, Kapitel 84 in diesem Band), Dokumente (Ernst, Kapitel 81 in diesem Band), Akten (Salheiser, Kapitel 80 in diesem Band), Zeitungsartikel (Klein, Kapitel 82 in diesem Band) und Internetmaterialien.},
	language = {de},
	urldate = {2022-12-13},
	booktitle = {Handbuch {Methoden} der empirischen {Sozialforschung}},
	publisher = {Springer Fachmedien},
	author = {Mayring, Philipp and Fenzl, Thomas},
	editor = {Baur, Nina and Blasius, Jörg},
	year = {2019},
	doi = {10.1007/978-3-658-21308-4_42},
	pages = {633--648},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/BAIJB42H/Mayring and Fenzl - 2019 - Qualitative Inhaltsanalyse.pdf:application/pdf},
}

@misc{pramoditha_10_2022,
	title = {10 {Amazing} {Machine} {Learning} {Visualizations} {You} {Should} {Know} in 2023},
	url = {https://towardsdatascience.com/10-amazing-machine-learning-visualizations-you-should-know-in-2023-528282940582},
	abstract = {Yellowbrick for creating machine learning plots with less code},
	language = {en},
	urldate = {2022-12-13},
	journal = {Medium},
	author = {Pramoditha, Rukshan},
	month = nov,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/DQFN3RZD/10-amazing-machine-learning-visualizations-you-should-know-in-2023-528282940582.html:text/html},
}

@article{strecker_quality_2022,
	title = {Quality of metadata describing research data and the influence of repository characteristics},
	abstract = {Objective — This article captures the status quo of metadata for research data, and identifies factors at the repository level that influence metadata quality.
Methods — Based on a joint analysis of DataCite metadata records and re3data repository descriptions, this paper evaluates the quality of metadata records describing research data and analyzes differences in metadata quality between repositories of different types and between repositories with or without formal certification to determine if these factors correlate with high metadata quality.
Results — Of individual metadata elements, mandatory elements are used most frequently, followed by recommended and optional elements. More than half of all metadata elements are used in less than 5 \% of metadata records. With the exception of related identifiers, persistent identifiers are rarely used. The average descriptions has 487.3 characters. On average, 18.7 elements are used in metadata records, which corresponds to 24.7 \% of the elements available. The homogeneity of metadata records varies considerably between repositories, on average, 50.9 \% of metadata records use the same common set of metadata elements. The analysis revealed statistically significant differences across repositories of varying type and certification status in the use of individual metadata elements, the comprehensiveness of descriptions, and the completeness of metadata records.
Conclusion — This paper presents a first systematic analysis of metadata quality for research data and the influence of repository characteristics on metadata quality. It discusses difficulties of using a generic metadata schema for describing diverse research data. The results show that some repositories appear to have established successful metadata practices and workflows, but some metadata elements remain underused. There is evidence of repository type and certification status affecting metadata quality, but more research is needed to identify specific factors.},
	language = {en},
	author = {Strecker, Dorothea},
	year = {2022},
	file = {Strecker - 2022 - Quality of metadata describing research data and t.pdf:/Users/isabelleborucki/Zotero/storage/QB53PY4Z/Strecker - 2022 - Quality of metadata describing research data and t.pdf:application/pdf},
}

@article{fernandez-garcia_discourses_2022,
	title = {Discourses about {Fake} {News}, {Conspiracies} and {Counterknowledge} in {Spain}},
	issn = {1057-0314, 1745-1027},
	url = {https://www.tandfonline.com/doi/full/10.1080/10570314.2022.2087896},
	doi = {10.1080/10570314.2022.2087896},
	language = {en},
	urldate = {2022-06-28},
	journal = {Western Journal of Communication},
	author = {Fernández-García, Belén and Salgado, Susana},
	month = jun,
	year = {2022},
	pages = {1--20},
}

@misc{lample_neural_2016,
	title = {Neural {Architectures} for {Named} {Entity} {Recognition}},
	url = {http://arxiv.org/abs/1603.01360},
	doi = {10.48550/arXiv.1603.01360},
	abstract = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
	month = apr,
	year = {2016},
	note = {Number: arXiv:1603.01360
arXiv:1603.01360 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Proceedings of NAACL 2016},
	file = {arXiv Fulltext PDF:/Users/isabelleborucki/Zotero/storage/CQI8N6NC/Lample et al. - 2016 - Neural Architectures for Named Entity Recognition.pdf:application/pdf;arXiv.org Snapshot:/Users/isabelleborucki/Zotero/storage/4HWZHRQG/1603.html:text/html},
}

@article{nadeau_survey_2007,
	title = {A survey of named entity recognition and classification},
	volume = {30},
	issn = {0378-4169, 1569-9927},
	url = {https://www.jbe-platform.com/content/journals/10.1075/li.30.1.03nad},
	doi = {10.1075/li.30.1.03nad},
	abstract = {This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.},
	language = {en},
	number = {1},
	urldate = {2022-06-23},
	journal = {Lingvisticæ Investigationes},
	author = {Nadeau, David and Sekine, Satoshi},
	month = jan,
	year = {2007},
	note = {Publisher: John Benjamins},
	pages = {3--26},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/Q2A9CWLX/li.30.1.html:text/html},
}

@incollection{mohit_named_2014,
	address = {Berlin, Heidelberg},
	series = {Theory and {Applications} of {Natural} {Language} {Processing}},
	title = {Named {Entity} {Recognition}},
	isbn = {978-3-642-45358-8},
	url = {https://doi.org/10.1007/978-3-642-45358-8_7},
	abstract = {Named entity recognition (NER) is the problem of locating and categorizing important nouns and proper nouns in a text. In this chapter, we review the general state of research on entity recognition, relevant challenges and the current state of the art works on named entity recognition on Semitic languages. Specifically, we look into two case studies for Arabic and Hebrew. We also review Semitic NLP tasks which overlap with the named entity recognition. We close with an overview of the available resources for Semitic named entity recognition and some the open.research questions.},
	language = {en},
	urldate = {2022-06-23},
	booktitle = {Natural {Language} {Processing} of {Semitic} {Languages}},
	publisher = {Springer},
	author = {Mohit, Behrang},
	editor = {Zitouni, Imed},
	year = {2014},
	doi = {10.1007/978-3-642-45358-8_7},
	keywords = {Conditional Random Field, Entity Recognition, Hide Markov Model, Machine Translation, Name Entity Recognition},
	pages = {221--245},
}

@misc{noauthor_named_2020,
	title = {Named {Entity} {Recognition}: {Concept}, {Tools} and {Tutorial}},
	shorttitle = {Named {Entity} {Recognition}},
	url = {https://monkeylearn.com/blog/named-entity-recognition/},
	abstract = {Named entity recognition (NER) is an AI technique that automatically identifies key information in a text, like names of people, places, companies, and more.},
	language = {en},
	urldate = {2022-06-23},
	journal = {MonkeyLearn Blog},
	month = mar,
	year = {2020},
	note = {Section: Keyword Extraction},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/UHNEU3DY/named-entity-recognition.html:text/html},
}

@inproceedings{guhr_training_2020,
	address = {Marseille, France},
	title = {Training a {Broad}-{Coverage} {German} {Sentiment} {Classification} {Model} for {Dialog} {Systems}},
	isbn = {979-10-95546-34-4},
	url = {https://aclanthology.org/2020.lrec-1.202},
	abstract = {This paper describes the training of a general-purpose German sentiment classification model. Sentiment classification is an important aspect of general text analytics. Furthermore, it plays a vital role in dialogue systems and voice interfaces that depend on the ability of the system to pick up and understand emotional signals from user utterances. The presented study outlines how we have collected a new German sentiment corpus and then combined this corpus with existing resources to train a broad-coverage German sentiment model. The resulting data set contains 5.4 million labelled samples. We have used the data to train both, a simple convolutional and a transformer-based classification model and compared the results achieved on various training configurations. The model and the data set will be published along with this paper.},
	language = {English},
	urldate = {2022-06-23},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Guhr, Oliver and Schumann, Anne-Kathrin and Bahrmann, Frank and Böhme, Hans Joachim},
	month = may,
	year = {2020},
	pages = {1627--1632},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/H9XQTDY8/Guhr et al. - 2020 - Training a Broad-Coverage German Sentiment Classif.pdf:application/pdf},
}

@misc{miller_poppler_2020,
	title = {Poppler {On} {Windows}},
	url = {https://towardsdatascience.com/poppler-on-windows-179af0e50150},
	abstract = {Python, PDFs, and Window’s Subsytem for Linux},
	language = {en},
	urldate = {2022-06-23},
	journal = {Medium},
	author = {Miller, Matthew Earl},
	month = jan,
	year = {2020},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/HQMWULPD/poppler-on-windows-179af0e50150.html:text/html},
}

@article{blaette_how_nodate,
	title = {How {GermaParl} {Evolves}: {Improving} {Data} {Quality} by {Reproducible} {Corpus} {Preparation} and {User} {Involvement}},
	abstract = {The development and curation of large-scale corpora of plenary debates requires not only care and attention to detail when the data is created but also effective means of sustainable quality control. This paper makes two contributions: Firstly, it presents an updated version of the GermaParl corpus of parliamentary debates in the German Bundestag. Secondly, it shows how the corpus preparation pipeline is designed to serve the quality of the resource by facilitating effective community involvement. Centered around a workﬂow which combines reproducibility, transparency and version control, the pipeline allows for continuous improvements to the corpus.},
	language = {en},
	author = {Blaette, Andreas and Rakers, Julia and Leonhardt, Christoph},
	pages = {9},
	file = {Blaette et al. - How GermaParl Evolves Improving Data Quality by R.pdf:/Users/isabelleborucki/Zotero/storage/8BD2UPYU/Blaette et al. - How GermaParl Evolves Improving Data Quality by R.pdf:application/pdf},
}

@misc{noauthor_program_nodate,
	title = {Program - {ParlaCLARIN} {III} {Workshop} on {Creating}, {Enriching} and {Using} {Parliamentary} {Corpora} within {LREC2022}},
	url = {http://www.lrec-conf.org/proceedings/lrec2022/workshops/ParlaCLARINIII/program.html},
	urldate = {2022-06-22},
	file = {Program - ParlaCLARIN III Workshop on Creating, Enriching and Using Parliamentary Corpora within LREC2022:/Users/isabelleborucki/Zotero/storage/J9PPCGXB/program.html:text/html},
}

@book{jockers_text_2014,
	address = {Cham},
	series = {Quantitative {Methods} in the {Humanities} and {Social} {Sciences}},
	title = {Text {Analysis} with {R} for {Students} of {Literature}},
	isbn = {978-3-319-03163-7 978-3-319-03164-4},
	url = {http://link.springer.com/10.1007/978-3-319-03164-4},
	language = {en},
	urldate = {2022-06-20},
	publisher = {Springer International Publishing},
	author = {Jockers, Matthew L.},
	year = {2014},
	doi = {10.1007/978-3-319-03164-4},
	file = {Jockers - 2014 - Text Analysis with R for Students of Literature.pdf:/Users/isabelleborucki/Zotero/storage/Z4A6J6D2/Jockers - 2014 - Text Analysis with R for Students of Literature.pdf:application/pdf},
}

@misc{noauthor_umgang_nodate,
	title = {Umgang mit {Forschungsdaten} in den {Geistes}- und {Sozialwissenschaften}},
	url = {https://wissenschaftliche-integritaet.de/kommentare/umgang-mit-forschungsdaten-in-den-geistes-und-sozialwissenschaften/},
	abstract = {Forschungsdaten in geistes- und sozialwissenschaftlichen Projekten sind so vielfältig wie das große Fächer- und Methodenspektrum und bilden einen wichtigen Teil der Forschungsergebnisse. Ein bewusster Umgang mit der Dokumentation, Pflege, Archivierung und Bereitstellung der Daten für eine spätere Prüfung und mögliche Nachnutzung ist für alle Projekte Pflicht.},
	language = {de-DE},
	urldate = {2022-06-19},
	journal = {Wissenschaftliche Integrität},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/AE6SEYR3/umgang-mit-forschungsdaten-in-den-geistes-und-sozialwissenschaften.html:text/html},
}

@article{dayal_demystifying_nodate,
	title = {Demystifying causal inference: ingredients of a recipe},
	abstract = {In the last few decades, scholars have contributed to a ﬂourishing literature on casual inference and the demand for its application in areas like programme evaluation has increased. Our suggestion is that the following ingredients are useful for demystifying causal inference in introductory courses: (1) using the potential outcomes and causal graph frameworks, (2) covering applications with real data that use key methods for causal inference: experiments, regression discontinuity etc., (3) using Monte Carlo simulation, and (4) using data graphs. The ﬁrst two ingredients are components of the scholarship in causal inference, while the latter two are more general ingredients of statistical and econometric pedagogy. We discuss the case for these ingredients, drawing on the substantive and pedagogical literature, our experience, and student opinions.},
	language = {en},
	author = {Dayal, Vikram and Murugesan, Anand},
	pages = {30},
	file = {Dayal and Murugesan - Demystifying causal inference ingredients of a re.pdf:/Users/isabelleborucki/Zotero/storage/DLIGFURV/Dayal and Murugesan - Demystifying causal inference ingredients of a re.pdf:application/pdf},
}

@article{blatte_germaparl_nodate,
	title = {The {GermaParl} {Corpus} of {Parliamentary} {Protocols}},
	abstract = {This paper introduces the GermaParl Corpus. We outline available data, the data preparation process for preparing corpora of parliamentary debates and the tools we used to obtain hand-coded annotations that serve as training data for classifying debates. Beyond introducing a resource that is valuable for research, we share experiences and best practices for preparing corpora of plenary protocols.},
	language = {en},
	author = {Blatte, Andreas and Blessing, Andre},
	pages = {7},
	file = {Blatte und Blessing - The GermaParl Corpus of Parliamentary Protocols.pdf:/Users/isabelleborucki/Zotero/storage/U4NEWHSB/Blatte und Blessing - The GermaParl Corpus of Parliamentary Protocols.pdf:application/pdf},
}

@book{gries_quantitative_2017,
	address = {Milton Park, Abingdon, Oxon},
	title = {Quantitative {Corpus} {Linguistics} with {R} : {A} {Practical} {Introduction}},
	volume = {Second edition},
	isbn = {978-1-138-81627-5},
	shorttitle = {Quantitative {Corpus} {Linguistics} with {R}},
	url = {https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,shib,uid&db=nlebk&AN=1386645&site=ehost-live&scope=site},
	abstract = {As in its first edition, the new edition of Quantitative Corpus Linguistics with R demonstrates how to process corpus-linguistic data with the open-source programming language and environment R. Geared in general towards linguists working with observational data, and particularly corpus linguists, it introduces R programming with emphasis on: data processing and manipulation in general; text processing with and without regular expressions of large bodies of textual and/or literary data, and; basic aspects of statistical analysis and visualization. This book is extremely hands-on and leads the reader through dozens of small applications as well as larger case studies. Along with an array of exercise boxes and separate answer keys, the text features a didactic sequential approach in case studies by way of subsections that zoom in to every programming problem. The companion website to the book contains all relevant R code (amounting to approximately 7,000 lines of heavily commented code), most of the data sets as well as pointers to others, and a dedicated Google newsgroup. This new edition is ideal for both researchers in corpus linguistics and instructors who want to promote hands-on approaches to data in corpus linguistics courses.},
	language = {English},
	urldate = {2022-05-31},
	publisher = {Routledge},
	author = {Gries, Stefan},
	year = {2017},
	keywords = {Computational linguistics, EDUCATION / Teaching / Subjects / Arts \& Humanities, LANGUAGE ARTS \& DISCIPLINES / General, LANGUAGE ARTS \& DISCIPLINES / Linguistics / General, Linguistics--Statistical methods, MATHEMATICS / Probability \& Statistics / General, R (Computer program language)},
	file = {Gries - 2017 - Quantitative Corpus Linguistics with R  A Practic.pdf:/Users/isabelleborucki/Zotero/storage/QK682832/Gries - 2017 - Quantitative Corpus Linguistics with R  A Practic.pdf:application/pdf},
}

@misc{noauthor_introduction_nodate-4,
	title = {Introduction - {GROBID} {Documentation}},
	url = {https://grobid.readthedocs.io/en/latest/Introduction/},
	urldate = {2022-06-12},
}

@misc{noauthor_pcrg_nodate,
	title = {{PCRG} {Home}},
	url = {https://partycongressresearchgroup.wordpress.com/},
	abstract = {Welcome to the Party Congress Research Group Homepage},
	language = {en},
	urldate = {2022-06-08},
	journal = {PCRG Home},
}

@misc{schumacher_replication_2019,
	title = {Replication {Data} for: {A} {New} {Dataset} of {Dutch} and {Danish} {Party} {Congress} {Speeches}},
	shorttitle = {Replication {Data} for},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/A3NO2G},
	abstract = {Replication data for analyses reported in "A New Dataset of Dutch and Danish Party Congress Speeches" published in Research and Politics},
	language = {en},
	urldate = {2022-06-08},
	publisher = {Harvard Dataverse},
	author = {Schumacher, Gijs},
	month = feb,
	year = {2019},
	doi = {10.7910/DVN/A3NO2G},
	note = {Type: dataset},
	keywords = {Social Sciences},
}

@misc{noauthor_wp4_inventoy_codebookdocx_nodate,
	title = {{WP4}\_inventoy\_codebook.docx},
	url = {https://cloud.wzb.eu/s/tgBMMBf46WSWCgX},
	abstract = {WZB Cloud - ein sicherer Ort für all Deine Daten},
	language = {de},
	urldate = {2022-06-08},
	journal = {WZB Cloud},
}

@article{greene_replication_2021,
	title = {Replication {Data} for: {Leadership} competition and disagreement at party national congresses},
	shorttitle = {Replication {Data} for},
	url = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/7J67DS},
	doi = {10.7910/DVN/7J67DS},
	abstract = {Raw texts of party conference speeches for Germany and France},
	language = {en},
	urldate = {2022-06-08},
	author = {Greene, Zachary},
	month = apr,
	year = {2021},
	note = {Publisher: Harvard Dataverse
Type: dataset},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/M4YW8HH3/dataset.html:text/html},
}

@misc{noauthor_wp4_inventoryxlsx_nodate,
	title = {{WP4}\_inventory.xlsx},
	url = {https://cloud.wzb.eu/s/5Z35gB3Rj4EFiwx},
	abstract = {WZB Cloud - ein sicherer Ort für all Deine Daten},
	language = {de},
	urldate = {2022-06-08},
	journal = {WZB Cloud},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/5T6F97D5/5Z35gB3Rj4EFiwx.html:text/html},
}

@misc{noauthor_noah_nodate,
	title = {Noah {Bubenhofer}: {Einführung} in die {Korpuslinguistik} ({Daten} aufbereiten: {XML})},
	url = {https://www.bubenhofer.com/korpuslinguistik/kurs/index.php?id=eigenes_aufbereitenXML.html},
	urldate = {2022-05-31},
	file = {Noah Bubenhofer\: Einführung in die Korpuslinguistik (Daten aufbereiten\: XML):/Users/isabelleborucki/Zotero/storage/4C7YZ6R5/index.html:text/html},
}

@misc{noauthor_v_nodate,
	title = {v. {A} {Gentle} {Introduction} to {XML} - {The} {TEI} {Guidelines}},
	url = {https://www.tei-c.org/release/doc/tei-p5-doc/en/html/SG.html},
	language = {SCHEME=iso639 en},
	urldate = {2022-05-31},
}

@misc{noauthor_extract_nodate-1,
	title = {Extract {Text} from {Images}},
	url = {https://cran.r-project.org/web/packages/tesseract/vignettes/intro.html},
	abstract = {The tesseract package provides R bindings Tesseract: a powerful optical character recognition (OCR) engine that supports over 100 languages. The engine is highly configurable in order to tune the detection algorithms and obtain the best possible results.},
	urldate = {2022-05-31},
}

@misc{noauthor_text_nodate-1,
	title = {Text {Extraction}, {Rendering} and {Converting} of {PDF} {Documents}},
	url = {https://docs.ropensci.org/pdftools/},
	abstract = {Utilities based on libpoppler for extracting text, fonts, attachments and 
    metadata from a PDF file. Also supports high quality rendering of PDF documents into
    PNG, JPEG, TIFF format, or into raw bitmap vectors for further processing in R.},
	language = {en},
	urldate = {2022-05-31},
}

@misc{noauthor_trickypdf_2021,
	title = {trickypdf},
	url = {https://github.com/PolMine/trickypdf/blob/e2ef03731b09d7f0b2b88b81605e294882d1ff61/vignettes/vignette.Rmd},
	abstract = {Turn pdf document into simple annotated XML for further processing in a corpus preparation pipeline.},
	urldate = {2022-05-31},
	publisher = {PolMine},
	month = nov,
	year = {2021},
	note = {original-date: 2017-06-11T10:49:50Z},
}

@article{evert_corpus_nodate,
	title = {Corpus {Encoding} and {Management} {Manual}   {CWB} {Version} 3.5},
	language = {en},
	author = {Evert, Stephanie},
	pages = {27},
	file = {Evert - Corpus Encoding and Management Manual  CWB Versio.pdf:/Users/isabelleborucki/Zotero/storage/3DN8BYM9/Evert - Corpus Encoding and Management Manual  CWB Versio.pdf:application/pdf},
}

@misc{blatte_introducing_nodate,
	title = {Introducing ‘cwbtools’},
	url = {https://cran.r-project.org/web/packages/cwbtools/vignettes/vignette.html},
	abstract = {The cwbtools package offers a toolset to create, modify and manage corpora to be used with the Corpus Workbench (CWB) from within R. It supports the transition from data formats established by well-known R packages such as tm, quanteda or tidytext to a CWB corpus, so that the efficiency of an query system using indexed corpora (i.e. CWB) can be used.},
	urldate = {2022-05-31},
	author = {Blätte, Andreas},
}

@book{desagulier_corpus_2017,
	address = {Cham},
	series = {Quantitative {Methods} in the {Humanities} and {Social} {Sciences}},
	title = {Corpus {Linguistics} and {Statistics} with {R}: {Introduction} to {Quantitative} {Methods} in {Linguistics}},
	isbn = {978-3-319-64570-4 978-3-319-64572-8},
	shorttitle = {Corpus {Linguistics} and {Statistics} with {R}},
	url = {http://link.springer.com/10.1007/978-3-319-64572-8},
	language = {en},
	urldate = {2022-05-31},
	publisher = {Springer International Publishing},
	author = {Desagulier, Guillaume},
	year = {2017},
	doi = {10.1007/978-3-319-64572-8},
	file = {Desagulier - 2017 - Corpus Linguistics and Statistics with R Introduc.pdf:/Users/isabelleborucki/Zotero/storage/2S37RKNS/Desagulier - 2017 - Corpus Linguistics and Statistics with R Introduc.pdf:application/pdf},
}

@book{zufferey_introduction_2020,
	address = {Hoboken},
	title = {Introduction to corpus linguistics},
	isbn = {978-1-78630-417-9},
	language = {en},
	publisher = {ISTE Ltd / John Wiley and Sons},
	author = {Zufferey, Sandrine},
	year = {2020},
	file = {Zufferey - 2020 - Introduction to corpus linguistics.pdf:/Users/isabelleborucki/Zotero/storage/WDVXHNVS/Zufferey - 2020 - Introduction to corpus linguistics.pdf:application/pdf},
}

@article{truan_building_nodate,
	title = {Building, {Encoding}, and {Annotating} a {Corpus} of {Parliamentary} {Debates} in {XML}-{TEI}: {A} {Cross}-{Linguistic} {Account}},
	abstract = {This paper introduces an integrative and comprehensive method for the linguistic annotation of parliamentary discourse. Initially conceived as a documentation for a specific and small-scale research project, the annotation scheme takes into account national specificities and is geared to proposing an annotation scheme that is both highly standardized and adaptable to other research contexts. The paper reads as a specific application of the Text Encoding Initiative (TEI) framework applied to a subset of official transcripts of plenary proceedings in three parliamentary cultures. The TEI annotation scheme proposed here has two main applications: first, it serves as a basis for the encoding of parliamentary corpora by providing a systematic way of annotating both elements within the text (e.g. turns, incidents, interruptions) and the metadata associated with it (e.g. variables pertaining to the speaker or the speech event); second, it provides a cross-linguistic empirical basis for further annotation projects.},
	language = {en},
	author = {Truan, Naomi and Romary, Laurent},
	pages = {29},
	file = {Truan und Romary - Building, Encoding, and Annotating a Corpus of Par.pdf:/Users/isabelleborucki/Zotero/storage/9WV9J4IH/Truan und Romary - Building, Encoding, and Annotating a Corpus of Par.pdf:application/pdf},
}

@incollection{behnke_6_2018,
	title = {6 {Interaktion} und {Dialog} mit großen {Textdaten}: {Korpusanalyse} mit dem „{polmineR}“},
	isbn = {978-3-8452-8655-6},
	shorttitle = {6 {Interaktion} und {Dialog} mit großen {Textdaten}},
	url = {https://www.nomos-elibrary.de/index.php?doi=10.5771/9783845286556-119},
	language = {de},
	urldate = {2022-05-31},
	booktitle = {Computational {Social} {Science}},
	publisher = {Nomos Verlagsgesellschaft mbH \& Co. KG},
	author = {Blätte, Andreas},
	editor = {Behnke, Joachim and Blätte, Andreas and Schnapp, Kai-Uwe and Wagemann, Claudius},
	year = {2018},
	doi = {10.5771/9783845286556-119},
	pages = {119--138},
	file = {Blätte - 2018 - 6 Interaktion und Dialog mit großen Textdaten Kor.pdf:/Users/isabelleborucki/Zotero/storage/GTRQWFRR/Blätte - 2018 - 6 Interaktion und Dialog mit großen Textdaten Kor.pdf:application/pdf},
}

@article{leonhardt_verknupfung_nodate,
	title = {Die {Verknüpfung} von {Textdaten} mit {Identifikatoren}: {Potentiale} - {Optionen} - {Evaluation}},
	language = {de},
	author = {Leonhardt, Christoph and Blätte, Andreas},
	pages = {48},
	file = {Leonhardt und Blätte - Die Verknüpfung von Textdaten mit Identifikatoren.pdf:/Users/isabelleborucki/Zotero/storage/BYEYLMHI/Leonhardt und Blätte - Die Verknüpfung von Textdaten mit Identifikatoren.pdf:application/pdf},
}

@article{griebel_interdisziplinares_2020,
	title = {Interdisziplinäres {Lernen} in der kritischen digitalen {Politikwissenschaft} evaluieren},
	volume = {67},
	issn = {0044-3360},
	url = {https://www.nomos-elibrary.de/index.php?doi=10.5771/0044-3360-2020-3-271},
	doi = {10.5771/0044-3360-2020-3-271},
	abstract = {Aufbauend auf dem Fundament des Critical Realism entwirft der Beitrag eine kritische digitale Politikwissenschaft, welche die menschliche Emanzipation im digitalen Kontext zum Ziel hat. Diese spezielle Form von Interdisziplinarität integriert Einsichten der Computer- und der Sozialwissenschaften durch ein in zweifacher Hinsicht kritisches Bewusstsein. Methoden der Computerwissenschaften müssen mit Gedanken der kritischen Theorie in Kontakt gebracht werden, um die durch sie generierten Ergebnisse interpretieren und die Methoden selbst kritisch hinterfragen zu können. Anschließend skizziert der Beitrag die Vermittlung der kritischen digitalen Politikwissenschaft in einem Bachelor-Seminar im Rahmen einer korpusbasierten Diskursanalyse und legt die durch einen Mixed-Methods-Ansatz gewonnen Erkenntnisse bei der Evaluation des Seminars dar.
          , 
            Building on the foundation of Critical Realism, this article develops a critical digital political science that pursues human emancipation in the digital context. This special form of interdisciplinarity integrates insights from the computational and social sciences on the basis of a two-part form of critical awareness. Methods from the computational sciences must be brought in contact with critical theory in order to interpret the results generated by them and to critically reflect upon these methods themselves. In the following parts, this article describes how critical digital political science was taught in a bachelor seminar with the help of a corpus-assisted discourse analysis and which insights have been gained by a mixed-methods evaluation of the seminar.},
	number = {3},
	urldate = {2022-11-22},
	journal = {Zeitschrift für Politik},
	author = {Griebel, Tim},
	year = {2020},
	pages = {271--293},
}

@article{georgakopoulou_designing_2021,
	series = {Digital language practices: media, awareness, pedagogy},
	title = {Designing stories on social media: {A} corpus-assisted critical perspective on the mismatches of story-curation},
	volume = {62},
	issn = {0898-5898},
	shorttitle = {Designing stories on social media},
	url = {https://www.sciencedirect.com/science/article/pii/S0898589818304212},
	doi = {10.1016/j.linged.2019.05.003},
	abstract = {At a time of increased monetization of social media, there is scope and need for critical-linguistic perspectives to go beyond the focus on users’ linguistic and multi-modal resources. Drawing on the project ‘Life-writing of the moment: The sharing and updating self on social media’ (www.ego-media.org), in this article, I make a case for a corpus-assisted critical perspective which allows the scrutiny of media companies’ design of stories as communication features in their apps. What definitions and views of stories underpin such story-features? What facilities are on offer for posting stories, how are they branded, and why? Who is positioned as an ideal story-creator and audience of those stories and why? I address these questions with reference to the recent story-designing spree on Snapchat and Instagram. The corpus analysis of how stories as an app feature are launched and discussed on online media, incl. keyword analysis and lexical and thematic associations of the term ‘story’, has brought to the fore three mismatches between the marketing rhetoric or branding of stories as a feature and the actual affordances offered for them. These involve tensions and trade-offs between: continuity of self and ephemerality; textuality and visuality; creativity and control for the user vs. pre-selection templates and customization. These mismatches are revealing of a re-designation of key-ingredients of stories, in particular time, memories and audience engagement, so as to suit the apps’ agenda of metricization of users’ lives and their ever closer links with advertising.},
	language = {en},
	urldate = {2022-12-08},
	journal = {Linguistics and Education},
	author = {Georgakopoulou, Alex},
	month = apr,
	year = {2021},
	keywords = {Creativity, Instagram \& Snapchat Stories, Pre-selection templates, Sharing-life-in-the-moment, Visuality},
	pages = {100737},
	file = {ScienceDirect Snapshot:/Users/isabelleborucki/Zotero/storage/XLDJUGXG/S0898589818304212.html:text/html;Submitted Version:/Users/isabelleborucki/Zotero/storage/II2LVBDD/Georgakopoulou - 2021 - Designing stories on social media A corpus-assist.pdf:application/pdf},
}

@inproceedings{abbott_internet_2016,
	address = {Portorož, Slovenia},
	title = {Internet {Argument} {Corpus} 2.0: {An} {SQL} schema for {Dialogic} {Social} {Media} and the {Corpora} to go with it},
	shorttitle = {Internet {Argument} {Corpus} 2.0},
	url = {https://aclanthology.org/L16-1704},
	abstract = {Large scale corpora have benefited many areas of research in natural language processing, but until recently, resources for dialogue have lagged behind. Now, with the emergence of large scale social media websites incorporating a threaded dialogue structure, content feedback, and self-annotation (such as stance labeling), there are valuable new corpora available to researchers. In previous work, we released the INTERNET ARGUMENT CORPUS, one of the first larger scale resources available for opinion sharing dialogue. We now release the INTERNET ARGUMENT CORPUS 2.0 (IAC 2.0) in the hope that others will find it as useful as we have. The IAC 2.0 provides more data than IAC 1.0 and organizes it using an extensible, repurposable SQL schema. The database structure in conjunction with the associated code facilitates querying from and combining multiple dialogically structured data sources. The IAC 2.0 schema provides support for forum posts, quotations, markup (bold, italic, etc), and various annotations, including Stanford CoreNLP annotations. We demonstrate the generalizablity of the schema by providing code to import the ConVote corpus.},
	urldate = {2022-12-08},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'16)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Abbott, Rob and Ecker, Brian and Anand, Pranav and Walker, Marilyn},
	month = may,
	year = {2016},
	pages = {4445--4452},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/4ERFCLDC/Abbott et al. - 2016 - Internet Argument Corpus 2.0 An SQL schema for Di.pdf:application/pdf},
}

@inproceedings{petrovic_edinburgh_2010,
	address = {Los Angeles, California, USA},
	title = {The {Edinburgh} {Twitter} {Corpus}},
	url = {https://aclanthology.org/W10-0513},
	urldate = {2022-12-08},
	booktitle = {Proceedings of the {NAACL} {HLT} 2010 {Workshop} on {Computational} {Linguistics} in a {World} of {Social} {Media}},
	publisher = {Association for Computational Linguistics},
	author = {Petrović, Saša and Osborne, Miles and Lavrenko, Victor},
	month = jun,
	year = {2010},
	pages = {25--26},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/BUPKN7C2/Petrović et al. - 2010 - The Edinburgh Twitter Corpus.pdf:application/pdf},
}

@article{hansson_corpus-assisted_2022,
	title = {Corpus-assisted analysis of legitimation strategies in government social media communication},
	volume = {16},
	issn = {1750-4813},
	url = {https://doi.org/10.1177/17504813221099202},
	doi = {10.1177/17504813221099202},
	abstract = {When governments introduce controversial policies that many citizens disapprove of, officeholders increasingly use discursive legitimation strategies in their public communication to ward off blame. In this paper, we contribute to the study of blame avoidance in government social media communication by exploring how corpus-assisted discourse analysis helps to identify three types of common legitimations: self-defensive appeals to (1) personal authority of policymakers, (2) impersonal authority of rules or documents and (3) goals or effects of policies. We use a specialised corpus of tweets by the Brexit department of the British government (42,618 words) which we analyse both qualitatively and quantitatively. We demonstrate how the analysis of lexical bundles that characterise each type of legitimation might provide a new avenue for identifying the presence, characteristics and uses of these legitimations in larger datasets.},
	language = {en},
	number = {5},
	urldate = {2022-12-08},
	journal = {Discourse \& Communication},
	author = {Hansson, Sten and Page, Ruth},
	month = oct,
	year = {2022},
	note = {Publisher: SAGE Publications},
	pages = {551--571},
	file = {SAGE PDF Full Text:/Users/isabelleborucki/Zotero/storage/I6ATPUTW/Hansson and Page - 2022 - Corpus-assisted analysis of legitimation strategie.pdf:application/pdf},
}

@book{rudiger_corpus_2020,
	title = {Corpus {Approaches} to {Social} {Media}},
	isbn = {978-90-272-6049-9},
	abstract = {From Twitter to Reddit, Facebook, and WhatsApp – social media is a part of modern everyday life. Studying the language used on social media platforms presents great opportunities as well as challenges to corpus linguists. The contributions in Corpus Approaches to Social Media address technical, ethical, and methodological issues by showcasing in-depth social media studies as conducted by corpus scholars. The chapters are based on a variety of social media platforms and include corpus perspectives on the language of online communities, linguistic variation in short media texts, and the role of images in computer-mediated communication. A particularly strong point of the collection are the detailed accounts of the methodological aspects of working with social media corpora. The volume features research applying traditional corpus linguistic methods to social media data as well as novel and innovative research methods for the analysis of multimodal material and atypical corpus texts.},
	language = {en},
	publisher = {John Benjamins Publishing Company},
	author = {Rüdiger, Sofia and Dayter, Daria},
	month = nov,
	year = {2020},
	note = {Google-Books-ID: MI0EEAAAQBAJ},
	keywords = {Computers / Artificial Intelligence / Natural Language Processing, Language Arts \& Disciplines / Linguistics / Sociolinguistics},
}

@misc{noauthor_appendix_nodate,
	title = {{APPENDIX} {A} {CODEBOOK} {Dimensions} of {Incivility}},
	url = {https://1library.net/article/appendix-a-codebook-dimensions-of-incivility.q59d4vrz},
	abstract = {APPENDIX A CODEBOOK Dimensions of Incivility},
	language = {en},
	urldate = {2022-02-19},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/B29CQ535/appendix-a-codebook-dimensions-of-incivility.html:text/html},
}

@article{leiner_too_2019,
	title = {Too {Fast}, too {Straight}, too {Weird}: {Non}-{Reactive} {Indicators} for {Meaningless} {Data} in {Internet} {Surveys}},
	volume = {13},
	url = {https://www.semanticscholar.org/paper/37ed663fbe3e61b4555a1e42f0f58121faa39083},
	doi = {10.18148/SRM/2019.V13I3.7403},
	abstract = {Practitioners use various indicators to screen for meaningless, careless, or fraudulent responses in Internet surveys. This study employs an experimental-like design to empirically test the ability of non-reactive indicators to identify records with low data quality. Findings suggest that careless responses are most reliably identified by questionnaire completion time, but the tested indicators do not allow for detecting intended faking. The article introduces various indicators, their benefits and drawbacks, proposes a completion speed index for common application in data cleaning, and discusses whether to remove meaningless records at all.},
	journal = {Survey research methods},
	author = {Leiner, Dominik J.},
	year = {2019},
	pages = {229--248},
}

@article{yavuz_continuity_2021,
	title = {The {Continuity} of {Students}’ {Disengaged} {Responding} in {Low}-stakes {Assessments}: {Evidence} from {Response} {Times}},
	url = {https://www.semanticscholar.org/paper/b9113d8249c314fe3ba470cbffe20df5319cbef9},
	doi = {10.21449/IJATE.789212},
	abstract = {Response time, Disengaged responding, Insufficient effort responding, Validity, Low-stakes assessments. Abstract: Several studies have been published on disengaged test respondents, and others have analyzed disengaged survey respondents separately. For many largescale assessments, students answer questionnaire and test items in succession. This study examines the percentage of students who continuously engage in disengaged responding behaviors across sections in a low-stakes assessment. The effects on calculated scores of filtering students, based on their responding behaviors, are also analyzed. Data of this study came from the 2015 administration of PISA. For data analysis, frequencies and percentages of engaged students in the sessions were initially calculated using students' response times. To investigate the impact of filtering disengaged respondents on parameter estimation, three groups were created, namely engaged in both measures, engaged only in the test, and engaged only in the questionnaire. Next, several validity checks were performed on each group to verify the accuracy of the classifications and the impact of filtering student groups based on their responding behavior. The results indicate that students who are disengaged in tests tend to continue this behavior when responding to the questionnaire items in PISA. Moreover, the rate of continuity of disengaged responding is non-negligible as can be seen from the effect sizes. On the other hand, removing disengaged students in both measures led to higher or nearly the same performance ratings compared to the other groups. Researchers analyzing the dataset including achievement tests and survey items are recommended to review disengaged responses and filter out students who are continuously showing disengaged responding before performing further statistical analysis.},
	journal = {International Journal of Assessment Tools in Education},
	author = {Yavuz, H.},
	year = {2021},
	pages = {527--541},
}

@article{desimone_dirty_2018,
	title = {Dirty {Data}: {The} {Effects} of {Screening} {Respondents} {Who} {Provide} {Low}-{Quality} {Data} in {Survey} {Research}},
	volume = {33},
	url = {https://www.semanticscholar.org/paper/a944441fd429866037efce12a8a367ad7519745c},
	doi = {10.1007/S10869-017-9514-9},
	abstract = {S2 TL;DR: This study addresses questions about the impact of screening techniques on data and statistical analyses, and serves an initial attempt to estimate descriptive statistics and graphically display the distributions of popular screening techniques.},
	journal = {Journal of Business and Psychology},
	author = {DeSimone, J. and Harms, P.},
	year = {2018},
	pages = {559--577},
}

@article{tawa_response_2021,
	title = {The {Response} {Entropy} {Index}: {Comparative} {Assessment} of {Performance} and {Cultural} {Bias} across {Indices} of {Careless} {Responding}},
	url = {https://www.semanticscholar.org/paper/3e387fdc0414c3d852e6d65451cb7f35745d6884},
	abstract = {The response entropy (RE) index is proposed as a new method for flagging careless response patterns and is determined by calculating the balance of proportions of response types endorsed by participants on Likert-scaled surveys. In the first study, performance of the RE index was compared to other commonly used post hoc indices for detecting careless responding (CR) such as the Mahalanobis distance (MD) and the psychometric synonym (PS) index. Three different types of Bogus Sets (BS) were generated: 1) uniform random values produced by computer (n = 100); 2) normally distributed random values produced by computer (n = 100); and 3) purposefully careless responses produced by human participants (n = 100). The BS data were then implanted in a true, cleaned social science dataset (n = 500). Multinomial logistic regression determined that the RE index made independent contributions from other indices to the prediction of BS. Latent variable analyses suggest that the variability type RE index may be tapping distinct constructs from regression type indices such as the PS index. In study 2, potential cultural bias in CR indices was examined with a true social science dataset (n = 302) comprised of racially diverse participants. Unlike other post hoc indices of CR, the RE index was unrelated to participant race. Further analyses demonstrated that racial differences on other indices of CR could be accounted for by culturally different styles of survey responding. For example, Asian participants’ higher MD scores relative to White participants’ was mediated by a culturally specific acquiescent survey response style. These findings point to the useful of the RE index for detecting CR while also avoiding the conflation of CR with culturally different responding.},
	author = {Tawa, John},
	year = {2021},
}

@article{huang_insufficient_2020,
	title = {Insufficient {Effort} {Responding} as a {Potential} {Confound} between {Survey} {Measures} and {Objective} {Tests}},
	url = {https://www.semanticscholar.org/paper/3a5733d711e645b103650bdc6cc56c378757d40b},
	doi = {10.1007/s10869-020-09707-2},
	abstract = {null},
	journal = {Journal of Business and Psychology},
	author = {Huang, Jason L. and DeSimone, J.},
	year = {2020},
	pages = {1--22},
}

@article{bowling_quick_2021,
	title = {The {Quick} and the {Careless}: {The} {Construct} {Validity} of {Page} {Time} as a {Measure} of {Insufficient} {Effort} {Responding} to {Surveys}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/6a0e6f05571a9d7e8174400ef8f7317925a244fa},
	doi = {10.1177/10944281211056520},
	abstract = {Several recent studies have examined the prevention, causes, and consequences of insufficient effort responding (IER) to surveys. Scientific progress in this area, however, rests on the availability of construct-valid IER measures. In the current paper we describe the potential merits of the page time index, which is computed by counting the number of questionnaire pages to which a participant has responded more quickly than two seconds per item (see Huang et al., 2012 ). We conducted three studies (total N = 1,056) to examine the page time index's construct validity. Across these studies, we found that page time converged highly with other IER indices, that it was sensitive to an experimental manipulation warning participants to respond carefully, and that it predicted the extent to which participants were unable to recognize item content. We also found that page time's validity was superior to that of total completion time and that the two-seconds-per-item rule yielded a construct-valid page time score for items of various word lengths. Given its apparent validity, we provide practical recommendations for the use of the page time index.},
	journal = {Organizational Research Methods},
	author = {Bowling, N. and Huang, Jason L. and Brower, Cheyna K. and Bragg, Caleb B.},
	year = {2021},
	pages = {null},
}

@article{schroeders_detecting_2020,
	title = {Detecting {Careless} {Responding} in {Survey} {Data} {Using} {Stochastic} {Gradient} {Boosting}},
	volume = {82},
	url = {https://www.semanticscholar.org/paper/5b0c4321e9acd3ace40f6feace8d7743926dc0bc},
	doi = {10.1177/00131644211004708},
	abstract = {Careless responding is a bias in survey responses that disregards the actual item content, constituting a threat to the factor structure, reliability, and validity of psychological measurements. Different approaches have been proposed to detect aberrant responses such as probing questions that directly assess test-taking behavior (e.g., bogus items), auxiliary or paradata (e.g., response times), or data-driven statistical techniques (e.g., Mahalanobis distance). In the present study, gradient boosted trees, a state-of-the-art machine learning technique, are introduced to identify careless respondents. The performance of the approach was compared with established techniques previously described in the literature (e.g., statistical outlier methods, consistency analyses, and response pattern functions) using simulated data and empirical data from a web-based study, in which diligent versus careless response behavior was experimentally induced. In the simulation study, gradient boosting machines outperformed traditional detection mechanisms in flagging aberrant responses. However, this advantage did not transfer to the empirical study. In terms of precision, the results of both traditional and the novel detection mechanisms were unsatisfactory, although the latter incorporated response times as additional information. The comparison between the results of the simulation and the online study showed that responses in real-world settings seem to be much more erratic than can be expected from the simulation studies. We critically discuss the generalizability of currently available detection methods and provide an outlook on future research on the detection of aberrant response patterns in survey research.},
	journal = {Educational and Psychological Measurement},
	author = {Schroeders, U. and Schmidt, C. and Gnambs, Timo},
	year = {2020},
	pmid = {34992306},
	pages = {29 -- 56},
}

@article{marjanovic_differentiating_2019,
	title = {Differentiating conscientious from indiscriminate responders in existing {NEO}-{Five} {Factor} {Inventory}-3 data},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/9d14857900e7d49a7b15e6fad775ace12ce4e07d},
	doi = {10.1016/J.JRP.2019.05.009},
	abstract = {null},
	journal = {Journal of Research in Personality},
	author = {Marjanović, Zdravko and Holden, R.},
	year = {2019},
	pages = {null},
}

@article{dupuis_detecting_2018,
	title = {Detecting computer-generated random responding in questionnaire-based data: {A} comparison of seven indices},
	url = {https://www.semanticscholar.org/paper/b2d3950303b7c146f7c557321c6c7116caa2b97e},
	doi = {10.3758/s13428-018-1103-y},
	abstract = {S2 TL;DR: Three of the seven indices in this study appear to be the best estimators for detecting nonhuman response sets and every researcher working with online questionnaires could use them to screen for the presence of such invalid data.},
	journal = {Behavior Research Methods},
	author = {Dupuis, M. and Meier, Emanuele and Cuneo, Félix},
	year = {2018},
	pmid = {30091086},
	pages = {1--10},
}

@article{muenzen_extent_2019,
	title = {Extent, {Correlates}, and {Consequences} of {Careless} and {Inattentive} {Responding} in {Certification} {Job} {Analysis} {Surveys}},
	url = {https://www.semanticscholar.org/paper/169c7aae31d2be103b2cfe7878639db1682ec8d9},
	abstract = {Extent, Correlates, and Consequences of Careless and Inattentive Responding in Certification Job Analysis Surveys by Patricia M. Muenzen MA, Stony Brook University, 1988 Sc.B., Brown University, 1983 Dissertation Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy Industrial/Organizational Psychology},
	author = {Muenzen, P.},
	year = {2019},
}

@article{ulitzsch_response-time-based_2021,
	title = {A {Response}-{Time}-{Based} {Latent} {Response} {Mixture} {Model} for {Identifying} and {Modeling} {Careless} and {Insufficient} {Effort} {Responding} in {Survey} {Data}},
	volume = {87},
	url = {https://www.semanticscholar.org/paper/f6b5f64028abbd7855a3a11ca3d8ba9f7a51640e},
	doi = {10.1007/s11336-021-09817-7},
	abstract = {S2 TL;DR: A model-based approach for detecting manifold manifestations of C/IER at once is presented by leveraging response time (RT) information available from computer-administered questionnaires and integrating theoretical considerations on C/IED with recent psychometric modeling approaches.},
	journal = {Psychometrika},
	author = {Ulitzsch, Esther and Pohl, S. and Khorramdel, Lale and Kroehne, Ulf and Davier, Matthias von},
	year = {2021},
	pmid = {34855118},
	pages = {593 -- 619},
}

@article{goldammer_careless_2020,
	title = {Careless responding in questionnaire measures: {Detection}, impact, and remedies},
	volume = {31},
	url = {https://www.semanticscholar.org/paper/3cc4c968fad9bee17a6fcbe79030e0524232902c},
	doi = {10.1016/j.leaqua.2020.101384},
	abstract = {null},
	journal = {Leadership Quarterly},
	author = {Goldammer, Philippe and Annen, H. and Stöckli, Peter Lucas and Jonas, K.},
	year = {2020},
	pages = {101384},
}

@article{jin_evaluation_2019,
	title = {The {Evaluation} of {Statistical} {Process} {Control} {Methods} to {Monitor} {Interview} {Duration} {During} {Survey} {Data} {Collection}},
	volume = {9},
	url = {https://www.semanticscholar.org/paper/30d6ccb825e1e3c2ddd6f7509824c430f564b08f},
	doi = {10.1177/2158244019854652},
	abstract = {Despite general agreement regarding the usefulness of statistical process control (SPC) tools for monitoring paradata, using SPC from an early phase of the survey fieldwork is rather rare. This study focuses on one type of paradata—interview duration—to fill this void. First, we establish a procedure based on the idea of enabling fieldwork monitoring for the seventh round of the European Social Survey in Belgium from its start. The impact of respondent characteristics on interview duration is controlled for by multiple regression. Moreover, we simulate the real conditions of an ongoing survey data collection process by cumulating data and repeating the identification of problematic interviews each week, on the basis that “new” data are available. Second, for each interview we record and track the results with regard to whether or not it is problematic over the fieldwork period, to examine the consistency of our findings. We find that as more data becomes available, the results concerning whether an interview is problematic changes in only 0.3\% of the cases. Out of the 27 interviews identified as problematic when all information was available, 25 were immediately identified once relevant information was available. Overall, these findings suggest that SPC tools are reliable and efficient in a survey context, and accordingly have great potential for allowing survey practitioners to focus on the interviews for which further examination is needed immediately, rather than when the data collection has been completed.},
	journal = {SAGE Open},
	author = {Jin, Jiayun and Vandenplas, C. and Loosveldt, G.},
	year = {2019},
	pages = {null},
}

@article{hong_methods_2020,
	title = {Methods of {Detecting} {Insufficient} {Effort} {Responding}: {Comparisons} and {Practical} {Recommendations}},
	volume = {80},
	url = {https://www.semanticscholar.org/paper/a2952214ec654df042aeab6af3c1b0bc06122eff},
	doi = {10.1177/0013164419865316},
	abstract = {Insufficient effort responding (IER) affects many forms of assessment in both educational and psychological contexts. Much research has examined different types of IER, IER’s impact on the psychometric properties of test scores, and preprocessing procedures used to detect IER. However, there is a gap in the literature in terms of practical advice for applied researchers and psychometricians when evaluating multiple sources of IER evidence, including the best strategy or combination of strategies when preprocessing data. In this study, we demonstrate how the use of different IER detection methods may affect psychometric properties such as predictive validity and reliability. Moreover, we evaluate how different data cleansing procedures can detect different types of IER. We provide evidence via simulation studies and applied analysis using the ACT’s Engage assessment as a motivating example. Based on the findings of the study, we provide recommendations and future research directions for those who suspect their data may contain responses reflecting careless, random, or biased responding.},
	journal = {Educational and Psychological Measurement},
	author = {Hong, Maxwell R. and Steedle, J. and Cheng, Ying},
	year = {2020},
	pmid = {32158024},
	pages = {312 -- 345},
}

@article{huang_detecting_2012,
	title = {Detecting and {Deterring} {Insufficient} {Effort} {Responding} to {Surveys}},
	volume = {27},
	url = {https://www.semanticscholar.org/paper/adf2b218b70f9b08d7bb225d1d3e665ad5e4a93e},
	doi = {10.1007/S10869-011-9231-8},
	abstract = {null},
	journal = {Journal of Business and Psychology},
	author = {Huang, Jason L. and Curran, P. and Keeney, Jessica and Poposki, Elizabeth M. and DeShon, R.},
	year = {2012},
	pages = {99--114},
}

@article{conijn_assessment_2019,
	title = {The {Assessment} and {Impact} of {Careless} {Responding} in {Routine} {Outcome} {Monitoring} within {Mental} {Health} {Care}},
	volume = {54},
	url = {https://www.semanticscholar.org/paper/357b1eab50d7b530cd2268288d8f7a73e1b56493},
	doi = {10.1080/00273171.2018.1563520},
	abstract = {Abstract Careless responding by mental health patients on self-report assessments is rarely investigated in routine care despite the potential for serious consequences such as faulty clinical decisions. We investigated validity indices most appropriate for detecting careless responding in routine outcome monitoring (ROM) in mental health-care. First, we reviewed indices proposed in previous research for their suitability in ROM. Next, we evaluated six selected indices using data of the Brief Symptom Inventory and the Mood and Anxiety Symptom Questionnaire from 3,483 outpatients. Simulations showed that for typical ROM scales the index, Mahalanobis distance, and inter-item standard deviation may be too strongly confounded with the latent trait value to compare careless responding across patients with different symptom severity. Application of two different classification methods to the validity indices did not converge in similar prevalence estimates of careless responding. Finally, results suggest that careless responding does not have a substantial biasing effect on scale-score statistics. We recommend the person-fit index to screen for random careless responding in large ROM data sets. However, additional research should further investigate methods for detecting repetitive responding in typical ROM data and assess whether there are specific circumstances in which simpler validity statistics or direct screening methods perform similarly as the index.},
	journal = {Multivariate Behavioral Research},
	author = {Conijn, Judith M. and Franz, Gunhild and Emons, W. and Beurs, E. de and Carlier, I.},
	year = {2019},
	pmid = {31001995},
	pages = {593 -- 611},
}

@article{gummer_using_2018,
	title = {Using {Instructed} {Response} {Items} as {Attention} {Checks} in {Web} {Surveys}: {Properties} and {Implementation}},
	volume = {50},
	url = {https://www.semanticscholar.org/paper/1b9e708f041a2ed44e00c4dde433c4cacf933b1b},
	doi = {10.1177/0049124118769083},
	abstract = {Identifying inattentive respondents in self-administered surveys is a challenging goal for survey researchers. Instructed response items (IRIs) provide a measure for inattentiveness in grid questions that is easy to implement. The present article adds to the sparse research on the use and implementation of attention checks by addressing three research objectives. In a first study, we provide evidence that IRIs identify respondents who show an elevated use of straightlining, speeding, item nonresponse, inconsistent answers, and implausible statements throughout a survey. Excluding inattentive respondents, however, did not alter the results of substantive analyses. Our second study suggests that respondents’ inattentiveness partially changes as the context in which they complete the survey changes. In a third study, we present experimental evidence that a mere exposure to an IRI does not negatively or positively affect response behavior within a survey. A critical discussion on using IRI attention checks concludes this article.},
	journal = {Sociological Methods \& Research},
	author = {Gummer, Tobias and Roßmann, Joss and Silber, Henning},
	year = {2018},
	pages = {238 -- 264},
}

@article{kunz_rating_2015,
	title = {Rating scales in {Web} surveys. {A} test of new drag-and-drop rating procedures},
	url = {https://www.semanticscholar.org/paper/250f11c1f3d5c17dad39cd47f7983302f0510214},
	abstract = {In Web surveys, rating scales measuring the respondents’ attitudes and self-descriptions by means of a series of related statements are commonly presented in grid (or matrix) questions. Despite the benefits of displaying multiple rating scale items neatly arranged and supposedly easy to complete on a single screen, respondents are often tempted to rely on cognitive shortcuts in order to reduce the extent of cognitive and navigational effort required to answer a set of rating scale items. In order to minimize this risk of cognitive shortcuts resulting in satisfying rather than optimal answers, respondents have to be motivated to spend extra time and effort on the attentive and careful processing of rating scales. A wide range of visual and dynamic features are available in interactive Web surveys allowing for visual enhancement and greater interactivity in the presentation of survey questions. To date, however, only a few studies have systematically examined new rating scale designs using data input methods other than conventional radio buttons. In the present study, two different rating scales were designed using drag-and-drop as a more interactive data input method: Respondents have to drag the response options towards the rating scale items (‘drag-response’), or in the reverse direction, the rating scale items towards the response options (‘drag-item’). In both drag-and-drop rating scales, the visual highlighting of the items and response options as well as the dynamic strengthening of the link between these key components are aimed at encouraging the respondents to process a rating scale more attentively and carefully. The effectiveness of the drag-and-drop rating scales in preventing the respondents’ susceptibility to cognitive shortcuts is assessed on the basis of five systematic response tendencies that are typically accompanied by rating scales, i.e., careless, nondifferentiated, acquiescent, and extreme responding as well as the respondents’ systematic tendency to select one of the first response options, so called primacy effects. Moreover, item missing data, response times, and respondent evaluation are examined. The findings of the present study revealed that although both drag-and-drop scales entail a higher level of respondent burden as indicated by an increase in item missing data and longer response times compared to conventional radio button scales, they promote the respondents’ attentiveness and carefulness towards the response task which is accompanied by the respondents’ reduced susceptibility to cognitive shortcuts in processing rating scales.},
	author = {Kunz, Tanja},
	year = {2015},
}

@article{steedle_effects_2019,
	title = {The {Effects} of {Inattentive} {Responding} on {Construct} {Validity} {Evidence} {When} {Measuring} {Social}–{Emotional} {Learning} {Competencies}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/aecf54d623b60deafa128b60f0756361fc853632},
	doi = {10.1111/EMIP.12256},
	abstract = {null},
	journal = {Educational Measurement: Issues and Practice},
	author = {Steedle, J. and Hong, Maxwell R. and Cheng, Ying},
	year = {2019},
	pages = {null},
}

@article{curran_methods_2016,
	title = {Methods for the detection of carelessly invalid responses in survey data},
	volume = {66},
	url = {https://www.semanticscholar.org/paper/deb576459476939eacb53937bacc9f42def17341},
	doi = {10.1016/J.JESP.2015.07.006},
	abstract = {S2 TL;DR: Different perspectives into a review and assessment of current tech- niques, an introduction of new techniques, and a generation of recommendations for practical use are aimed at.},
	journal = {Journal of Experimental Social Psychology},
	author = {Curran, P.},
	year = {2016},
	pages = {4--19},
}

@article{carden_cronbachs_2018,
	title = {Cronbach’s {Alpha} under {Insufficient} {Effort} {Responding}: {An} {Analytic} {Approach}},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/c941ea961240aa79d1c239ceae19aaf49977e905},
	doi = {10.3390/STATS2010001},
	abstract = {Surveys commonly suffer from insufficient effort responding (IER). If not accounted for, IER can cause biases and lead to false conclusions. In particular, Cronbach’s alpha has been empirically observed to either deflate or inflate due to IER. This paper will elucidate how IER impacts Cronbach’s alpha in a variety of situations. Previous results concerning internal consistency under mixture models are extended to obtain a characterization of Cronbach’s alpha in terms of item validities, average variances, and average covariances. The characterization is then applied to contaminating distributions representing various types of IER. The discussion will provide commentary on previous simulation-based investigations, confirming some previous hypotheses for the common types of IER, but also revealing possibilities from newly considered responding patterns. Specifically, it is possible that the bias can change from negative to positive (and vice versa) as the proportion of contamination increases.},
	journal = {Stats},
	author = {Carden, S. and Camper, Trevor R. and Holtzman, Nicholas S.},
	year = {2018},
	pages = {null},
}

@article{kung_are_2018,
	title = {Are {Attention} {Check} {Questions} a {Threat} to {Scale} {Validity}?},
	volume = {67},
	url = {https://www.semanticscholar.org/paper/7b1859560da9cf2165811f0317defce9a45123b2},
	doi = {10.1111/apps.12108},
	abstract = {Attention checks have become increasingly popular in survey research as a means to filter out careless respondents. Despite their widespread use, little research has empirically tested the impact of attention checks on scale validity. In fact, because attention checks can induce a more deliberative mindset in survey respondents, they may change the way respondents answer survey questions, posing a threat to scale validity. In two studies, we tested this hypothesis (N 5 816). We examined whether common attention checks—instructedresponse items (Study 1) and an instructional manipulation check (Study 2)— impact responses to a well-validated management scale. Results showed no evidence that they affect scale validity, both in reported scale means and tests of measurement invariance. These findings allow researchers to justify the use of attention checks without compromising scale validity and encourage future research to examine other survey characteristic-respondent dynamics to advance our use of survey methods.},
	journal = {Applied Psychology},
	author = {Kung, Franki Y. H. and Kwok, N. and Brown, Douglas J.},
	year = {2018},
	pages = {264--283},
}

@article{bowling_will_2020,
	title = {Will the {Questions} {Ever} {End}? {Person}-{Level} {Increases} in {Careless} {Responding} {During} {Questionnaire} {Completion}},
	volume = {24},
	url = {https://www.semanticscholar.org/paper/4e265d1a66a7eb4edc2409b24687507ce0fb89d2},
	doi = {10.1177/1094428120947794},
	abstract = {Is there a point within a self-report questionnaire where participants will start responding carelessly? If so, then after how many items do participants reach that point? And what can researchers do to encourage participants to remain careful throughout the entirety of a questionnaire? We conducted two studies (Study 1 N = 358; Study 2 N = 129) to address these questions. Our results found (a) consistent evidence that participants responded more carelessly as they progressed further into a questionnaire, (b) mixed evidence that participants who were warned that carelessness would be punished displayed smaller increases in carelessness, and (c) mixed evidence that increases in carelessness were greater within an unproctored online study (Study 1) than within a proctored laboratory study (Study 2). These findings help address when and why careless responding is likely to occur, and they suggest effective preventive strategies.},
	journal = {Organizational Research Methods},
	author = {Bowling, N. and Gibson, Anthony M. and Houpt, Joseph W. and Brower, Cheyna K.},
	year = {2020},
	pages = {718 -- 738},
}

@article{zhong_preventing_2021,
	title = {Preventing and detecting insufficient effort survey responding},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/777ce79960706c1271bfc08c9ed832dc4fd2610d},
	doi = {10.3724/SP.J.1042.2021.00225},
	abstract = {: Surveys are commonly used in psychological and educational research. Insufficient effort response (IER), as one source of invalid response data, is somewhat prevalent due to the low-stakes nature of the majority of surveys, which often leads to statistically significantly biased estimates and invalid inferences. The current literature shows: (a) IER is commonly believed to be caused by some inner causes, (e.g., low motivation), showing as specific patterns, (e.g., random responding); (b) The most common methods to prevent IER include reducing task difficulty and increasing respondents’ motivation; (c) Current detection methods fall into three main categories, which are proactive approaches/ direct screening methods, response patterns analysis, and response time analysis. Recommendations for future research directions and practitioners are (a) deepening the investigation on IER mechanism and improving the preventing methods, (b) examining the effectiveness of IER identification methods’ applicability of cross-situation and developing new approaches, and (c) delving into the identification and treatment of partial IER.},
	journal = {Advances in Psychological Science},
	author = {Zhong, Xiaoyu and Li, Ming-yan and Li, Lingyan},
	year = {2021},
	pages = {null},
}

@article{dogan_novel_2018,
	title = {A novel method for detecting careless respondents in survey data: floodlight detection of careless respondents},
	volume = {6},
	url = {https://www.semanticscholar.org/paper/a11890b67f591d1b9c8162c090a0dbbd70642110},
	doi = {10.1057/S41270-018-0035-9},
	abstract = {null},
	journal = {Journal of Marketing Analytics},
	author = {Doğan, V.},
	year = {2018},
	pages = {95--104},
}

@article{schneider_careless_2018,
	title = {Careless responding in internet-based quality of life assessments},
	volume = {27},
	url = {https://www.semanticscholar.org/paper/566eaa24767cbbd5e193ee0316317108ef1030b9},
	doi = {10.1007/s11136-017-1767-2},
	abstract = {S2 TL;DR: The results support the importance of identifying and screening out careless responders to ensure high-quality self-report data in Internet-based QoL research.},
	journal = {Quality of Life Research},
	author = {Schneider, Stefan and May, Marcella and Stone, A.},
	year = {2018},
	pmid = {29248996},
	pages = {1077--1088},
}

@article{bais_investigating_2020,
	title = {Investigating {Response} {Patterns} {Across} {Surveys}: {Do} {Respondents} {Show} {Consistency} in {Undesirable} {Answer} {Behaviour} over {Multiple} {Surveys}?},
	volume = {147-148},
	url = {https://www.semanticscholar.org/paper/33be5c0eb4606bb6d05455cef81472f1ac276aab},
	doi = {10.1177/0759106320939891},
	abstract = {The relation between answer behaviour and measurement error has been studied extensively. Answer behaviour may be considered undesirable, like answering ‘don’t know’ or ‘won’t tell’. It is not clear to what degree undesirable answer behaviour from the same respondents is present across different surveys. In this study, we investigated to what extent respondents show undesirable answer behaviours consistently over multiple surveys. First, we investigated to what extent the answer behaviours occurred in ten large general population surveys of CentERdata and Statistics Netherlands. Second, we explored the respondent variances and respondent-survey interaction variances to obtain an indication for respondent consistency for each answer behaviour. The results showed that respondents only occasionally give ‘don’t know’– and ‘won’t tell’-answers. An indication for respondent consistency was found for fast responding, slow responding, and ‘won’t tell’-answers in particular. We recommend follow-up research to investigate the relation between respondent characteristics and consistent answer behaviour.},
	journal = {Bulletin de Méthodologie Sociologique},
	author = {Bais, F. and Schouten, B. and Toepoel, V.},
	year = {2020},
	pages = {150 -- 168},
}

@article{gibson_effects_2020,
	title = {The {Effects} of {Questionnaire} {Length} and {Behavioral} {Consequences} on {Careless} {Responding}},
	volume = {36},
	url = {https://www.semanticscholar.org/paper/0ed80c8195e6c46d691f757d450452355c64b11b},
	doi = {10.1027/1015-5759/A000526},
	abstract = {Abstract. The current paper reports the results of two randomized experiments designed to test the effects of questionnaire length on careless responding (CR). Both experiments also examined whethe...},
	journal = {European Journal of Psychological Assessment},
	author = {Gibson, Anthony M. and Bowling, N.},
	year = {2020},
	pages = {410--420},
}

@article{desimone_differential_2018,
	title = {The {Differential} {Impacts} of {Two} {Forms} of {Insufficient} {Effort} {Responding}},
	volume = {67},
	url = {https://www.semanticscholar.org/paper/f5ab19be34f01ba013886d281dd1332eb68cc447},
	doi = {10.1111/apps.12117},
	abstract = {Recent years have seen a renewed interest in insufficient effort responding (IER). Previous research has demonstrated that IER can have detrimental effects on survey research ranging from introducing untrustworthy data to influencing psychometric and statistical results. The present simulations examine two forms of IER, straightlining (SL) and random responding (RR), in an attempt to determine whether the presence of these response patterns have differential impacts on data. In three studies, we explore the combined effects of extreme SL and RR, the effects of full and partial RR, and the effects of full and partial SL on scale characteristics such as inter-item correlations, alpha, and component structure. We also explore how various IER response distributions may influence these statistics. Empirical results demonstrate a tendency for SL to increase and RR to decrease the magnitude of inter-item correlations, alpha, and the first component eigenvalue. Results also indicate that the impact of SL may be more pronounced than the impact of RR in the organisational sciences. It is important for researchers to consider the type of IER in addition to the prevalence of IER in a sample prior to conducting statistical analyses.},
	journal = {Applied Psychology},
	author = {DeSimone, J. and DeSimone, Alice J. and Harms, P. and Wood, D.},
	year = {2018},
	pages = {309--338},
}

@article{francavilla_social_2018,
	title = {Social {Interaction} and {Internet}‐{Based} {Surveys}: {Examining} the {Effects} of {Virtual} and {In}‐{Person} {Proctors} on {Careless} {Response}},
	volume = {68},
	url = {https://www.semanticscholar.org/paper/2e393a9249f62a5d9db768d8eec9a3fdb93eb4f4},
	doi = {10.1111/apps.12159},
	abstract = {A lack of human interaction and environmental control in Internet‐based data collection have been suggested as possible antecedents of careless responding, which occurs when participants respond to survey items without regard for item content. To address these possible antecedents, this study investigated whether survey proctoring deterred careless response in an undergraduate sample by reducing environmental distractions. The study randomly assigned respondents to one of three proctoring conditions: remote online un‐proctored, remote online virtually proctored, and in‐person classroom proctored. Data quality was examined via nine careless response indicators. Analyses indicated that proctor presence had effects on a small number of careless response indicators. Virtually proctored participants performed better than un‐proctored participants on one of nine careless response indicators, and in‐person proctored participants performed better on two careless response indicators compared to un‐proctored participants. Environmental distraction fully mediated the relationship between in‐person proctor presence and self‐reported diligence. Implications for survey administration are discussed.},
	journal = {Applied Psychology},
	author = {Francavilla, N. M. and Meade, A. and Young, A. L.},
	year = {2018},
	pages = {223--249},
}

@article{read_racing_2021,
	title = {Racing the {Clock}: {Using} {Response} {Time} as a {Proxy} for {Attentiveness} on {Self}-{Administered} {Surveys}},
	volume = {30},
	url = {https://www.semanticscholar.org/paper/f736d3ec4b0a313d0b12d9bdcb15b3c1e377b277},
	doi = {10.1017/pan.2021.32},
	abstract = {Abstract Internet-based surveys have expanded public opinion data collection at the expense of monitoring respondent attentiveness, potentially compromising data quality. Researchers now have to evaluate attentiveness ex-post. We propose a new proxy for attentiveness—response-time attentiveness clustering (RTAC)—that uses dimension reduction and an unsupervised clustering algorithm to leverage variation in response time between respondents and across questions. We advance the literature theoretically arguing that the existing dichotomous classification of respondents as fast or attentive is insufficient and neglects slow and inattentive respondents. We validate our theoretical classification and empirical strategy against commonly used proxies for survey attentiveness. In contrast to other methods for capturing attentiveness, RTAC allows researchers to collect attentiveness data unobtrusively without sacrificing space on the survey instrument.},
	journal = {Political Analysis},
	author = {Read, Blair and Wolters, L. and Berinsky, A.},
	year = {2021},
	pages = {550 -- 569},
}

@article{kim_detecting_2018,
	title = {Detecting random responders with infrequency scales using an error-balancing threshold},
	volume = {50},
	url = {https://www.semanticscholar.org/paper/82c80e497177a5124c9c2faa77408a7ab70c76d6},
	doi = {10.3758/s13428-017-0964-9},
	abstract = {S2 TL;DR: A traditional zero-tolerance approach, on average, screens data that are less indicative of careless responding than those screened by the error-balancing approach, so that meaningful responses may also be removed from analyses.},
	journal = {Behavior Research Methods},
	author = {Kim, Dale S. and McCabe, Connor J. and Yamasaki, Brianna L. and Louie, Kristine A. and King, K.},
	year = {2018},
	pmid = {28936811},
	pages = {1960--1970},
}

@article{matjasic_web_2018,
	title = {Web {Survey} {Paradata} on {Response} {Time} {Outliers}: {A} {Systematic} {Literature} {Review}},
	url = {https://www.semanticscholar.org/paper/1dda8d32f93b843ce3269601c72f4f56215afc0f},
	abstract = {In the last two decades, survey researchers have intensively used computerised methods for the collection of different types of paradata, such as keystrokes, mouse clicks and response times, to evaluate and improve survey instruments as well as to understand the survey response process. With the growing popularity of web surveys, the importance of paradata has further increased. Within this context, response time measurement is the prevailing paradata approach. Papers typically analyse the time (measured in milliseconds or seconds) a respondent needs to answer a certain item, question, page or questionnaire. One of the key challenges when analysing the response time is to identify and separate units that are answering too quickly or too slowly. These units can have a poor response quality and are typically labelled as response time outliers. This paper focuses on approaches for identifying and processing response time outliers. It presents a systematic overview of scientific papers on response time outliers in web surveys. The key observed characteristics of the papers are the approaches used, the level of time measurement, the processing of response time outliers and the relationship between response time and response quality. The results show that knowledge on response time outliers is scattered, inconsistent and lacking systematic comparisons of approaches. Consequently, there is a need to improve and upgrade the knowledge on this issue and to develop new approaches that will overcome existing deficiencies and inconsistencies in identifying and dealing with response time outliers.},
	author = {Matjašič, M. and Vehovar, V. and Manfreda, K.},
	year = {2018},
}

@article{magrawmickelson_survey_2020,
	title = {Survey mode and data quality: {Careless} responding across three modes in cross-cultural contexts},
	volume = {22},
	url = {https://www.semanticscholar.org/paper/2edcd45bd3489f57a86c24d30d205c40a9037caf},
	doi = {10.1080/15305058.2021.2019747},
	abstract = {Abstract Much psychological research depends on participants’ diligence in filling out materials such as surveys. However, not all participants are motivated to respond attentively, which leads to unintended issues with data quality, known as careless responding. Our question is: how do different modes of data collection—paper/pencil, computer/web-based, and smartphone—affect participants’ diligence vs. “careless responding” tendencies and, thus, data quality? Results from prior studies suggest that different data collection modes produce a comparable prevalence of careless responding tendencies. However, as technology develops and data are collected with increasingly diversified populations, this question needs to be readdressed and taken further. The present research examined the effect of survey mode on careless responding in a repeated-measures design with data from three different samples. First, in a sample of working adults from China, we found that participants were slightly more careless when completing computer/web-based survey materials than in paper/pencil mode. Next, in a German student sample, participants were slightly more careless when completing the paper/pencil mode compared to the smartphone mode. Finally, in a sample of Chinese-speaking students, we found no difference between modes. Overall, in a meta-analysis of the findings, we found minimal difference between modes across cultures. Theoretical and practical implications are discussed.},
	journal = {International Journal of Testing},
	author = {Magraw‐Mickelson, Zoe and Wang, H. and Gollwitzer, M.},
	year = {2020},
	pages = {121 -- 153},
}

@article{gummer_explaining_2015,
	title = {Explaining {Interview} {Duration} in {Web} {Surveys}},
	volume = {33},
	url = {https://www.semanticscholar.org/paper/c13392e8b6f8810db2687df6e3247d394d7e162a},
	doi = {10.1177/0894439314533479},
	abstract = {Interview duration is an important variable in web surveys because it is a direct measure of the response burden. In this article, we analyze the effects of the survey design, respondent characteristics, and the interaction between these effects on interview duration. For that purpose, we applied multilevel analysis to a data set of 21 web surveys on political attitudes and behavior. Our results showed that factors on both levels, the individual and the survey level, had effects on interview duration. However, the larger share of the variation in interview duration is explained by the characteristics of the respondents. In this respect, we illustrate the impact of mobile devices and panel recruitment on interview duration. In addition, we found important relationships between the respondents’ attitudes and how a web survey is designed: Highly motivated respondents spent significantly more time answering cognitively demanding questions than less motivated respondents. When planning a survey, not only the number and formats of questions need to be taken into account but also the expected sample composition and how the participants will respond to the design of the web survey.},
	journal = {Social Science Computer Review},
	author = {Gummer, Tobias and Roßmann, Joss},
	year = {2015},
	pages = {217 -- 234},
}

@article{jin_mixture_2018,
	title = {Mixture {Item} {Response} {Models} for {Inattentive} {Responding} {Behavior}},
	volume = {21},
	url = {https://www.semanticscholar.org/paper/9e39e8035d924c2a3301b4d41539504876157832},
	doi = {10.1177/1094428117725792},
	abstract = {Inattentive responses can threaten measurement quality, yet they are common in rating- or Likert-scale data. In this study, we proposed a new mixture item response theory model to distinguish inattentive responses from normal responses so that test validity can be ascertained. Simulation studies demonstrated that the parameters of the new model were recovered fairly well using the Bayesian methods implemented in the freeware WinBUGS, and fitting the new model to data that lacked inattentive responses did not result in severely biased parameter estimates. In contrast, ignoring inattentive responses by fitting standard item response theory models to data containing inattentive responses yielded seriously biased parameter estimates and a failure to distinguish inattentive participants from normal participants; the person-fit statistic lz was also unsatisfactory in identifying inattentive responses. Two empirical examples demonstrate the applications of the new model.},
	journal = {Organizational Research Methods},
	author = {Jin, K. and Chen, Hui-Fang and Wang, Wen-Chung},
	year = {2018},
	pages = {197 -- 225},
}

@article{grau_cultural_2019,
	title = {Cultural {Differences} in {Careless} {Responding}},
	volume = {50},
	url = {https://www.semanticscholar.org/paper/26b06895bc689cc7ba6dc3f1775cdfa0117adb93},
	doi = {10.1177/0022022119827379},
	abstract = {Careless responding (CR) in surveys has been identified as a serious threat for the validity of survey data. It occurs when participants respond without following the instructions or reading the content of items. The purpose of this article is to assess and explain the amount of CR at the individual and country level. In our study, individual CR (measured by indices using a short Big 5 personality questionnaire) correlated with education level and personality traits. In addition, using a sample of 8,320 participants from 34 countries, CR at the country level was investigated and it was strongly correlated with the cultural dimensions: human development, individualism, gender inequality, and power distance. CR can be seen as a powerful predictor of differences between countries. Finally, a comparison between CR and response styles (extreme and midpoint answers, acquiescence, and socially desirable responses) was conducted. CR and response styles showed some overlap, but loaded on different factors. CR is compatible with extreme answers, midpoint answers, and acquiescence, but different from social desirability. Social desirability is the only response style which requires careful reading of items.},
	journal = {Journal of Cross-Cultural Psychology},
	author = {Grau, Ina and Ebbeler, Christine and Banse, R.},
	year = {2019},
	pages = {336 -- 357},
}

@article{gibson_stop_2019,
	title = {Stop what you’re doing, right now! {Effects} of interactive messages on careless responding},
	url = {https://www.semanticscholar.org/paper/1dab1bc94d05bea7e78f512caa719190a04f99d6},
	abstract = {null},
	author = {Gibson, Anthony M.},
	year = {2019},
}

@article{steedle_detecting_2018,
	title = {Detecting {Inattentive} {Responding} on a {Psychosocial} {Measure} of {College} {Readiness}. {Research} {Report} 2018-5.},
	url = {https://www.semanticscholar.org/paper/d0737fa6e5dee808477539aaec52c893312495db},
	abstract = {Self-report inventories are commonly administered to measure social and emotional learning competencies related to college readiness. If students respond inattentively or dishonestly, validity will suffer. This study applies several methods of detecting insufficient effort responding (IER) to data from ACT® Engage®. Different methods indicated that between 0.8\% and 20.3\% of respondents exhibited IER, but filtering those students from the data resulted in negligible improvements in criterion-related validity, coefficient alpha, convergent validity, and confirmatory factor analysis model-data fit. Even so, researchers are advised to investigate IER. Analyses affirmed that the IER detection methods effectively flagged suspect item score patterns, so these methods may still be used to flag individual results as potentially invalid.},
	author = {Steedle, J.},
	year = {2018},
}

@article{ulitzsch_explanatory_2022,
	title = {An explanatory mixture {IRT} model for careless and insufficient effort responding in self-report measures.},
	volume = {null},
	url = {https://www.semanticscholar.org/paper/b0a503669304d0cef3f73f2d8f5989e9e587de83},
	doi = {10.1111/bmsp.12272},
	abstract = {Careless and insufficient effort responding (C/IER) on self-report measures results in responses that do not reflect the trait to be measured, thereby posing a major threat to the quality of survey data. Reliable approaches for detecting C/IER aid in increasing the validity of inferences being made from survey data. First, once detected, C/IER can be taken into account in data analysis. Second, approaches for detecting C/IER support a better understanding of its occurrence, which facilitates designing surveys that curb the prevalence of C/IER. Previous approaches for detecting C/IER are limited in that they identify C/IER at the aggregate respondent or scale level, thereby hindering investigations of item characteristics evoking C/IER. We propose an explanatory mixture item response theory model that supports identifying and modelling C/IER at the respondent-by-item level, can detect a wide array of C/IER patterns, and facilitates a deeper understanding of item characteristics associated with its occurrence. As the approach only requires raw response data, it is applicable to data from paper-and-pencil and online surveys. The model shows good parameter recovery and can well handle the simultaneous occurrence of multiple types of C/IER patterns in simulated data. The approach is illustrated on a publicly available Big Five inventory data set, where we found later item positions to be associated with higher C/IER probabilities. We gathered initial supporting validity evidence for the proposed approach by investigating agreement with multiple commonly employed indicators of C/IER.},
	journal = {The British journal of mathematical and statistical psychology},
	author = {Ulitzsch, Esther and Yildirim-Erbasli, S. N. and Gorgun, Guher and Bulut, O.},
	year = {2022},
	pmid = {35730351},
	pages = {null},
}

@article{camper_essays_2019,
	title = {Essays on {Mixture} {Models}},
	url = {https://www.semanticscholar.org/paper/ebce23e2a02d242fd425bba80e4cb24fcb8575d3},
	abstract = {null},
	author = {Camper, Trevor R.},
	year = {2019},
}

@article{montgomery_social_nodate,
	title = {Social {Media} {Platform} {Safeguards} for {Whom}?},
	language = {en},
	author = {Montgomery, Kathryn C},
	pages = {49},
	file = {Montgomery - Social Media Platform Safeguards for Whom.pdf:/Users/isabelleborucki/Zotero/storage/F9TDYIQB/Montgomery - Social Media Platform Safeguards for Whom.pdf:application/pdf},
}

@incollection{wenzelburger_prozessanalyse_2015,
	address = {Wiesbaden},
	title = {Prozessanalyse},
	isbn = {978-3-658-01967-9 978-3-658-01968-6},
	url = {http://link.springer.com/10.1007/978-3-658-01968-6_18},
	language = {de},
	urldate = {2021-11-10},
	booktitle = {Handbuch {Policy}-{Forschung}},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Starke, Peter},
	editor = {Wenzelburger, Georg and Zohlnhöfer, Reimut},
	year = {2015},
	doi = {10.1007/978-3-658-01968-6_18},
	pages = {453--482},
	file = {Starke - 2015 - Prozessanalyse.pdf:/Users/isabelleborucki/Zotero/storage/BLMGICSI/Starke - 2015 - Prozessanalyse.pdf:application/pdf},
}

@article{fowler_blue_2020,
	title = {The {Blue} {Wave}: {Assessing} {Political} {Advertising} {Trends} and {Democratic} {Advantages} in 2018},
	volume = {53},
	issn = {1049-0965, 1537-5935},
	shorttitle = {The {Blue} {Wave}},
	url = {https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/blue-wave-assessing-political-advertising-trends-and-democratic-advantages-in-2018/5545DDBE51267FEBB492E08F24DD4B3E/share/d5c20e79fb7a891983284e83528113ef16b344bf},
	doi = {10.1017/S1049096519001240},
	abstract = {This research offers a post-mortem on political advertising in 2018, providing important context for 2018’s “blue wave.” In a majority of US House of Representatives races, there were more pro-Democratic than pro-Republican ads, including in the most competitive contests. The one theme that united pro-Democratic advertising was health care, which was mentioned in nearly three of every five Democratic ads in the fall campaign. Contrary to the narrative that television is declining, a record number of television ads aired in the 2018 midterms, whereas digital spending still constituted a small percentage of overall advertising spending for most candidate campaigns. Finally, there was a healthy volume of outside-group spending in 2018, with “dark-money” groups increasing their involvement—especially in support of Democratic candidates.},
	language = {en},
	number = {1},
	urldate = {2020-11-03},
	journal = {PS: Political Science \& Politics},
	author = {Fowler, Erika Franklin and Franz, Michael M. and Ridout, Travis N.},
	month = jan,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	pages = {57--63},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/MYWZNQM5/d5c20e79fb7a891983284e83528113ef16b344bf.html:text/html},
}

@book{beach_process-tracing_2019,
	title = {Process-tracing {Methods}: {Foundations} and {Guidelines}},
	isbn = {978-0-472-03735-3},
	shorttitle = {Process-tracing {Methods}},
	abstract = {Revised edition of the authors' Process-tracing methods, c2013.},
	language = {en},
	publisher = {University of Michigan Press},
	author = {Beach, Derek and Pedersen, Rasmus Brun},
	month = jan,
	year = {2019},
	note = {Google-Books-ID: jul3DwAAQBAJ},
	keywords = {Social Science / Methodology},
}

@article{collier_understanding_2011,
	title = {Understanding {Process} {Tracing}},
	volume = {44},
	issn = {1049-0965, 1537-5935},
	url = {http://www.journals.cambridge.org/abstract_S1049096511001429},
	doi = {10.1017/S1049096511001429},
	abstract = {Process tracing is a fundamental tool of qualitative analysis. This method is often invoked by scholars who carry out within-case analysis based on qualitative data, yet frequently it is neither adequately understood nor rigorously applied. This deﬁcit motivates this article, which oﬀers a new framework for carrying out process tracing. The reformulation integrates discussions of process tracing and causal-process observations, gives greater attention to description as a key contribution, and emphasizes the causal sequence in which process-tracing observations can be situated. In the current period of major innovation in quantitative tools for causal inference, this reformulation is part of a wider, parallel eﬀort to achieve greater systematization of qualitative methods. A key point here is that these methods can add inferential leverage that is often lacking in quantitative analysis. This article is accompanied by online teaching exercises, focused on four examples from American politics, two from comparative politics, three from international relations, and one from public health/epidemiology.},
	language = {en},
	number = {04},
	urldate = {2020-10-23},
	journal = {PS: Political Science \& Politics},
	author = {Collier, David},
	month = oct,
	year = {2011},
	pages = {823--830},
	file = {Collier - 2011 - Understanding Process Tracing.pdf:/Users/isabelleborucki/Zotero/storage/WQ8JBUZD/Collier - 2011 - Understanding Process Tracing.pdf:application/pdf},
}

@article{rohlfing_varieties_2013,
	title = {Varieties of {Process} {Tracing} and {Ways} to {Answer} {Why}-{Questions}},
	volume = {12},
	issn = {1682-0983},
	url = {https://doi.org/10.1057/eps.2012.7},
	doi = {10.1057/eps.2012.7},
	abstract = {A fit between theory and method is essential in theory – guided empirical research. Achieving such a fit in process tracing is less straightforward than it may seem at first glance. There are two different types of processes that one can theorise and, consequently, two varieties of process tracing. The two varieties are introduced by empirical examples and distinguished with respect to four characteristics. Failure to determine the form of process tracing at hand may lead to invalid causal inferences.},
	language = {en},
	number = {1},
	urldate = {2020-10-14},
	journal = {European Political Science},
	author = {Rohlfing, Ingo},
	month = mar,
	year = {2013},
	pages = {31--39},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/4QUSN7YY/Rohlfing - 2013 - Varieties of Process Tracing and Ways to Answer Wh.pdf:application/pdf},
}

@article{beach_integrating_2018,
	title = {Integrating {Cross}-case {Analyses} and {Process} {Tracing} in {Set}-{Theoretic} {Research}: {Strategies} and {Parameters} of {Debate}},
	volume = {47},
	issn = {0049-1241},
	shorttitle = {Integrating {Cross}-case {Analyses} and {Process} {Tracing} in {Set}-{Theoretic} {Research}},
	url = {https://doi.org/10.1177/0049124115613780},
	doi = {10.1177/0049124115613780},
	abstract = {In recent years, there has been increasing interest in the combination of two methods on the basis of set theory. In our introduction and this special issue, we focus on two variants of cross-case set-theoretic methods?qualitative comparative analysis (QCA) and typological theory (TT)?and their combination with process tracing (PT). Our goal is to broaden and deepen set-theoretic empirical research and equip scholars with guidance on how to implement it in multimethod research (MMR). At first glance, set-theoretic cross-case methods and PT seem to be highly compatible when causal relationships are conceptualized in terms of set theory. However, multiple issues have not so far been thoroughly addressed. Our article builds on the emerging MMR literature and seeks to enhance it in four ways. First, we offer a comprehensive and coherent elaboration of the two sequences in which case studies can be combined with a cross-case method. Second, we expand the perspective and discuss QCA and TT as two alternative methods for the cross-case analysis. Third, based on the idea of analytical priority, we introduce the distinction between a condition-centered and a mechanism-centered variant of set-theoretic MMR. Fourth, we point attention to the challenges of theorizing and analyzing arrangements of conditions and mechanisms associated with sufficient conjunctions.},
	number = {1},
	urldate = {2020-10-14},
	journal = {Sociological Methods \& Research},
	author = {Beach, Derek and Rohlfing, Ingo},
	month = jan,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	pages = {3--36},
	file = {SAGE PDF Full Text:/Users/isabelleborucki/Zotero/storage/7Z42377S/Beach and Rohlfing - 2018 - Integrating Cross-case Analyses and Process Tracin.pdf:application/pdf},
}

@article{rohlfing_time-varying_2019,
	title = {The time-varying relationship between economic globalization and the ideological center of gravity of party systems},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0212945},
	doi = {10.1371/journal.pone.0212945},
	abstract = {Does economic globalization influence the positioning of parties and, as a consequence, the ideological characteristics of party systems? Answering this question is important because we need to understand the constraints that parties face in formulating policies from which voters have to choose. In our paper, we take a systemic perspective and conceptualize a party system’s ideological center of gravity as the outcome of interest. We define the center of gravity as the weighted mean position of all parliamentary parties in a country that represents the position to which parties gravitate. We start by formulating static hypotheses on the effect of imports and exports on the center of gravity and derive their underlying mechanisms. We further derive dynamic hypotheses stipulating varying effects over time based on the premise that partisan attitudes toward globalization have undergone multiple changes over the last decades. A time-series cross-section analysis of 129 elections in 15 Western European countries from 1974 to 2015 finds evidence for opposite effects of exports and imports in the pooled data. Additionally, a moving-window analysis indicates that the relationship between globalization and the center of gravity varies over time. This is a significant finding because it suggests that economic globalization has an influence on party systems and that it is important to test for time-varying effects.},
	language = {en},
	number = {2},
	urldate = {2020-10-14},
	journal = {PLOS ONE},
	author = {Rohlfing, Ingo and Schafföner, Tobias},
	month = feb,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Europe, Elections, Economic analysis, Economic impact analysis, Economics, Finance, Labor economics, Psychological attitudes},
	pages = {e0212945},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/L692GSXF/Rohlfing and Schafföner - 2019 - The time-varying relationship between economic glo.pdf:application/pdf},
}

@article{rohlfing_asset_2015,
	title = {Asset or liability? {An} analysis of the effect of changes in party membership on partisan ideological change},
	volume = {21},
	issn = {1354-0688},
	shorttitle = {Asset or liability?},
	url = {https://doi.org/10.1177/1354068812472405},
	doi = {10.1177/1354068812472405},
	abstract = {The role of members of political parties is ambiguous because it entails both benefits and costs. In order to shed light on the question of whether members are an asset or a liability for parties, I examine whether parties use their ideology on a left?right dimension as a collective incentive for the appeal to actual and potential party members. A quantitative analysis of the effects of changes in membership on partisan ideological change, covering 61 parties in 11 Western democracies from the 1950s to the early 1990s, shows that there is a weak, but statistically significant, effect. An additional analysis of two mechanisms by which membership has an effect refutes the alternative explanation that positional changes of the median member account for partisan ideological change. In total, the results indicate that members are both an asset and a liability and that parties try to keep the two in balance.},
	number = {1},
	urldate = {2020-10-14},
	journal = {Party Politics},
	author = {Rohlfing, Ingo},
	month = jan,
	year = {2015},
	note = {Publisher: SAGE Publications Ltd},
	pages = {17--27},
	file = {SAGE PDF Full Text:/Users/isabelleborucki/Zotero/storage/QBFQU8EN/Rohlfing - 2015 - Asset or liability An analysis of the effect of c.pdf:application/pdf},
}

@incollection{lambach_process-tracing_2016,
	address = {Wiesbaden},
	title = {Process-{Tracing} und das {Kausalmodell} von {Staatskollaps}},
	isbn = {978-3-658-11823-5},
	url = {https://doi.org/10.1007/978-3-658-11823-5_7},
	abstract = {Aufbauend auf dem vorhergehenden Kapitel und den Ergebnissen der dort vorgestellten QCA stellt dieses Kapitel die systematischen Process-Tracing-Studien der Kollapsfälle dar. Während durch die QCA die Existenz verschiedener Bedingungen bestätigt oder verworfen wurde, förderte das Process-Tracing die kausal bedeutsamen Bedingungen zu Tage und half zwischen Ursachen und Begleiterscheinungen zu unterscheiden. Das Resultat ist ein kausales Modell um sechs zentrale Risikofaktoren für Staatskollaps, welches hier vorgestellt wird.},
	language = {de},
	urldate = {2021-05-27},
	booktitle = {Warum {Staaten} zusammenbrechen: {Eine} vergleichende {Untersuchung} der {Ursachen} von {Staatskollaps}},
	publisher = {Springer Fachmedien},
	author = {Lambach, Daniel and Johais, Eva and Bayer, Markus},
	editor = {Lambach, Daniel and Johais, Eva and Bayer, Markus},
	year = {2016},
	doi = {10.1007/978-3-658-11823-5_7},
	keywords = {kausale Mechanismen, kausales Modell, Process-Tracing, Prozessanalyse, Staatskollaps},
	pages = {135--156},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/4BQQEW6M/Lambach et al. - 2016 - Process-Tracing und das Kausalmodell von Staatskol.pdf:application/pdf},
}

@article{robins_tutorial_nodate,
	title = {A tutorial on methods for the modeling and analysis of social network data},
	shorttitle = {Robins – {A} tutorial on methods},
	url = {http://www.sciencedirect.com/science/article/pii/S0022249613000126 http://ac.els-cdn.com/S0022249613000126/1-s2.0-S0022249613000126-main.pdf?_tid=2b12a568-1b92-11e7-a50f-00000aacb360&acdnat=1491570206_9b007094826b499c715064e0944e68ed},
	doi = {10.1016/j.jmp.2013.02.001},
	abstract = {Abstract This article provides a tutorial review of some fundamental ideas and important methods for the modeling of empirical social network data. It describes basic concepts from graph theory and central elements from social network theory. It presents models for the network degree distribution and for network roles and positions, as well as algebraic approaches, before reviewing recent work on statistical methods to analyze social networks, including boot-strap procedures for testing the prevalence of network structures, basic edge- and dyad-independent statistical models, and more recent statistical network models that assume dependence, exponential random graph models and dynamic stochastic actor oriented models. Network social influence models are reviewed. The article concludes with a summary of new developments relating to models for time-ordered transactions.},
	language = {en},
	number = {0},
	journal = {Journal of Mathematical Psychology},
	author = {Robins, Garry},
	file = {Attachment:/Users/isabelleborucki/Zotero/storage/J6J6HAFA/Robins - Unknown - A tutorial on methods for the modeling and analysis of social network data.pdf:application/pdf},
}

@book{kolaczyk_statistical_nodate,
	title = {Statistical {Analysis} of {Network} {Data}},
	isbn = {978-0-387-88145-4},
	abstract = {{\textless}p{\textgreater}{\textless}/p{\textgreater} {\textless}p{\textgreater}In the past decade, the study of networks has increased dramatically. Researchers from across the sciences—including biology and bioinformatics, computer science, economics, engineering, mathematics, physics, sociology, and statistics—are more and more involved with the collection and statistical analysis of network-indexed data. As a result, statistical methods and models are being developed in this area at a furious pace, with contributions coming from a wide spectrum of disciplines.{\textless}/p{\textgreater} {\textless}p{\textgreater}This book provides an up-to-date treatment of the foundations common to the statistical analysis of network data across the disciplines. The material is organized according to a statistical taxonomy, although the presentation entails a conscious balance of concepts versus mathematics. In addition, the examples—including extended cases studies—are drawn widely from the literature. This book should be of substantial interest both to statisticians and to anyone else working in the area of ‘network science.'{\textless}/p{\textgreater} {\textless}p{\textgreater}The coverage of topics in this book is broad, but unfolds in a systematic manner, moving from descriptive (or exploratory) methods, to sampling, to modeling and inference. Specific topics include network mapping, characterization of network structure, network sampling, and the modeling, inference, and prediction of networks, network processes, and network flows. This book is the first such resource to present material on all of these core topics in one place. {\textless}/p{\textgreater} {\textless}p{\textgreater}Eric Kolaczyk is a professor of statistics, and Director of the Program in Statistics, in the Department of Mathematics and Statistics at Boston University, where he also is an affiliated faculty member in the Center for Biodynamics, the Program in Bioinformatics, and the Division of Systems Engineering. His publications on network-based topics include work ranging from the detection of anomalous traffic patterns in computer networks to the prediction of biological function in networks of interacting proteins to the characterization of influence of groups of actors in social networks.{\textless}/p{\textgreater} {\textless}p{\textgreater}{\textless}/p{\textgreater}{\textless}br /{\textgreater}},
	author = {Kolaczyk, Eric D},
	doi = {10.1007/978-0-387-88146-1},
}

@book{atteslander_methoden_2010,
	address = {Berlin},
	edition = {13., neu bearbeitete und erweiterte Auflage},
	series = {{ESV} basics},
	title = {Methoden der empirischen {Sozialforschung}},
	isbn = {978-3-503-12618-7},
	language = {ger},
	publisher = {Erich Schmidt Verlag},
	author = {Atteslander, Peter and Cromm, Jürgen and Grabow, Busso and Klein, Harald and Maurer, Andrea and Siegert, Gabriele},
	year = {2010},
	annote = {Grundlagenwerk zur Einführung in die Methoden der empirischen Sozialforschung Der Atteslander gilt seit Jahrzehnten als Standardlehrbuch zur empirischen Sozialforschung und genießt auch international höchste Anerkennung. Weit über die Soziologie hinaus ist das Buch eine unentbehrliche und verlässliche Lern- und Arbeitshilfe für alle, die soziale Tatbestände systematisch erfassen und interpretieren. Das bewährte Werk bietet eine umfassende und verständliche Einführung in die komplexe Materie. Mit vielen Beispielen und Grafiken erleichtert der Atteslander insb. Anfangssemestern aller sozialwissenschaftlichen Fächer den Einstieg in die empirische Sozialforschung. Von Dozenten kann er hervorragend mit eigenen Fallbeispielen kombiniert werden. Didaktisch aufbereitete Fragen zur Wissenskontrolle leiten zu eigenen Übungen in der Anwendung von Forschungsinstrumenten an. Abschließende Überlegungen zur sachgerechten Interpretation von gesicherten Befunden helfen dabei, sich innerhalb der Vielzahl von Ideologien, Theorien und Methoden zurechtzufinden. Diese 13. Auflage ist neu bearbeitet und erweitert. Die zusätzlichen Orientierungshilfen für das Fachgebiet bieten in der Neuauflage eine ausführliche und aktuelle Darstellung der Diskussion qualitative vs. quantitative Forschungsmethoden},
	annote = {Literaturangaben Literaturverzeichnis: Seite 361-380},
	file = {Table of Contents PDF:/Users/isabelleborucki/Zotero/storage/2MLQ8IFI/Atteslander et al. - 2010 - Methoden der empirischen Sozialforschung.pdf:application/pdf},
}

@book{diekmann_empirische_2010,
	address = {Reinbek bei Hamburg},
	edition = {Orig.-Ausg},
	title = {Empirische {Sozialforschung}: {Grundlagen}, {Methoden}, {Anwendungen}},
	isbn = {978-3-499-55678-4},
	shorttitle = {Diekmann 2010 – {Empirische} {Sozialforschung}},
	language = {ger},
	number = {55678},
	publisher = {Rowohlt-Taschenbuch-Verl},
	author = {Diekmann, Andreas},
	year = {2010},
	note = {Publication Title: Rowohlts Enzyklopädie},
	keywords = {Theorie, Sozialforschung, Empirische Methode},
}

@book{egner_methoden_2019,
	address = {München},
	series = {{UTB} {Politikwissenschaft}},
	title = {Methoden der {Politikwissenschaft}: eine anwendungsbezogene {Einführung}},
	isbn = {978-3-8252-5235-9},
	shorttitle = {Methoden der {Politikwissenschaft}},
	language = {ger},
	number = {5235},
	publisher = {UVK Verlag},
	author = {Egner, Björn},
	collaborator = {Lehning, Melina},
	year = {2019},
	annote = {Literaturverzeichnis: Seite 202-213},
	file = {Table of Contents PDF:/Users/isabelleborucki/Zotero/storage/IANM25KB/Egner - 2019 - Methoden der Politikwissenschaft eine anwendungsb.pdf:application/pdf},
}

@book{hader_empirische_2019,
	address = {Wiesbaden [Heidelberg]},
	edition = {4. Auflage},
	series = {Lehrbuch},
	title = {Empirische {Sozialforschung}: eine {Einführung}},
	isbn = {978-3-658-26985-2},
	shorttitle = {Empirische {Sozialforschung}},
	abstract = {Sozialwissenschaftliche Methoden wie Befragungen, Beobachtungen und Inhaltsanalysen kommen in der Marktforschung, bei Studien zur Zeitgeschichte, in der Stadtplanung und in der Kommunikationsforschung zum Einsatz. Erst recht werden sie von Soziologen und empirisch arbeitenden Politikwissenschaftlern benötigt. Egal, ob im Rahmen der Evaluation eines Präventionsprogramms oder für die Erhebung des Gesundheitsverhaltens oder für eine Studie zur sozialen Mobilität, die sichere Handhabung des sozialwissenschaftlichen Instrumentariums ist stets die Voraussetzung, um belastbare Ergebnisse zu erzielen. Das Buch stellt wichtige Informationen für die Anwender und Entwickler dieser Instrumente zur Verfügung. Es behandelt die theoretischen Grundlagen der Methoden, die Schritte bei der Konzipierung und Umsetzung eines Projekts, die vielfältigen Varianten der Datenerhebung, die bei der Auswahl der Untersuchungseinheiten einzusetzenden Methoden ebenso wie die Prinzipien, die bei der Auswertung und Dokumentation der Befunde zu beachten sind. Mithilfe zahlreicher Beispiele gelingt eine besonders anschauliche Darstellung. In der vierten, aktualisierten Auflage hat im Rahmen der Auswahlverfahren nun auch das River Sampling Eingang gefunden, werden verstärkt auch digitale Methoden vorgestellt sowie vor dem Hintergrund der neuen Datenschutzverordnung auch die Forschungsethik und der Datenschutz aktualisiert},
	language = {ger},
	publisher = {Springer VS},
	author = {Häder, Michael},
	year = {2019},
	annote = {Die Bedeutung des Methodenwissens für das Verständnis empirischer Daten -- Wissenschaftstheorie -- Forschungs- und Untersuchungsplanung -- Auswahlverfahren -- Erhebungsmethoden -- Komplexe Designs -- Pretests -- Aufbereitung und Auswertung der Daten -- Dokumentation},
	annote = {Literaturverzeichnis: Seite 487-516, Register},
	file = {Häder - 2019 - Empirische Sozialforschung eine Einführung.pdf:/Users/isabelleborucki/Zotero/storage/FQ6FQXGJ/Häder - 2019 - Empirische Sozialforschung eine Einführung.pdf:application/pdf},
}

@book{diaz-bone_statistik_2013,
	address = {Konstanz},
	edition = {2., überarb. Aufl},
	series = {{UTB} {Basics}},
	title = {Statistik für {Soziologen}},
	isbn = {978-3-8252-4034-9},
	language = {ger},
	number = {2782},
	publisher = {UVK-Verl.-Ges [u.a.]},
	author = {Diaz-Bone, Rainer},
	year = {2013},
	annote = {Literaturangaben},
	file = {Table of Contents PDF:/Users/isabelleborucki/Zotero/storage/SESDWPTW/Diaz-Bone - 2013 - Statistik für Soziologen.pdf:application/pdf},
}

@book{bernauer_einfuhrung_2018,
	title = {Einführung in die {Politikwissenschaft}},
	isbn = {978-3-8487-4872-3},
	publisher = {Nomos Verlagsgesellschaft mbH \& Co. KG},
	author = {Bernauer, Thomas and {Jahn, Detlef} and {Kuhn, Patrick M} and {Walter, Stefanie}},
	year = {2018},
	doi = {10.5771/9783845289724},
	file = {Einführung in die Politikwissenschaft eBook (2018) / 978-3-8487-4872-3 - Volume (2018) - Issue | Nomos eLibrary:/Users/isabelleborucki/Zotero/storage/K6T22CEF/einfuehrung-in-die-politikwissenschaft.html:text/html},
}

@book{field_adventure_2022,
	address = {Thousand Oaks},
	edition = {Second edition},
	title = {An adventure in statistics: the reality enigma},
	isbn = {978-1-5297-9713-8 978-1-5297-9714-5},
	shorttitle = {An adventure in statistics},
	abstract = {"Join Zach Slade on a bizarre journey that will transform your understanding of statistics forever Will Zach find Alice, the missing love of his life, and save the world? Will he survive the Bridge of Death? Can he escape the zombie horde? Statistically speaking the odds don't look good... In the new second edition of this stunningly illustrated textbook, follow Zach as he encounters unusual characters and solves puzzling enigmas in his quest to find Alice and learn everything you need to know about statistics along the way - from models and probability, to hypothesis testing and factorial designs. With its unique combination of story, concepts and terminology, this complete introduction to statistics from bestselling author Andy Field breaks the mold to present a statistical tale like no other"--},
	publisher = {SAGE Publications},
	author = {Field, Andy},
	year = {2022},
}

@book{schnell_methoden_2018,
	title = {Methoden der empirischen {Sozialforschung}},
	isbn = {978-3-11-057732-7},
	url = {https://www.degruyter.com/document/isbn/9783110577327/html?lang=de},
	abstract = {Dieser Bestseller mit über 70.000 verkauften Exemplaren holt den Studierenden am Studienbeginn ab und führt ihn erfolgreich in die empirische Sozialforschung ein. Dabei schafft das Lehrbuch vielfältig den methodischen Brückenschlag von empirischer Sozialforschung und soziologischer Theorie. Es stellt Verfahren und Sachverhalte nicht nur vor, sondern erklärt sie verständlich. Die kritische Darstellung auch der neueren Entwicklungen der Methoden der empirischen Sozialforschung und ihrer Grundlagen weist über andere Lehrbücher hinaus. Auch daher ist dieses Lehrbuch das am häufigsten zitierte Lehrbuch zum Thema in deutscher Sprache. Für die 11. Auflage wurde der Band u.a. um Abschnitte über Big Data in den Sozialwissenschaften, zu adaptiven Designs bei Befragungen und zum Web-Scraping erweitert.},
	language = {de},
	urldate = {2022-12-21},
	publisher = {De Gruyter Oldenbourg},
	author = {Schnell, Rainer and Hill, Paul B. and Esser, Elke},
	month = aug,
	year = {2018},
	note = {Publication Title: Methoden der empirischen Sozialforschung},
}

@book{mau_metrische_2017,
	address = {Berlin},
	edition = {Erste Auflage, Originalausgabe},
	title = {Das metrische {Wir}: über die {Quantifizierung} des {Sozialen}},
	isbn = {978-3-518-07292-9},
	shorttitle = {Das metrische {Wir}},
	publisher = {Suhrkamp},
	author = {Mau, Steffen},
	year = {2017},
	note = {OCLC: on1005664181},
	keywords = {Information technology, Big data, Data mining, Social aspects},
	annote = {"Ob Bildung, Gesundheit oder Konsum: Über so ziemlich jeden Aspekt unserer Person und unseres Verhaltens werden inzwischen Daten gesammelt. Schritt für Schritt entsteht so eine Gesellschaft der Sternchen, Scores, Likes und Listen, in der alles und jeder ständig vermessen und bewertet wird. Das beginnt beim alljährlichen Hochschulranking, reicht über die Quantified-Self-Bewegung fitnessbegeisterter Grossstädter, die über das Internet ihre Bestzeiten miteinander vergleichen, bis hin zur Beurteilung der Effizienz politischer Massnahmen. Steffen Mau untersucht die Techniken dieser neuen Soziometrie und zeigt ihre Folgen auf. Die Bewertungssysteme der quantifizierten Gesellschaft, so sein zentraler Gedanke, bilden nicht einfach die Ungleichheiten in der Welt ab, sondern sind letztlich mitentscheidend bei der Verteilung von Lebenschancen." -- cover "Whether it is education, health or consumption, data is now gathered about just about every aspect of our person and behavior. This creates a society of asterisks, scores, likes and lists, in which everything and everyone is constantly measured and evaluated. This starts at the annual university campus, reaches over the quantified self-movement of fitness-minded metropolises, which compare their best times over the Internet, to the assessment of the efficiency of political measures. Steffen Mau examines the techniques of this new sociometry and shows its consequences. The evaluation systems of the quantified society, according to his central thought, do not simply represent the inequalities in the world, but are ultimately decisive in the distribution of life chances." -- rough translation of the cover},
}

@book{criado-perez_unsichtbare_2020,
	title = {Unsichtbare {Frauen}: {Wie} eine von {Daten} beherrschte {Welt} die {Hälfte} der {Bevölkerung} ignoriert},
	isbn = {978-3-641-22377-9},
	shorttitle = {Unsichtbare {Frauen}},
	abstract = {Ein kraftvolles und provokantes Plädoyer für Veränderung!Unsere Welt ist von Männern für Männer gemacht und tendiert dazu, die Hälfte der Bevölkerung zu ignorieren. Caroline Criado-Perez erklärt, wie dieses System funktioniert. Sie legt die geschlechtsspezifischen Unterschiede bei der Erhebung wissenschaftlicher Daten offen. Die so entstandene Wissenslücke liegt der kontinuierlichen und systematischen Diskriminierung von Frauen zugrunde und erzeugt eine unsichtbare Verzerrung, die sich stark auf das Leben von Frauen auswirkt. Kraftvoll und provokant plädiert Criado-Perez für einen Wandel dieses Systems und lässt uns die Welt mit neuen Augen sehen.},
	language = {de},
	publisher = {btb Verlag},
	author = {Criado-Perez, Caroline},
	month = feb,
	year = {2020},
	note = {Google-Books-ID: HiqPDwAAQBAJ},
	keywords = {Political Science / General, Social Science / General},
}

@book{harford_data_2022,
	title = {The {Data} {Detective}: {Ten} {Easy} {Rules} to {Make} {Sense} of {Statistics}},
	isbn = {978-0-593-08466-3},
	shorttitle = {The {Data} {Detective}},
	abstract = {From “one of the great (greatest?) contemporary popular writers on economics” (Tyler Cowen) comes a smart, lively, and encouraging rethinking of how to use statistics. Today we think statistics are the enemy, numbers used to mislead and confuse us. That’s a mistake, Tim Harford says in The Data Detective. We shouldn’t be suspicious of statistics—we need to understand what they mean and how they can improve our lives: they are, at heart, human behavior seen through the prism of numbers and are often “the only way of grasping much of what is going on around us.” If we can toss aside our fears and learn to approach them clearly—understanding how our own preconceptions lead us astray—statistics can point to ways we can live better and work smarter. As “perhaps the best popular economics writer in the world” (New Statesman), Tim Harford is an expert at taking complicated ideas and untangling them for millions of readers. In The Data Detective, he uses new research in science and psychology to set out ten strategies for using statistics to erase our biases and replace them with new ideas that use virtues like patience, curiosity, and good sense to better understand ourselves and the world. As a result, The Data Detective is a big-idea book about statistics and human behavior that is fresh, unexpected, and insightful.},
	language = {en},
	publisher = {Penguin Publishing Group},
	author = {Harford, Tim},
	month = feb,
	year = {2022},
	note = {Google-Books-ID: SKVPEAAAQBAJ},
	keywords = {Psychology / Social Psychology, Business \& Economics / Consumer Behavior, Business \& Economics / Statistics},
}

@book{blatte_computational_2018,
	address = {Baden-Baden},
	edition = {1. Auflage},
	series = {Schriftenreihe der {Sektion} {Methoden} der {Politikwissenschaft} der {Deutschen} {Vereinigung} für {Politikwissenschaft}},
	title = {Computational {Social} {Science}: die {Analyse} von {Big} {Data}},
	isbn = {978-3-8487-4393-3 978-3-8452-8655-6},
	shorttitle = {Computational {Social} {Science}},
	language = {ger},
	publisher = {Nomos},
	editor = {Blätte, Andreas and Behnke, Joachim and Schnapp, Kai-Uwe and Wagemann, Claudius},
	year = {2018},
	doi = {10.5771/9783845286556},
	note = {OCLC: 1013470838},
	keywords = {Big Data, Datenanalyse, Massendaten, Politikwissenschaft, Politische Wissenschaft, Statistische Methode},
	annote = {Blätte, Andreas (HerausgeberIn) Behnke, Joachim (HerausgeberIn) Schnapp, Kai-Uwe (HerausgeberIn) Wagemann, Claudius (HerausgeberIn)},
	annote = {Blätte, Andreas (HerausgeberIn) Behnke, Joachim (HerausgeberIn) Schnapp, Kai-Uwe (HerausgeberIn) Wagemann, Claudius (HerausgeberIn)},
	annote = {Enthält 16 Beiträge Literaturangaben},
	file = {9783845286556.pdf:/Users/isabelleborucki/Zotero/storage/7Z4QGZKU/9783845286556.pdf:application/pdf;Computational Social Science - Volume (2018) - Issue | Nomos eLibrary:/Users/isabelleborucki/Zotero/storage/7XA6GFEV/computational-social-science.html:text/html;Table of Contents PDF:/Users/isabelleborucki/Zotero/storage/XWHXAJTI/Blätte et al. - 2018 - Computational Social Science die Analyse von Big .pdf:application/pdf},
}

@incollection{blatter_forschungsmethoden_2007,
	address = {Wiesbaden},
	title = {Forschungsmethoden und politikwissenschaftliche {Anwendungen}},
	isbn = {978-3-531-90716-1},
	url = {https://doi.org/10.1007/978-3-531-90716-1_4},
	abstract = {Nach der Übersicht über die Vorgehensweisen qualitativer Forschung in Kapitel 1 und dem Rückbezug auf die maßgeblichen Forschungstraditionen und theoreti-schen Grundlagen in Kapitel 2 sollen nun wichtige Methoden der Datenerhebung und Datenanalyse behandelt werden. Mit den Methoden der Datenerhebung sind jene Verfahren gemeint, die gewährleisten, dass eine auf diese erhobenen Daten bezogene Analyse vorgenommen werden kann. Mit anderen Worten ist eine Datenerhebung oder Datensammlung immer dann notwendig, wenn eine anvisierte Datenanalyse gar nicht auf schon vorhandene Daten — in Form von Statistiken, Protokollen, Dokumenten, Interviewtexten — zurückgreifen kann: „Datensammlung ist immer dann notwendig, wenn das zur Auswertung benötigte Datenmaterial noch nicht in dieser Form in der Wirklichkeit vorhanden ist, sondern mittels Techniken der Protokollierung im weitesten Sinne verfügbar gemacht werden muss. Der Prozess der Datenerhebung besteht daher in einer Art von Umformung einer bestimmten Sorte von Rohmaterial in die eigentlichen Daten, die in dieser umgewandelten Form in der Wissenschaft Verwendung finden können.“ (Behnke/Baur/Behnke 2006: 201)},
	language = {de},
	urldate = {2021-03-23},
	booktitle = {Qualitative {Politikanalyse}: {Eine} {Einführung} in {Forschungsansätze} und {Methoden}},
	publisher = {VS Verlag für Sozialwissenschaften},
	editor = {Blatter, Joachim K. and Janning, Frank and Wagemann, Claudius},
	year = {2007},
	doi = {10.1007/978-3-531-90716-1_4},
	pages = {59--121},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/LD9DR4HU/Blatter et al. - 2007 - Forschungsmethoden und politikwissenschaftliche An.pdf:application/pdf},
}

@book{behnke_kausalprozesse_2007,
	title = {Kausalprozesse und {Identität}. Über den {Sinn} von {Signifikanztests} und {Konfidenzintervallen} bei {Vollerhebungen}},
	volume = {2},
	shorttitle = {Kausalprozesse und {Identität}. Über den {Sinn} von {Si}},
	number = {3},
	publisher = {Arbeitskreis der DVPW "Empirische Methoden der Politikwissenschaft"},
	author = {Behnke, Joachim},
	year = {2007},
	note = {Publication Title: Beiträge zu empirischen Methoden der Politikwissenschaft; Teilgebiet Statistik/ Wissenschaftstheorie},
}

@book{salganik_bit_2019,
	title = {Bit by {Bit}},
	isbn = {978-0-691-19610-7},
	url = {https://press.princeton.edu/books/paperback/9780691196107/bit-by-bit},
	abstract = {An innovative and accessible guide to doing social research in the digital age},
	language = {en},
	urldate = {2022-12-01},
	publisher = {Princeton University Press},
	author = {Salganik, Mathew},
	month = aug,
	year = {2019},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/XEBTIGNW/bit-by-bit.html:text/html},
}

@incollection{rogers_digital_2015,
	address = {Hoboken, NJ},
	title = {Digital {Methods} for {Web} {Research}},
	isbn = {978-1-118-90077-2},
	shorttitle = {Rogers 2015 – {Digital} {Methods} for {Web} {Research}},
	booktitle = {Emerging trends in the social and behavioral sciences},
	publisher = {Wiley},
	author = {Rogers, Richard},
	editor = {Scott, Robert and Kosslyn, Stephan},
	year = {2015},
	pages = {1--22},
}

@incollection{borucki_methoden_2022,
	address = {Wiesbaden},
	title = {Methoden in der {Regierungsforschung}},
	copyright = {All rights reserved},
	isbn = {978-3-658-30071-5},
	url = {https://doi.org/10.1007/978-3-658-30071-5_3},
	abstract = {Kaum ein Bereich oder Thema ist so umstritten in der Politikwissenschaft und den Sozialwissenschaften wie der Methodenkanon. Dieser Beitrag widmet sich schlaglichtartig den verschiedenen Debatten rund um methodische Ansätze, mit einem Schwerpunkt auf dem Themenfeld der Regierungsforschung. Hierbei wird mittels verschiedener Dimensionierungen einerseits ein Zugang zu den verschiedenen Grundlagen unserer modernen Methoden geleistet und andererseits ein Überblick über in der Regierungsforschung gängige Methoden geliefert.},
	language = {de},
	urldate = {2022-10-08},
	booktitle = {Handbuch {Regierungsforschung}},
	publisher = {Springer Fachmedien},
	author = {Borucki, Isabelle},
	editor = {Korte, Karl-Rudolf and Florack, Martin},
	year = {2022},
	doi = {10.1007/978-3-658-30071-5_3},
	keywords = {Methoden, Methodologie, Wissenschaftstheorie, Mixed Methods, Triangulation},
	pages = {37--53},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/JJYBAIEM/Borucki - 2022 - Methoden in der Regierungsforschung.pdf:application/pdf},
}

@incollection{borucki_objectivity_2020,
	address = {2455 Teller Road, Thousand Oaks, California 91320},
	title = {Objectivity},
	volume = {118},
	copyright = {All rights reserved},
	isbn = {978-1-4833-7553-3},
	url = {http://dx.doi.org/10.4135/9781483375519.n488},
	number = {471},
	booktitle = {The {SAGE} {International} {Encyclopedia} of {Mass} {Media} and {Society}},
	publisher = {SAGE Publications, Inc.},
	author = {Borucki, Isabelle R},
	editor = {Merskin, Debra},
	year = {2020},
	doi = {10.4135/9781483375519.n488},
	note = {ISSN: 00264423},
	pages = {739--769},
}

@article{borucki_visual_2017,
	title = {A {Visual} {Data} {Collection} {Method}: {German} {Local} {Parties} and {Associations}},
	copyright = {All rights reserved},
	issn = {02261766},
	url = {https://www.exeley.com/connections/pdf/10.21307/connections-2017-003},
	doi = {10.21307/connections-2017-003},
	abstract = {This research captures local networks of German political parties and welfare agencies in re-gards to poverty. The article explores whether there are differences in regards to homophily and brokerage between the two studied groups using a dataset of 33 egonetworks in two Ger-man cities. The computer assisted drawn networks were collected in an interactive-participative way together with the interviewed egonetworks. To achieve the theoretical aim of analysing homophily and brokerage between politicians and welfare workers, two hypothe-ses are examined, resting upon social capital theory. The hypotheses were quantified and ex-plicated with different variables. The first hypothesis states that heterophile networks imply more social capital, which referred to different measurements (size, density, homophily). This could be partially validated since the analysed networks of association representatives (N=12) were denser and slightly more heterophile than those of party representatives (N=21). Second, it was assumed that politicians, because of their function as elected representatives, would be more likely to take on an interface function within the communities than representatives of civil society institutions. Results based on calculated EI-indices, subgraphs and brokerage show that party representatives do indeed have larger networks, but these networks split into fewer subgraphs than association representatives' networks.},
	journal = {Connections},
	author = {Borucki, Isabelle},
	year = {2017},
}

@book{noauthor_quantitative_2022,
	title = {Quantitative {Social} {Science}},
	isbn = {978-0-691-22227-1},
	url = {https://press.princeton.edu/books/hardcover/9780691222271/quantitative-social-science},
	abstract = {A tidyverse edition of the acclaimed textbook on data analysis and statistics for the social sciences and allied fields},
	language = {en},
	urldate = {2022-12-21},
	month = aug,
	year = {2022},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/7GH3M2MX/quantitative-social-science.html:text/html},
}

@book{noauthor_quantitative_2018-1,
	title = {Quantitative {Social} {Science}},
	isbn = {978-0-691-16703-9},
	url = {https://press.princeton.edu/books/hardcover/9780691167039/quantitative-social-science},
	abstract = {An introductory textbook on data analysis and statistics written especially for students in the social sciences and allied fields},
	language = {en},
	urldate = {2022-12-21},
	month = feb,
	year = {2018},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/CHQY2DME/quantitative-social-science.html:text/html},
}

@book{stutzer_computational_2018,
	address = {Köln},
	series = {Neue {Schriften} zur {Online}-{Forschung}},
	title = {Computational social science in the age of big data: concepts, methodologies, tools, and applications},
	isbn = {978-3-86962-267-5 978-3-86962-268-2},
	shorttitle = {Computational social science in the age of big data},
	language = {eng},
	number = {15},
	publisher = {Herbert von Halem Verlag},
	editor = {Stützer, Cathleen and Welker, Martin and Egger, Marc},
	year = {2018},
	annote = {Literaturangaben},
	file = {Table of Contents PDF:/Users/isabelleborucki/Zotero/storage/SWLMTMHB/Stützer et al. - 2018 - Computational social science in the age of big dat.pdf:application/pdf},
}

@misc{saltzer_twitter_2021,
	title = {Twitter accounts of candidates in the {German} federal election {2021Twitter}-{Accounts} der {Kandidierenden} zur {Bundestagswahl} 2021},
	copyright = {Alle im GESIS DBK veröffentlichten Metadaten sind frei verfügbar unter den Creative Commons CC0 1.0 Universal Public Domain Dedication. GESIS bittet jedoch darum, dass Sie alle Metadatenquellen anerkennen und sie nennen, etwa die Datengeber oder jeglichen Aggregator, inklusive GESIS selbst. Für weitere Informationen siehe https://dbk.gesis.org/dbksearch/guidelines.asp?db=d, All metadata from GESIS DBK are available free of restriction under the Creative Commons CC0 1.0 Universal Public Domain Dedication. However, GESIS requests that you actively acknowledge and give attribution to all metadata sources, such as the data providers and any data aggregators, including GESIS. For further information see https://dbk.gesis.org/dbksearch/guidelines.asp},
	url = {https://search.gesis.org/research_data/ZA7721?doi=10.4232/1.13789},
	language = {en},
	urldate = {2023-01-09},
	publisher = {GESIS Data Archive},
	author = {Sältzer, Marius and Stier, Sebastian and Bäuerle, Joscha and Blumenberg, Manuela and Mechkova, Valeriya and Pemstein, Daniel and Seim, Brigitte and Wilson, Steven},
	year = {2021},
	doi = {10.4232/1.13789},
	note = {Version Number: 1.0.0
Type: dataset},
}

@misc{noauthor_computational_nodate,
	title = {Computational {Social} {Science} {Methodology}, {Anyone}? {\textbar} {Methodology}},
	url = {https://econtent.hogrefe.com/doi/10.1027/1614-2241/a000127},
	urldate = {2023-01-09},
	file = {Computational Social Science Methodology, Anyone? | Methodology:/Users/isabelleborucki/Zotero/storage/KQZ8EFXX/a000127.html:text/html},
}

@misc{noauthor_collecting_nodate,
	title = {Collecting vertical trace data: {Big} possibilities and big challenges for multi‐method research - {Menchen}‐{Trevino} - 2013 - {Policy} \&amp; {Internet} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/1944-2866.POI336},
	urldate = {2023-01-09},
	file = {Collecting vertical trace data\: Big possibilities and big challenges for multi‐method research - Menchen‐Trevino - 2013 - Policy &amp\; Internet - Wiley Online Library:/Users/isabelleborucki/Zotero/storage/DZSEAPKK/1944-2866.html:text/html},
}

@misc{noauthor_validity_nodate,
	title = {"{Validity} {Issues} in the {Use} of {Social} {Network} {Analysis} with {Digital} {Tra}" by {James} {Howison}, {Andrea} {Wiggins} et al.},
	url = {https://aisel.aisnet.org/jais/vol12/iss12/2/},
	urldate = {2023-01-09},
	file = {Untitled Document:/Users/isabelleborucki/Zotero/storage/GM5JLRG3/2.html:text/html},
}

@article{saltzer_bundestagswahl_2022,
	title = {Die {Bundestagswahl} 2021 auf {Twitter}},
	issn = {2199-9082},
	doi = {https://doi.org/10.15464/easy.2022.05},
	abstract = {Soziale Medien nehmen gerade unter Corona-Bedingungen eine größere Rolle im Wahlkampf ein. Verbunden mit dem innerparteilichen Kampf um die Spitzenkandidaturen, der Zersplitterung des Parteiensystems und einer personalisierten Kanzlerwahl befördert das individualisierte Medium Twitter die Personalisierung des politischen Wettbewerbs. Für eine Analyse der Bundestagswahl stellt sich die Frage, ob es mit Twitterdaten auch möglich ist, Rückschlüsse auf die individuellen politischen Positionen von Bundestagskandidierenden zu ziehen. Anhand der politischen Kommunikation einiger prominenter Spitzenpolitiker:innen werden die zentralen Dimensionen des politischen Raums auf Twitter sichtbar, insbesondere die Neuausrichtung der traditionellen Links-Rechts Dimension.Social media have become increasingly important during election campaigns, especially under corona conditions. Combined with the inner-party struggles, the fragmentation of the party system and personalized campaigns including a strong focus on chancellor candidates, the individualized medium of Twitter promotes the personalization of political competition. For an analysis of the Bundestag elections, the question arises as to whether it is also possible to draw conclusions about the individual political positions of Bundestag candidates using Twitter data. Based on the politial communication of top politicians, the central dimensions of the political space become visible on Twitter, in particular the realignment of the traditional left-right dimension.},
	language = {de},
	number = {67},
	journal = {easy\_social\_sciences},
	author = {Sältzer, Marius and Stier, Sebastian},
	year = {2022},
	keywords = {social media, Twitter, Soziale Medien, Wahlkampf, Personalisierung, twitter, Bundesrepublik Deutschland, Bundestagswahl, election to the Bundestag, Federal Republic of Germany, Textanalyse, text analysis, election campaign, political attitude, politische Einstellung, politician, personalization, Politiker},
	pages = {30--38},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/FYC7LTRG/79902.html:text/html},
}

@article{munzert_whos_nodate,
	title = {Who’s {Cheating} on {Your} {Survey}? {A} {Detection} {Approach} with {Digital} {Trace} {Data}},
	abstract = {In this note, we provide direct evidence of cheating in online assessments of political knowledge. We combine survey responses with web tracking data of a German and a U.S. online panel to assess whether people turn to external sources for answers. We observe item-level prevalence rates of cheating that range from 0 to 12\% depending on question type and difficulty, and find that 23\% of respondents engage in cheating at least once across waves. In the U.S. panel, which employed a commitment pledge, we observe cheating behavior among less than 1\% of respondents. We find robust respondent- and item-level characteristics associated with cheating. However, itemlevel instances of cheating are rare events; as such, they are difficult to predict and correct for without tracking data. Even so, our analyses comparing naive and cheating-corrected measures of political knowledge provide evidence that cheating does not substantially distort inferences.},
	language = {en},
	author = {Munzert, Simon and Ramirez‑Ruiz, Sebastian and Barberá, Pablo and Guess, Andrew M and Yang, JungHwan},
	file = {Munzert et al. - Who’s Cheating on Your Survey A Detection Approac.pdf:/Users/isabelleborucki/Zotero/storage/9NCW6Z3I/Munzert et al. - Who’s Cheating on Your Survey A Detection Approac.pdf:application/pdf},
}

@misc{noauthor_network_nodate,
	title = {Network {Psychometrics} with {R}: {A} {Guide} for {Behavioral} and {Social} {Scient}},
	url = {https://www.routledge.com/Network-Psychometrics-with-R-A-Guide-for-Behavioral-and-Social-Scientists/Isvoranu-Epskamp-Waldorp-Borsboom/p/book/9780367612948},
	urldate = {2023-01-11},
	file = {Network Psychometrics with R\: A Guide for Behavioral and Social Scient:/Users/isabelleborucki/Zotero/storage/M5MSV7YG/9780367612948.html:text/html},
}

@article{borsboom_possible_2022,
	title = {Possible {Futures} for {Network} {Psychometrics}},
	volume = {87},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/s11336-022-09851-z},
	doi = {10.1007/s11336-022-09851-z},
	abstract = {This commentary reflects on the articles included in the Psychometrika Special Issue on Network Psychometrics in Action. The contributions to the special issue are related to several possible future paths for research in this area. These include the development of models to analyze and represent interventions, improvement in exploratory and inferential techniques in network psychometrics, the articulation of psychometric theories in addition to psychometric models, and extensions of network modeling to novel data sources. Finally, network psychometrics is part of a larger movement in psychology that revolves around the analysis of human beings as complex systems, and it is timely that psychometricians start extending their rich modeling tradition to improve and extend the analysis of systems in psychology.},
	language = {en},
	number = {1},
	urldate = {2023-01-11},
	journal = {Psychometrika},
	author = {Borsboom, Denny},
	month = mar,
	year = {2022},
	keywords = {Network analysis, Complex systems, Causal models, Exploratory data analysis, Time series},
	pages = {253--265},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/XGWB7XNL/Borsboom - 2022 - Possible Futures for Network Psychometrics.pdf:application/pdf},
}

@article{epskamp_psychometric_2020,
	title = {Psychometric network models from time-series and panel data},
	volume = {85},
	issn = {1860-0980},
	doi = {10.1007/s11336-020-09697-3},
	abstract = {Researchers in the field of network psychometrics often focus on the estimation of Gaussian graphical models (GGMs)-an undirected network model of partial correlations-between observed variables of cross-sectional data or single-subject time-series data. This assumes that all variables are measured without measurement error, which may be implausible. In addition, cross-sectional data cannot distinguish between within-subject and between-subject effects. This paper provides a general framework that extends GGM modeling with latent variables, including relationships over time. These relationships can be estimated from time-series data or panel data featuring at least three waves of measurement. The model takes the form of a graphical vector-autoregression model between latent variables and is termed the ts-lvgvar when estimated from time-series data and the panel-lvgvar when estimated from panel data. These methods have been implemented in the software package psychonetrics, which is exemplified in two empirical examples, one using time-series data and one using panel data, and evaluated in two large-scale simulation studies. The paper concludes with a discussion on ergodicity and generalizability. Although within-subject effects may in principle be separated from between-subject effects, the interpretation of these results rests on the intensity and the time interval of measurement and on the plausibility of the assumption of stationarity.},
	language = {eng},
	number = {1},
	journal = {Psychometrika},
	author = {Epskamp, Sacha},
	month = mar,
	year = {2020},
	pmid = {32162233},
	pmcid = {PMC7186258},
	keywords = {panel data, structural equation modeling, dynamics, Humans, Time, Computer Simulation, Cross-Sectional Studies, Depression, Ecological Momentary Assessment, Gaussian graphical model, Interrupted Time Series Analysis, Male, Metabolic Networks and Pathways, Middle Aged, Models, Statistical, network psychometrics, Normal Distribution, Psychometrics, time-series data},
	pages = {206--231},
	file = {Full Text:/Users/isabelleborucki/Zotero/storage/3EHS9EPI/Epskamp - 2020 - Psychometric network models from time-series and p.pdf:application/pdf},
}

@misc{noauthor_full_nodate,
	title = {Full article: {Comparing} {Chatbots} and {Online} {Surveys} for ({Longitudinal}) {Data} {Collection}: {An} {Investigation} of {Response} {Characteristics}, {Data} {Quality}, and {User} {Evaluation}},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2022.2156489},
	urldate = {2023-01-18},
	file = {Full article\: Comparing Chatbots and Online Surveys for (Longitudinal) Data Collection\: An Investigation of Response Characteristics, Data Quality, and User Evaluation:/Users/isabelleborucki/Zotero/storage/I73KYCQF/19312458.2022.html:text/html},
}

@article{dodds_popularity-driven_2023,
	title = {Popularity-driven {Metrics}: {Audience} {Analytics} and {Shifting} {Opinion} {Power} to {Digital} {Platforms}},
	issn = {1461-670X, 1469-9699},
	shorttitle = {Popularity-driven {Metrics}},
	url = {https://www.tandfonline.com/doi/full/10.1080/1461670X.2023.2167104},
	doi = {10.1080/1461670X.2023.2167104},
	abstract = {As digital technologies have made their way into news production, allowing news organizations to measure audience behaviors and engagement in real-time, click-based and editorial goals have become increasingly intertwined. Ongoing developments in algorithmic technologies allow editors to bring their audience into the newsroom using specialized tools such as Chartbeat or Google Analytics. This article examines how these technologies have aﬀected the composition of the audience and their power to inﬂuence news-making processes inside two Chilean newsrooms. Drawing on several months of newsroom ethnography, we identify how the pursuit of “clickable news” impacts editorial processes and journalistic priorities by changing the dataﬁed audience opinion power behind news production. Shifts in opinion power, loss of control, and increased platform dependency may contribute to a concentrated media landscape. Our ﬁndings show that opinion power has shifted to a dataﬁed version of the audience, raising new questions about platform dependency and editorial autonomy in media organizations. These results carry signiﬁcant implications for understanding the chase for traﬃc in current multiplatform newsrooms and how this phenomenon impacts news production.},
	language = {en},
	urldate = {2023-01-18},
	journal = {Journalism Studies},
	author = {Dodds, Tomás and de Vreese, Claes and Helberger, Natali and Resendez, Valeria and Seipp, Theresa},
	month = jan,
	year = {2023},
	pages = {1--19},
	file = {Dodds et al. - 2023 - Popularity-driven Metrics Audience Analytics and .pdf:/Users/isabelleborucki/Zotero/storage/YYPDU2PD/Dodds et al. - 2023 - Popularity-driven Metrics Audience Analytics and .pdf:application/pdf},
}

@misc{noauthor_computational_nodate-1,
	title = {Computational {Social} {Science} {Methodology}, {Anyone}?},
	url = {https://econtent.hogrefe.com/doi/epdf/10.1027/1614-2241/a000127},
	language = {en},
	urldate = {2023-01-27},
	note = {ISSN: 1614-2241},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/35VYWWB7/a000127.html:text/html},
}

@article{university_of_texas_at_austin_validity_2011,
	title = {Validity {Issues} in the {Use} of {Social} {Network} {Analysis} with {Digital} {Trace} {Data}},
	volume = {12},
	issn = {15369323},
	url = {http://aisel.aisnet.org/jais/vol12/iss12/2/},
	doi = {10.17705/1jais.00282},
	abstract = {There is an exciting natural match between social network analysis methods and the growth of data sources produced by social interactions via information technologies, from online communities to corporate information systems. Information Systems researchers have not been slow to embrace this combination of method and data. Such systems increasingly provide “digital trace data” that provide new research opportunities. Yet digital trace data are substantively different from the survey and interview data for which network analysis measures and interpretations were originally developed. This paper examines 10 validity issues associated with the combination of digital trace data and social network analysis methods, with examples from the IS literature, to provide recommendations for improving the validity of future research.},
	language = {en},
	number = {12},
	urldate = {2023-01-27},
	journal = {Journal of the Association for Information Systems},
	author = {{University of Texas at Austin} and Howison, James and Wiggins, Andrea and {Syracuse University} and Crowston, Kevin and {Syracuse University}},
	month = dec,
	year = {2011},
	pages = {767--797},
	file = {University of Texas at Austin et al. - 2011 - Validity Issues in the Use of Social Network Analy.pdf:/Users/isabelleborucki/Zotero/storage/6PS44AHC/University of Texas at Austin et al. - 2011 - Validity Issues in the Use of Social Network Analy.pdf:application/pdf},
}

@article{barbaresi_reproducible_2021,
	title = {A {Reproducible} {IT}-{Blog} {Corpus}},
	volume = {7},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2059-481X},
	url = {http://openhumanitiesdata.metajnl.com/articles/10.5334/johd.35/},
	doi = {10.5334/johd.35},
	abstract = {The dataset comprises text and metadata extracted from several hundred IT-blogs and websites, along with a method to duplicate the data by updating its contents and downloading it to the user’s local machine. The targets have been hand-picked with the intention to represent the discourse on blogs and websites dedicated to questions at the intersection of technology and society from Germany and the United States of America. The texts have been retrieved by web crawling techniques. The resulting corpus is accessible through a search platform and also reproducible with freely accessible descriptors and software.},
	language = {en},
	number = {0},
	urldate = {2023-02-06},
	journal = {Journal of Open Humanities Data},
	author = {Barbaresi, Adrien and Pohlmann, Jens},
	month = jul,
	year = {2021},
	note = {Number: 0
Publisher: Ubiquity Press},
	keywords = {discourse analysis, corpus linguistics, freedom of expression, internet policy, public discussion, web blogs},
	pages = {17},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/VL2EP79F/Barbaresi and Pohlmann - 2021 - A Reproducible IT-Blog Corpus.pdf:application/pdf},
}

@incollection{siewert_many_2023,
	address = {Cham},
	series = {Texts in {Quantitative} {Political} {Analysis}},
	title = {The {Many} {Threats} from {Mechanistic} {Heterogeneity} {That} {Can} {Spoil} {Multimethod} {Research}},
	isbn = {978-3-031-12982-7},
	url = {https://doi.org/10.1007/978-3-031-12982-7_10},
	abstract = {The combination of cross-case and within-case analysis in Multi-Method Research (MMR) designs has gained considerable traction in the social sciences over the last decade. One reason for the popularity of MMR is grounded in the idea that different methods can complement each other, in the sense that the strengths of one method can compensate for the blind spots and weaknesses of another and vice versa. In this chapter, we critically address this core premise of MMR with an emphasis on the external validity of applying some cross-case method, like standard regression or Qualitative Comparative Analysis, in combination with case study analysis. After a brief overview of the rationale of MMR, we discuss in detail the problem of deriving generalizable claims about mechanisms in research contexts that likely exhibit mechanistic heterogeneity. In doing so, we clarify what we mean by mechanistic heterogeneity and where researchers should look for potential sources of mechanistic heterogeneity. Finally, we propose a strategy for progressively updating our confidence in the external validity of claims about causal mechanisms through the strategic selection of cases for within-case analysis based on the diversity of the population.},
	language = {en},
	urldate = {2023-02-20},
	booktitle = {Causality in {Policy} {Studies}: a {Pluralist} {Toolbox}},
	publisher = {Springer International Publishing},
	author = {Siewert, Markus B. and Beach, Derek},
	editor = {Damonte, Alessia and Negri, Fedra},
	year = {2023},
	doi = {10.1007/978-3-031-12982-7_10},
	pages = {235--258},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/ZVFAZK4F/Siewert and Beach - 2023 - The Many Threats from Mechanistic Heterogeneity Th.pdf:application/pdf},
}

@article{robins_tutorial_2013,
	series = {Social {Networks}},
	title = {A tutorial on methods for the modeling and analysis of social network data},
	volume = {57},
	issn = {0022-2496},
	url = {https://www.sciencedirect.com/science/article/pii/S0022249613000126},
	doi = {10.1016/j.jmp.2013.02.001},
	abstract = {This article provides a tutorial review of some fundamental ideas and important methods for the modeling of empirical social network data. It describes basic concepts from graph theory and central elements from social network theory. It presents models for the network degree distribution and for network roles and positions, as well as algebraic approaches, before reviewing recent work on statistical methods to analyze social networks, including boot-strap procedures for testing the prevalence of network structures, basic edge- and dyad-independent statistical models, and more recent statistical network models that assume dependence, exponential random graph models and dynamic stochastic actor oriented models. Network social influence models are reviewed. The article concludes with a summary of new developments relating to models for time-ordered transactions.},
	language = {en},
	number = {6},
	urldate = {2023-02-22},
	journal = {Journal of Mathematical Psychology},
	author = {Robins, Garry},
	month = dec,
	year = {2013},
	pages = {261--274},
	file = {ScienceDirect Snapshot:/Users/isabelleborucki/Zotero/storage/VMN8X4LS/S0022249613000126.html:text/html},
}

@inproceedings{parwez_social_2020,
	title = {A {Social} {Media} {Time}-{Series} {Data} {Analytics} {Approach} for {Digital} {Epidemiology}},
	doi = {10.1109/WIIAT50758.2020.00131},
	abstract = {Various events and their perspectives around the world are discussed or posted at every moment on social media platforms like Twitter in near real-time, forming an enriched repository of information as historical records or time series. These include people's sentiments, emotions, opinions, and other information such as situational aspects of the spreading of a particular disease, ailment, or a population explosion of some vectors or pathogens. Exploring and harnessing such information about a disease for surveillance to prevent and control its spreading or becoming epidemic or pandemic is worthwhile for a country or the world. In this paper, we correlate tweeting activity with the reported disease cases, and take advantage of the predictive power of neural networks and auto-regressive models to estimate disease incidences for the current week (aka nowcasting) considering the social media data and the disease case counts reported by the Government agencies. We propose Long Short-Term Memory (LSTM) network models and autoregressive moving average models with two channels of inputs to incorporate social media and historic disease case count data for predicting current disease case counts. We employ various LSTM network models and autoregressive moving average models to estimate the current week's disease case count and compared their performance considering tweets as exogenous input to these models. The experimental results establish the efficacy of the LSTM network models with dynamically merged inputs for predicting disease case count with least prediction error.},
	booktitle = {2020 {IEEE}/{WIC}/{ACM} {International} {Joint} {Conference} on {Web} {Intelligence} and {Intelligent} {Agent} {Technology} ({WI}-{IAT})},
	author = {Parwez, Md. Aslam and Abulaish, Muhammad and Jahiruddin, Jahiruddin},
	month = dec,
	year = {2020},
	keywords = {Sociology, Social media, Surveillance, Data models, Social networking (online), Digital epidemiology, Disease surveillance, LSTM, Neural network, Now-casting, Pathogens, Predictive models, Time series analysis, Time series forecasting},
	pages = {852--859},
	file = {IEEE Xplore Abstract Record:/Users/isabelleborucki/Zotero/storage/J675LPSS/9457692.html:text/html},
}

@book{eckstein_repetitorium_2014,
	address = {Wiesbaden},
	title = {Repetitorium {Statistik}: {Deskriptive} {Statistik} - {Stochastik} - {Induktive} {Statistik}},
	isbn = {978-3-658-05747-3 978-3-658-05748-0},
	shorttitle = {Repetitorium {Statistik}},
	url = {https://link.springer.com/10.1007/978-3-658-05748-0},
	language = {de},
	urldate = {2023-02-26},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Eckstein, Peter P.},
	year = {2014},
	doi = {10.1007/978-3-658-05748-0},
	file = {Eckstein - 2014 - Repetitorium Statistik Deskriptive Statistik - St.pdf:/Users/isabelleborucki/Zotero/storage/7YCCTBAG/Eckstein - 2014 - Repetitorium Statistik Deskriptive Statistik - St.pdf:application/pdf},
}

@incollection{eckstein_zeitreihenanalyse_2016,
	address = {Wiesbaden},
	title = {Zeitreihenanalyse},
	isbn = {978-3-658-10220-3 978-3-658-10221-0},
	url = {https://link.springer.com/10.1007/978-3-658-10221-0_10},
	language = {de},
	urldate = {2023-02-26},
	booktitle = {Statistik für {Wirtschaftswissenschaftler}},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Eckstein, Peter P.},
	collaborator = {Eckstein, Peter P.},
	year = {2016},
	doi = {10.1007/978-3-658-10221-0_10},
	pages = {365--404},
	file = {Eckstein - 2016 - Zeitreihenanalyse.pdf:/Users/isabelleborucki/Zotero/storage/YGAL9UTF/Eckstein - 2016 - Zeitreihenanalyse.pdf:application/pdf},
}

@book{eckstein_klausurtraining_2018,
	address = {Wiesbaden},
	title = {Klausurtraining {Statistik}},
	isbn = {978-3-658-22469-1 978-3-658-22470-7},
	url = {http://link.springer.com/10.1007/978-3-658-22470-7},
	language = {de},
	urldate = {2023-02-26},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Eckstein, Peter P.},
	year = {2018},
	doi = {10.1007/978-3-658-22470-7},
	file = {Eckstein - 2018 - Klausurtraining Statistik.pdf:/Users/isabelleborucki/Zotero/storage/98S5AI27/Eckstein - 2018 - Klausurtraining Statistik.pdf:application/pdf},
}

@misc{politi_visual_2023,
	title = {A {Visual} {Explanation} of {Variance}, {Covariance}, {Correlation} and {Causation}},
	url = {https://towardsdatascience.com/a-visual-explanation-of-variance-covariance-correlation-and-causation-dcf762801029},
	abstract = {Improve your data analysis skills by understanding basic statistical concepts},
	language = {en},
	urldate = {2023-03-01},
	journal = {Towards Data Science},
	author = {Politi, Marcello},
	month = feb,
	year = {2023},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/AXJLHR5B/a-visual-explanation-of-variance-covariance-correlation-and-causation-dcf762801029.html:text/html},
}

@misc{noauthor_statistical_nodate,
	title = {Statistical {Methods} for the {Social} {Sciences}},
	url = {https://www.pearson.com/en-us/subject-catalog/p/statistical-methods-for-the-social-sciences/P200000006062?view=educator},
	urldate = {2023-03-02},
	file = {Statistical Methods for the Social Sciences:/Users/isabelleborucki/Zotero/storage/FXIFDTR2/P200000006062.html:text/html},
}

@misc{noauthor_openintro_nodate,
	title = {{OpenIntro} {Statistics}},
	url = {https://www.openintro.org/book/os/},
	urldate = {2023-03-02},
	file = {OpenIntro Statistics:/Users/isabelleborucki/Zotero/storage/LQ42IPR9/os.html:text/html},
}

@misc{noauthor_statistics_nodate,
	title = {Statistics and {Probability}},
	url = {https://www.khanacademy.org/math/statistics-probability},
	abstract = {Learn statistics and probability for free—everything you'd want to know about descriptive and inferential statistics. Full curriculum of exercises and videos.},
	language = {en},
	urldate = {2023-03-02},
	journal = {Khan Academy},
	file = {Snapshot:/Users/isabelleborucki/Zotero/storage/V7E38X5L/statistics-probability.html:text/html},
}

@incollection{von_dem_berge_teilstandardisierte_2020,
	address = {Wiesbaden},
	series = {Grundwissen {Politik}},
	title = {Teilstandardisierte {Experteninterviews}},
	isbn = {978-3-658-30237-5},
	url = {https://doi.org/10.1007/978-3-658-30237-5_9},
	abstract = {Im Rahmen der qualitativen empirischen Sozialforschung stellen Interviews eine wichtige Methode der Datenerhebung dar. Es existieren zahlreiche unterschiedliche Arten bzw. Typen von Interviews. In diesem Beitrag werden teilstandardisierte Experteninterviews behandelt, die auf eine Hypothesenprüfung abzielen und mit Hilfe eines (teilstandardisierten) Interviewleitfadens durchgeführt werden. Der Beitrag ist in erster Linie als Leitfaden für Neulinge im Bereich der Interviewführung zu verstehen und kann insofern als eine Art „Kurzanleitung“ zur Durchführung von Experteninterviews betrachtet werden. Es handelt sich um einen ersten Überblick für Personen ohne Erfahrungen in der der Durchführung von teilstandardisierten Experteninterviews.},
	language = {de},
	urldate = {2021-01-29},
	booktitle = {Fortgeschrittene {Analyseverfahren} in den {Sozialwissenschaften}: {Ein} Überblick},
	publisher = {Springer Fachmedien},
	author = {von dem Berge, Benjamin},
	editor = {Tausendpfund, Markus},
	year = {2020},
	doi = {10.1007/978-3-658-30237-5_9},
	keywords = {Experten, Befragung, Datenerhebung, Interview, Interviewleitfaden, Qualitative empirische Sozialforschung, Teilstandardisiert},
	pages = {275--300},
	file = {Springer Full Text PDF:/Users/isabelleborucki/Zotero/storage/6MAF58V3/von dem Berge - 2020 - Teilstandardisierte Experteninterviews.pdf:application/pdf},
}

@incollection{helfferich_leitfaden-_2014,
	address = {Wiesbaden},
	title = {Leitfaden- und {Experteninterviews}},
	isbn = {978-3-531-17809-7},
	shorttitle = {Helfferich 2014 – {Leitfaden}- und {Experteninterview}},
	booktitle = {Handbuch {Methoden} der empirischen {Sozialforschung}},
	publisher = {Springer VS},
	author = {Helfferich, Cornelia},
	editor = {Baur, Nina and Blasius, Jörg},
	year = {2014},
	pages = {559--574},
}

@book{glaser_experteninterviews_2010,
	title = {Experteninterviews und qualitative {Inhaltsanalyse} als {Instrumente} rekonstruktiver {Untersuchungen}},
	abstract = {Viele sozialwissenschaftliche Untersuchungen beruhen auf Rekonstruktionen von Situationen oder Prozessen. Das Lehrbuch vermittelt anhand zweier Beispieluntersuchungen anwendungsbereites Wissen über alle Phasen solcher rekonstruierender Untersuchungen und stellt je eine Erhebungs- und eine Auswertungsmethode ausführlich vor. Die Interviewpartner werden als Experten aufgefasst, die über spezifisches Wissen über die zu rekonstruierenden Sachverhalte verfügen. Die qualitative Inhaltsanalyse ermöglicht eine systematische Extraktion relevanter Informationen aus den Interviews und ist zugleich offen für nicht erwartete Befunde. Mit Lernfragen nach jedem Kapitel und einer übersichtlichen Gliederung eignet sich das Buch als praxisorientierte Einführung. Dr. Jochen Gläser ist Privatdozent an der Freien Universität Berlin. Dr. Grit Laudel ist Senior Researcher am Rathenau Institut in Den Haag (Niederlande).},
	author = {Gläser, Jochen and Laudel, Grit},
	year = {2010},
	doi = {10.1007/978-3-531-91538-8},
	note = {Publication Title: Experteninterviews und qualitative Inhaltsanalyse},
}

@incollection{meuser_experteninterview_2009,
	address = {Wiesbaden},
	title = {Das {Experteninterview} - konzeptionelle {Grundlagen} und methodische {Anlage}},
	isbn = {3-531-16194-6},
	shorttitle = {Meuser, {Nagel} 2009 – {Das} {Experteninterview}},
	language = {de},
	booktitle = {Methoden der vergleichenden {Politik}- und {Sozialwissenschaft}},
	publisher = {VS Verlag},
	author = {Meuser, Michael and Nagel, Ulrike},
	editor = {Pickel, Susanne},
	year = {2009},
	keywords = {Methoden, Experteninterview},
	pages = {465--479},
	annote = {RecordNumber: 969 Notes: RecordNumber: 1881 NameOfDatabase: EndNote},
	annote = {RecordNumber: 969 Notes: RecordNumber: 1881 NameOfDatabase: EndNote},
}

@incollection{liebold_experteninterview_2009,
	title = {Experteninterview {Handbuch} {Methoden} der {Organisationsforschung}},
	isbn = {978-3-531-91570-8},
	shorttitle = {Liebold, {Trinczek} 2009 – {Experteninterview} {Handbuc}},
	url = {http://dx.doi.org/10.1007/978-3-531-91570-8_3},
	abstract = {Der Begriff ‚Experteninterview‘ ist außerordentlich unpräzise. Etwas überspitzt formuliert könnte man sagen, der folgende Beitrag handelt von einem methodischen Verfahren, das es als eine bestimmte Interviewform im Grunde gar nicht gibt. Bereits die Spezifizierung des Verfahrens qua Verweis auf den Interviewpartner sowie dessen spezifische Qualität (‚Experte‘) ist ungewöhnlich. Üblicherweise werden Interviewverfahren sprachlich durch eine Präzisierung der Erhebungsmethode näher bezeichnet: Das narrative Interview, das vollstandardisierte Interview, das problemzentrierte Interview, das Telefoninterview etc.},
	publisher = {VS Verlag für Sozialwissenschaften},
	author = {Liebold, Renate and Trinczek, Rainer},
	editor = {Kühl, Stefan and Strodtholz, Petra and Taffertshofer, Andreas},
	year = {2009},
	doi = {10.1007/978-3-531-91570-8_3},
	keywords = {Methoden, Experteninterview},
	pages = {32--56},
	annote = {RecordNumber: 854 Notes: RecordNumber: 1880 NameOfDatabase: EndNote},
	annote = {RecordNumber: 854 Notes: RecordNumber: 1880 NameOfDatabase: EndNote},
}

@book{glaser_experteninterviews_2009,
	address = {Wiesbaden},
	edition = {3., überar},
	title = {Experteninterviews und qualitative {Inhaltsanalyse} als {Instrumente} rekonstruierender {Untersuchungen}},
	isbn = {978-3-531-15684-2},
	shorttitle = {Gläser, {Laudel} 2009 – {Experteninterviews} und quali},
	url = {http://deposit.d-nb.de/cgi-bin/dokserv?id=2995427&prov=M&dok_var=1&dok_ext=htm / http://swbplus.bsz-bw.de/bsz271776439inh.htm},
	language = {ger},
	publisher = {VS Verlag},
	author = {Gläser, Jochen and Laudel, Grit},
	year = {2009},
	annote = {Jochen Gläser; Grit Laudel /// Literaturverz. S. 289 - 294 kart. : EUR 29.90 SWB - Baden-Württemberg Bibliotheksservice-Zentrum /// Deutsche Nationalbibliothek http://deposit.d-nb.de/cgi-bin/dokserv?id=2995427\&prov=M\&dok\_var=1\&dok\_ext=htm http://swbplus.bsz-bw.de/bsz271776439inh.htm},
	annote = {Jochen Gläser; Grit Laudel /// Literaturverz. S. 289 - 294 kart. : EUR 29.90 SWB - Baden-Württemberg Bibliotheksservice-Zentrum /// Deutsche Nationalbibliothek http://deposit.d-nb.de/cgi-bin/dokserv?id=2995427\&prov=M\&dok\_var=1\&dok\_ext=htm http://swbplus.bsz-bw.de/bsz271776439inh.htm},
}

@incollection{jahr_parlamentarier_2008,
	address = {Baden-Baden},
	title = {Parlamentarier am {Telefon}: {Erfahrungsbericht} einer {Erhebung} von {Rollenverständnis} und mandatzbezogenen {Einstellungen} deutscher {Abgeordneter}},
	shorttitle = {Parlamentarier am {Telefon}: {Erfahrungsbericht} einer},
	booktitle = {Eliten am {Telefon}: {Neue} {Formen} von {Experteninterviews} in der {Praxis}},
	publisher = {Nomos Verlagsgesellschaft},
	author = {Jahr, Stefan and Edinger, Michael},
	editor = {Martens, Bernd and Ritter, Thomas},
	year = {2008},
	pages = {23--40},
}

@incollection{meuser_expertinneninterviews_2005,
	address = {Wiesbaden},
	edition = {2. Aufl.},
	title = {{ExpertInneninterviews} - vielfach erprobt,wenig bedacht: {Ein} {Beitrag} zur qualitativen {Methodendiskussion}},
	isbn = {3-531-14447-2},
	shorttitle = {Meuser, {Nagel} 2005 – {ExpertInneninterviews}},
	language = {de},
	booktitle = {Das {Experteninterview}},
	publisher = {VS Verlag},
	author = {Meuser, Michael and Nagel, Ulrike},
	editor = {Bogner, Alexander},
	year = {2005},
	pages = {71--130},
}

@book{bogner_experteninterview_2005,
	address = {Wiesbaden},
	edition = {2. Aufl.},
	title = {Das {Experteninterview}: {Theorie}, {Methode}, {Anwendung}},
	isbn = {3-531-14447-2},
	shorttitle = {Bogner ({Hg}.) 2005 – {Das} {Experteninterview}},
	language = {ger},
	publisher = {VS Verlag},
	author = {Bogner, Alexander},
	year = {2005},
	keywords = {Sociology, Interviews, Experteninterview},
}

@article{meuser_experteninterview_2004,
	title = {Das {Experteninterview} – konzeptionelle {Grundlagen} und methodische {Anlage}},
	number = {1995},
	author = {Meuser, Michael},
	year = {2004},
	file = {Attachment:/Users/isabelleborucki/Zotero/storage/FE3EUZCK/Meuser - 2004 - Das Experteninterview – konzeptionelle Grundlagen und.pdf:application/pdf},
}

@book{glaser_experteninterviews_2004,
	address = {Wiesbaden},
	title = {Experteninterviews und qualitative {Inhaltsanalyse} als {Instrumente} rekonstruierender {Untersuchungen}},
	isbn = {3-8252-2348-5},
	shorttitle = {Gläser, {Laudel} 2004 – {Experteninterviews} und quali},
	url = {http://www.agi-imc.de/intelligentSEARCH.nsf/alldocs/60569829249D1315C1256FBF0034FC82/},
	language = {de},
	number = {2348},
	publisher = {VS Verlag},
	author = {Gläser, Jochen and Laudel, Grit},
	year = {2004},
	note = {Publication Title: UTB Sozialwissenschaften},
	keywords = {Qualitative Inhaltsanalyse, Lehrbuch, Auswertung, Experteninterview},
	annote = {Literaturverz. S. 281 - 286 EUR 29.90 /// kart. : EUR 29.90 Gemeinsamer Bibliotheksverbund (GBV) /// Deutsche Nationalbibliothek http://www.agi-imc.de/intelligentSEARCH.nsf/alldocs/60569829249D1315C1256FBF0034FC82/},
	annote = {Literaturverz. S. 281 - 286 EUR 29.90 /// kart. : EUR 29.90 Gemeinsamer Bibliotheksverbund (GBV) /// Deutsche Nationalbibliothek http://www.agi-imc.de/intelligentSEARCH.nsf/alldocs/60569829249D1315C1256FBF0034FC82/},
}

@article{voraussetzung_experteninterview_nodate,
	title = {Das {Experteninterview} {Methoden} der {Politikwissenschaft} {Techniken} der {Datenerhebung} {Das} {Experteninterview} {Allgemeine} {Bemerkungen} ( {I} ) {Allgemeine} {Bemerkungen} ( {II} ) {Allgemeine} {Bemerkungen} ( {III} ) {Voraussetzung} ( {II} ) {Voraussetzung} ( {III} ) {Voraussetzung} ( {I}},
	number = {Iv},
	author = {Voraussetzung, I},
	file = {Attachment:/Users/isabelleborucki/Zotero/storage/PZNWYYGJ/Voraussetzung - Unknown - Das Experteninterview Methoden der Politikwissenschaft Techniken der Datenerhebung Das Experteninterview Allge.pdf:application/pdf},
}

@book{juretig_r_2019,
	address = {Birmingham Mumbai},
	edition = {First published},
	title = {R statistics cookbook: over 100 recipes for performing complex statistical operations with {R} 3.5},
	isbn = {978-1-78980-256-6},
	shorttitle = {R statistics cookbook},
	abstract = {Table of ContentsGetting Started with R and StatisticsUnivariate and Multivariate Tests for Equality of MeansLinear RegressionBayesian RegressionNonparametric MethodsRobust MethodsTime Series AnalysisMixed Effects ModelsPredictive Models Using the Caret PackageBayesian Networks and Hidden Markov ModelsELD},
	language = {eng},
	publisher = {Packt},
	author = {Juretig, Francisco},
	year = {2019},
	file = {Juretig - 2019 - R statistics cookbook over 100 recipes for performing complex statistical operations with R 3.5.pdf:/Users/isabelleborucki/Zotero/storage/GHSWKU4I/Juretig - 2019 - R statistics cookbook over 100 recipes for performing complex statistical operations with R 3.5.pdf:application/pdf},
}

@book{flick_qualitative_2021,
	address = {Reinbek bei Hamburg},
	edition = {10. Auflage, Originalausgabe},
	series = {Rororo {Rowohlts} {Enzyklopädie}},
	title = {Qualitative {Sozialforschung}: eine {Einführung}},
	isbn = {978-3-499-55694-4},
	shorttitle = {Qualitative {Sozialforschung}},
	language = {ger},
	number = {55694},
	publisher = {rowohlts enzyklopädie im Rowohlt Taschenbuch Verlag},
	author = {Flick, Uwe},
	year = {2021},
}

@book{morrow_be_2021,
	address = {London ; New York, NY},
	title = {Be data literate: the data literacy skills everyone needs to succeed},
	isbn = {978-1-78966-803-2 978-1-78966-801-8},
	shorttitle = {Be data literate},
	abstract = {"In the fast moving world of the fourth industrial revolution not everyone needs to be a data scientist but everyone should be data literate, with the ability to read, analyze and communicate with data. It is not enough for a business to have the best technology if those using it don't understand the right questions to ask or how to use the information generated to make decisions. Be Data Literate is the essential guide to developing the curiosity, creativity and critical thinking necessary to make anyone data literate, without retraining as a data scientist or statistician. With exercises to show development and real-world examples from industries implementing data literacy skills, this book explains how to confidently read and speak the 'language of data' in the modern business environment and everyday life. Be Data Literate is a practical guide to understanding the four levels of analytics, how to analyze data and the key steps to making smarter, data-informed decisions. Written by a founding pioneer and worldwide leading expert on data literacy, this book empowers professionals with the skills they need to succeed in the digital world"--},
	publisher = {KoganPage},
	author = {Morrow, Jordan},
	year = {2021},
}

@book{schurz_einfuhrung_2011,
	address = {Darmstadt},
	edition = {3., durchges. Aufl},
	title = {Einführung in die {Wissenschaftstheorie}},
	isbn = {978-3-534-24411-9},
	language = {ger},
	publisher = {Wiss. Buchges., [Abt. Verl.]},
	author = {Schurz, Gerhard},
	year = {2011},
	file = {Schurz - 2011 - Einführung in die Wissenschaftstheorie.pdf:/Users/isabelleborucki/Zotero/storage/XE6SI4XG/Schurz - 2011 - Einführung in die Wissenschaftstheorie.pdf:application/pdf},
}

@book{ellenberg_how_2015,
	address = {New York},
	title = {How not to be wrong: the power of mathematical thinking},
	isbn = {978-0-14-312753-6 978-1-59420-522-4},
	shorttitle = {How not to be wrong},
	abstract = {"In How Not to Be Wrong, Jordan Ellenberg shows us that math isn't confined to abstract incidents that never occur in real life, but rather touches everything we do--the whole world is shot through with it. Math allows us to see the hidden structures underneath the messy and chaotic surface of our world. It's a science of not being wrong, hammered out by centuries of hard work and argument. Armed with the tools of mathematics, we can see through to the true meaning of information we take for granted: How early should you get to the airport? What does "public opinion" really represent? Why do tall parents have shorter children? Who really won Florida in 2000? And how likely are you, really, to develop cancer? How Not to Be Wrong presents the surprising revelations behind all of these questions and many more, using the mathematician's method of analyzing life and exposing the hard-won insights of the academic community to the layman--minus the jargon. Ellenberg pulls from history as well as from the latest theoretical developments to provide those not trained in math with the knowledge they need. "--},
	language = {eng},
	publisher = {Penguin Books},
	author = {Ellenberg, Jordan},
	year = {2015},
	file = {Ellenberg - 2015 - How not to be wrong the power of mathematical thinking.pdf:/Users/isabelleborucki/Zotero/storage/PDE6GAQF/Ellenberg - 2015 - How not to be wrong the power of mathematical thinking.pdf:application/pdf},
}

@book{schurz2014,
	title = {Einführung in die Wissenschaftstheorie},
	author = {Schurz, Gerhard},
	year = {2014},
	month = {06},
	date = {2014-06-18},
	url = {https://content-select.com/de/portal/media/view/58ab282b-e4fc-41bd-844f-31bdb0dd2d03}
}

@inbook{strübing2018,
	title = {8. Forschungsethik und qualitative Forschung},
	author = {{Strübing}, {Jörg}},
	year = {2018},
	month = {05},
	date = {2018-05-07},
	publisher = {De Gruyter Oldenbourg},
	pages = {218--229},
	doi = {10.1515/9783110529920-008},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110529920-008/html},
	note = {DOI: 10.1515/9783110529920-008},
	langid = {de}
}

@article{wagner2019,
	title = {Eine {,,}Ethik der Politikberatung{\textquotedblleft} gehört zur Forschungsethik},
	author = {Wagner, Gert G.},
	year = {2019},
	date = {2019},
	journal = {RatSWD Working Paper Series},
	doi = {10.17620/02671.45},
	url = {https://www.konsortswd.de/aktuelles/publikation/wp269-2019/},
	note = {Publisher: German Data Forum ( RatSWD)
Version Number: 1},
	langid = {de}
}

@book{salganik2019,
	title = {Bit by Bit},
	author = {Salganik, Mathew},
	year = {2019},
	month = {08},
	date = {2019-08-06},
	publisher = {Princeton University Press},
	url = {https://press.princeton.edu/books/paperback/9780691196107/bit-by-bit},
	langid = {en}
}

@inbook{friedrichs2022,
	title = {Forschungsethik},
	author = {Friedrichs, {Jürgen}},
	year = {2022},
	date = {2022},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {349--358},
	doi = {10.1007/978-3-658-37985-8_21},
	url = {http://dx.doi.org/10.1007/978-3-658-37985-8_21}
}


@incollection{friedrichs_forschungsethik_2022,
	address = {Wiesbaden},
	title = {Forschungsethik},
	isbn = {978-3-658-37985-8},
	url = {https://doi.org/10.1007/978-3-658-37985-8_21},
	abstract = {Ethische Probleme treten vor allem bei der Befragung, dem Experiment und der teilnehmenden Beobachtung auf. Grundsätzliche Regelungen für derartige Probleme enthalten die nationalen und Landes-Datenschutzgesetze und die Ethik-Codes wissenschaftlicher Standesorganisationen. Dennoch bleibt ein nicht unerheblicher Spielraum für die einzelnen Forscher/innen.},
	language = {de},
	urldate = {2023-03-15},
	booktitle = {Handbuch {Methoden} der empirischen {Sozialforschung}},
	publisher = {Springer Fachmedien},
	author = {Friedrichs, Jürgen},
	editor = {Baur, Nina and Blasius, Jörg},
	year = {2022},
	doi = {10.1007/978-3-658-37985-8_21},
	pages = {349--358},
	file = {Full Text PDF:/Users/isabelleborucki/Zotero/storage/HL35IQ9B/Friedrichs - 2022 - Forschungsethik.pdf:application/pdf},
}


@book{bernauer2018,
	title = {Einführung in die Politikwissenschaft},
	author = {Bernauer, Thomas and {Jahn, Detlef},  and {Kuhn, Patrick M},  and {Walter, Stefanie}, },
	year = {2018},
	date = {2018},
	publisher = {Nomos Verlagsgesellschaft mbH & Co. KG},
	doi = {10.5771/9783845289724},
	note = {DOI: 10.5771/9783845289724}
}

@inbook{stein2022,
	title = {Forschungsdesigns für die quantitative Sozialforschung},
	author = {Stein, Petra},
	year = {2022},
	date = {2022},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {143--162},
	doi = {10.1007/978-3-658-37985-8_8},
	url = {http://dx.doi.org/10.1007/978-3-658-37985-8_8}
}


@inbook{przyborski2022,
	title = {Forschungsdesigns für die qualitative Sozialforschung},
	author = {Przyborski, Aglaja and Wohlrab-Sahr, Monika},
	year = {2022},
	date = {2022},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {123--142},
	doi = {10.1007/978-3-658-37985-8_7},
	url = {http://dx.doi.org/10.1007/978-3-658-37985-8_7}
}

@inbook{horvath2022,
	title = {Forschungsfragen},
	author = {Horvath, Kenneth},
	year = {2022},
	date = {2022},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {35--50},
	doi = {10.1007/978-3-658-37985-8_2},
	url = {http://dx.doi.org/10.1007/978-3-658-37985-8_2}
}

@inbook{diaz-bone2022,
	title = {Messen},
	author = {Diaz-Bone, Rainer},
	year = {2022},
	date = {2022},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {105--122},
	doi = {10.1007/978-3-658-37985-8_6},
	url = {http://dx.doi.org/10.1007/978-3-658-37985-8_6}
}

@inbook{eifler2022,
	title = {Experiment},
	author = {Eifler, Stefanie and {Leitgöb}, Heinz},
	year = {2022},
	date = {2022},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {225--241},
	doi = {10.1007/978-3-658-37985-8_13},
	url = {http://dx.doi.org/10.1007/978-3-658-37985-8_13}
}

@book{handl2018,
	title = {Einführung in die Statistik},
	author = {Handl, Andreas and Kuhlenkasper, Torben},
	year = {2018},
	date = {2018},
	publisher = {Springer Berlin Heidelberg},
	doi = {10.1007/978-3-662-56440-0},
	url = {http://dx.doi.org/10.1007/978-3-662-56440-0}
}

@inbook{leifeld2020,
	title = {Netzwerkanalyse in der Politikwissenschaft},
	author = {Leifeld, Philip},
	year = {2020},
	date = {2020},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {573--594},
	doi = {10.1007/978-3-658-16936-7_37},
	url = {http://dx.doi.org/10.1007/978-3-658-16936-7_37}
}

@inbook{munzert2020,
	title = {Die Nutzung von Webdaten in den Sozialwissenschaften},
	author = {Munzert, Simon and Nyhuis, Dominic},
	year = {2020},
	date = {2020},
	publisher = {Springer Fachmedien Wiesbaden},
	pages = {373--397},
	doi = {10.1007/978-3-658-16936-7_22},
	url = {http://dx.doi.org/10.1007/978-3-658-16936-7_22}
}

@inbook{behnke2018,
	title = {1 Einleitung. Big Data in der Politikwissenschaft: Wirklich neu oder lediglich mehr?},
	author = {Behnke, Joachim and {Blätte}, Andreas and Schnapp, Kai-Uwe and Wagemann, Claudius},
	year = {2018},
	date = {2018},
	publisher = {Nomos Verlagsgesellschaft mbH & Co. KG},
	pages = {7--24},
	doi = {10.5771/9783845286556-7},
	url = {http://dx.doi.org/10.5771/9783845286556-7}
}

@inbook{2method2021,
	title = {2 Methodologie und Standards qualitativer Sozialforschung},
	year = {2021},
	month = {09},
	date = {2021-09-20},
	publisher = {De Gruyter},
	pages = {13--56},
	doi = {10.1515/9783110710663-002},
	url = {http://dx.doi.org/10.1515/9783110710663-002}
}

@book{przyborski2021,
	title = {Qualitative Sozialforschung},
	author = {Przyborski, Aglaja and Wohlrab-Sahr, Monika},
	year = {2021},
	month = {09},
	date = {2021-09-20},
	publisher = {De Gruyter},
	doi = {10.1515/9783110710663},
	url = {http://dx.doi.org/10.1515/9783110710663}
}
